{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MMLPix2Pix",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wNjDKdQy35h"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHZ8tEJuCEVC",
        "outputId": "453403f9-2c33-4866-9a33-103586f6e11a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/My\\ Drive/Colab Notebooks"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRm-USlsHgEV",
        "outputId": "3c36fc64-282a-4a4c-825b-4eea3dfb7680",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/loerssoni/raster-to-contour"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'raster-to-contour' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhS0v1TuTiRH",
        "outputId": "8b13d5ee-0563-485e-8196-53bd89a283c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "os.chdir('raster-to-contour/')\n",
        "os.getcwd()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/gdrive/My Drive/Colab Notebooks/raster-to-contour'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1EySlOXwwoa",
        "outputId": "53cf140f-972f-4010-ab0d-08b0b1dd5e5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.7.0+cu101)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.8.1+cu101)\n",
            "Collecting dominate>=2.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/a8/4354f8122c39e35516a2708746d89db5e339c867abbd8e0179bccee4b7f9/dominate-2.6.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (0.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (7.0.0)\n",
            "Installing collected packages: dominate\n",
            "Successfully installed dominate-2.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeN2NsowL4Nq",
        "outputId": "cf0e81f6-856f-4b0e-9389-02c19d25821a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git pull origin master"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From https://github.com/loerssoni/raster-to-contour\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UCN6VqWtYmS"
      },
      "source": [
        "# Dataset creation\n",
        "\n",
        "-   `python datasets/datagen.py --directory ./dataset_name --num_imgs 1000`\n",
        "\n",
        "Create a dataset of paired map images from  Maanmittauslaitos open data. Change the `--directory` and to the location your own dataset's path. Creates `--num_imgs` images with `--ratio` train to test split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWLT3r3EE1cZ",
        "outputId": "f8452450-a7b5-491f-ea13-144fd852bc09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python datasets/datagen.py --directory ./mydataset --num_imgs 2000"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "split = train, create 1800 images\n",
            "split = train, number of images = 1800\n",
            "split = test, create 200 images\n",
            "split = test, number of images = 200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFw1kDQBx3LN"
      },
      "source": [
        "# Training\n",
        "\n",
        "-   `python train.py --dataroot ./dataset_name --name name of the model --model pix2pix\n",
        "\n",
        "Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sp7TCT2x9dB",
        "outputId": "39c7a3cb-b496-4495-d150-0b15c2a70fa0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python train.py --dataroot ./mydataset --name maps_pix2pix --model pix2pix  --n_epochs 1 n_epochs_decay 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./mydataset                   \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 10                            \t[default: 1]\n",
            "                 gan_mode: vanilla                       \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                lambda_L1: 100.0                         \n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "                 log_name: loss_log.txt                  \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \n",
            "                 n_epochs: 100                           \n",
            "           n_epochs_decay: 100                           \n",
            "               n_layers_D: 3                             \n",
            "                     name: maps_pix2pix                  \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: unet_256                      \n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                     norm: batch                         \n",
            "              num_threads: 4                             \n",
            "                output_nc: 1                             \n",
            "                    phase: train                         \n",
            "                pool_size: 0                             \n",
            "               preprocess: resize_crop_noise             \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 100                           \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "The number of training images = 914\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 54.410 M\n",
            "[Network D] Total number of parameters : 2.767 M\n",
            "-----------------------------------------------\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 10, iters: 100, time: 0.076, data: 0.561) G_GAN: 2.567 G_L1: 13.978 D_real: 0.334 D_fake: 0.076 \n",
            "(epoch: 10, iters: 200, time: 0.076, data: 0.000) G_GAN: 3.120 G_L1: 8.714 D_real: 0.123 D_fake: 0.761 \n",
            "(epoch: 10, iters: 300, time: 0.075, data: 0.031) G_GAN: 0.798 G_L1: 7.043 D_real: 0.330 D_fake: 1.520 \n",
            "(epoch: 10, iters: 400, time: 0.081, data: 0.076) G_GAN: 1.184 G_L1: 6.366 D_real: 0.433 D_fake: 1.328 \n",
            "(epoch: 10, iters: 500, time: 0.078, data: 0.004) G_GAN: 0.883 G_L1: 1.965 D_real: 1.099 D_fake: 0.380 \n",
            "(epoch: 10, iters: 600, time: 0.080, data: 0.000) G_GAN: 0.719 G_L1: 0.445 D_real: 0.599 D_fake: 0.801 \n",
            "(epoch: 10, iters: 700, time: 0.071, data: 0.000) G_GAN: 2.293 G_L1: 8.325 D_real: 0.070 D_fake: 0.136 \n",
            "(epoch: 10, iters: 800, time: 0.087, data: 0.000) G_GAN: 1.269 G_L1: 1.587 D_real: 0.642 D_fake: 0.206 \n",
            "(epoch: 10, iters: 900, time: 0.090, data: 0.000) G_GAN: 2.134 G_L1: 5.221 D_real: 0.048 D_fake: 0.595 \n",
            "End of epoch 10 / 200 \t Time Taken: 107 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 11, iters: 86, time: 0.069, data: 0.000) G_GAN: 0.613 G_L1: 0.191 D_real: 0.638 D_fake: 0.754 \n",
            "(epoch: 11, iters: 186, time: 0.099, data: 0.000) G_GAN: 1.024 G_L1: 1.713 D_real: 0.349 D_fake: 0.691 \n",
            "(epoch: 11, iters: 286, time: 0.070, data: 0.000) G_GAN: 1.341 G_L1: 4.129 D_real: 0.265 D_fake: 0.174 \n",
            "(epoch: 11, iters: 386, time: 0.080, data: 0.000) G_GAN: 0.649 G_L1: 0.474 D_real: 0.653 D_fake: 0.764 \n",
            "(epoch: 11, iters: 486, time: 0.092, data: 0.000) G_GAN: 2.002 G_L1: 9.237 D_real: 0.575 D_fake: 0.241 \n",
            "(epoch: 11, iters: 586, time: 0.085, data: 0.000) G_GAN: 0.884 G_L1: 0.513 D_real: 0.893 D_fake: 0.496 \n",
            "(epoch: 11, iters: 686, time: 0.082, data: 0.000) G_GAN: 1.828 G_L1: 6.334 D_real: 0.323 D_fake: 0.230 \n",
            "(epoch: 11, iters: 786, time: 0.073, data: 0.000) G_GAN: 1.532 G_L1: 5.963 D_real: 0.491 D_fake: 1.108 \n",
            "(epoch: 11, iters: 886, time: 0.092, data: 0.000) G_GAN: 0.638 G_L1: 0.086 D_real: 0.454 D_fake: 1.044 \n",
            "End of epoch 11 / 200 \t Time Taken: 107 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 12, iters: 72, time: 0.082, data: 0.000) G_GAN: 1.187 G_L1: 2.096 D_real: 0.615 D_fake: 0.475 \n",
            "(epoch: 12, iters: 172, time: 0.094, data: 0.001) G_GAN: 1.341 G_L1: 2.617 D_real: 0.160 D_fake: 0.395 \n",
            "(epoch: 12, iters: 272, time: 0.083, data: 0.000) G_GAN: 0.663 G_L1: 0.060 D_real: 0.691 D_fake: 0.703 \n",
            "(epoch: 12, iters: 372, time: 0.071, data: 0.000) G_GAN: 0.702 G_L1: 0.082 D_real: 0.680 D_fake: 0.746 \n",
            "(epoch: 12, iters: 472, time: 0.069, data: 0.000) G_GAN: 1.453 G_L1: 9.916 D_real: 1.556 D_fake: 0.105 \n",
            "(epoch: 12, iters: 572, time: 0.082, data: 0.040) G_GAN: 1.695 G_L1: 3.534 D_real: 0.453 D_fake: 0.381 \n",
            "(epoch: 12, iters: 672, time: 0.100, data: 0.172) G_GAN: 1.074 G_L1: 0.847 D_real: 0.525 D_fake: 0.608 \n",
            "(epoch: 12, iters: 772, time: 0.103, data: 0.000) G_GAN: 0.752 G_L1: 1.412 D_real: 0.835 D_fake: 0.445 \n",
            "(epoch: 12, iters: 872, time: 0.087, data: 0.000) G_GAN: 2.571 G_L1: 4.402 D_real: 0.133 D_fake: 0.680 \n",
            "End of epoch 12 / 200 \t Time Taken: 108 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 13, iters: 58, time: 0.083, data: 0.000) G_GAN: 1.763 G_L1: 3.303 D_real: 0.412 D_fake: 0.555 \n",
            "(epoch: 13, iters: 158, time: 0.089, data: 0.000) G_GAN: 0.766 G_L1: 0.132 D_real: 0.548 D_fake: 0.872 \n",
            "(epoch: 13, iters: 258, time: 0.087, data: 0.000) G_GAN: 0.790 G_L1: 0.047 D_real: 0.807 D_fake: 0.599 \n",
            "(epoch: 13, iters: 358, time: 0.096, data: 0.000) G_GAN: 2.740 G_L1: 3.023 D_real: 0.042 D_fake: 1.268 \n",
            "(epoch: 13, iters: 458, time: 0.084, data: 0.000) G_GAN: 1.002 G_L1: 0.452 D_real: 0.501 D_fake: 0.580 \n",
            "(epoch: 13, iters: 558, time: 0.057, data: 0.000) G_GAN: 2.322 G_L1: 7.845 D_real: 0.125 D_fake: 0.658 \n",
            "(epoch: 13, iters: 658, time: 0.079, data: 0.000) G_GAN: 0.674 G_L1: 0.041 D_real: 0.888 D_fake: 0.539 \n",
            "(epoch: 13, iters: 758, time: 0.084, data: 0.000) G_GAN: 2.085 G_L1: 15.311 D_real: 0.141 D_fake: 0.419 \n",
            "(epoch: 13, iters: 858, time: 0.090, data: 0.000) G_GAN: 2.545 G_L1: 2.785 D_real: 0.947 D_fake: 0.021 \n",
            "End of epoch 13 / 200 \t Time Taken: 113 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 14, iters: 44, time: 0.101, data: 0.001) G_GAN: 2.506 G_L1: 2.180 D_real: 0.463 D_fake: 0.070 \n",
            "(epoch: 14, iters: 144, time: 0.105, data: 0.016) G_GAN: 3.481 G_L1: 8.009 D_real: 0.301 D_fake: 0.022 \n",
            "(epoch: 14, iters: 244, time: 0.080, data: 0.001) G_GAN: 0.343 G_L1: 7.277 D_real: 1.337 D_fake: 0.024 \n",
            "(epoch: 14, iters: 344, time: 0.100, data: 0.000) G_GAN: 1.747 G_L1: 2.497 D_real: 0.324 D_fake: 0.411 \n",
            "(epoch: 14, iters: 444, time: 0.116, data: 0.070) G_GAN: 2.271 G_L1: 6.977 D_real: 0.262 D_fake: 0.228 \n",
            "(epoch: 14, iters: 544, time: 0.098, data: 0.003) G_GAN: 2.978 G_L1: 8.596 D_real: 0.178 D_fake: 0.214 \n",
            "(epoch: 14, iters: 644, time: 0.089, data: 0.000) G_GAN: 1.903 G_L1: 4.491 D_real: 0.211 D_fake: 0.128 \n",
            "(epoch: 14, iters: 744, time: 0.092, data: 0.000) G_GAN: 0.739 G_L1: 0.020 D_real: 0.743 D_fake: 0.664 \n",
            "(epoch: 14, iters: 844, time: 0.102, data: 0.002) G_GAN: 0.705 G_L1: 0.039 D_real: 0.786 D_fake: 0.629 \n",
            "End of epoch 14 / 200 \t Time Taken: 111 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 15, iters: 30, time: 0.089, data: 0.003) G_GAN: 3.376 G_L1: 10.721 D_real: 0.038 D_fake: 0.061 \n",
            "(epoch: 15, iters: 130, time: 0.070, data: 0.013) G_GAN: 0.462 G_L1: 0.062 D_real: 0.342 D_fake: 1.326 \n",
            "(epoch: 15, iters: 230, time: 0.063, data: 0.181) G_GAN: 2.666 G_L1: 10.947 D_real: 0.123 D_fake: 0.233 \n",
            "(epoch: 15, iters: 330, time: 0.086, data: 0.054) G_GAN: 1.312 G_L1: 8.100 D_real: 1.299 D_fake: 0.033 \n",
            "(epoch: 15, iters: 430, time: 0.084, data: 0.000) G_GAN: 1.030 G_L1: 6.783 D_real: 0.651 D_fake: 0.242 \n",
            "saving the latest model (epoch 15, total_iters 5000)\n",
            "(epoch: 15, iters: 530, time: 0.085, data: 0.000) G_GAN: 0.711 G_L1: 0.765 D_real: 0.364 D_fake: 0.855 \n",
            "(epoch: 15, iters: 630, time: 0.126, data: 0.000) G_GAN: 1.780 G_L1: 5.458 D_real: 0.406 D_fake: 0.043 \n",
            "(epoch: 15, iters: 730, time: 0.083, data: 0.000) G_GAN: 0.498 G_L1: 1.867 D_real: 2.100 D_fake: 0.065 \n",
            "(epoch: 15, iters: 830, time: 0.111, data: 0.000) G_GAN: 0.668 G_L1: 0.014 D_real: 0.690 D_fake: 0.711 \n",
            "End of epoch 15 / 200 \t Time Taken: 116 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 16, iters: 16, time: 0.093, data: 0.000) G_GAN: 3.007 G_L1: 2.773 D_real: 0.051 D_fake: 0.512 \n",
            "(epoch: 16, iters: 116, time: 0.070, data: 0.105) G_GAN: 1.598 G_L1: 2.342 D_real: 0.271 D_fake: 0.608 \n",
            "(epoch: 16, iters: 216, time: 0.088, data: 0.000) G_GAN: 1.090 G_L1: 0.740 D_real: 0.101 D_fake: 1.821 \n",
            "(epoch: 16, iters: 316, time: 0.103, data: 0.007) G_GAN: 1.958 G_L1: 8.614 D_real: 0.258 D_fake: 0.780 \n",
            "(epoch: 16, iters: 416, time: 0.075, data: 0.012) G_GAN: 0.740 G_L1: 0.019 D_real: 0.698 D_fake: 0.695 \n",
            "(epoch: 16, iters: 516, time: 0.099, data: 0.000) G_GAN: 3.140 G_L1: 13.635 D_real: 0.006 D_fake: 0.161 \n",
            "(epoch: 16, iters: 616, time: 0.104, data: 0.151) G_GAN: 2.055 G_L1: 8.253 D_real: 0.179 D_fake: 0.655 \n",
            "(epoch: 16, iters: 716, time: 0.101, data: 0.028) G_GAN: 2.817 G_L1: 4.885 D_real: 0.073 D_fake: 0.283 \n",
            "(epoch: 16, iters: 816, time: 0.087, data: 0.002) G_GAN: 2.059 G_L1: 3.119 D_real: 0.135 D_fake: 0.207 \n",
            "End of epoch 16 / 200 \t Time Taken: 111 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 17, iters: 2, time: 0.078, data: 0.000) G_GAN: 1.473 G_L1: 4.818 D_real: 0.478 D_fake: 0.370 \n",
            "(epoch: 17, iters: 102, time: 0.088, data: 0.005) G_GAN: 0.649 G_L1: 0.009 D_real: 0.571 D_fake: 0.842 \n",
            "(epoch: 17, iters: 202, time: 0.120, data: 0.000) G_GAN: 1.771 G_L1: 5.646 D_real: 1.236 D_fake: 0.040 \n",
            "(epoch: 17, iters: 302, time: 0.095, data: 0.003) G_GAN: 1.559 G_L1: 3.791 D_real: 0.023 D_fake: 1.760 \n",
            "(epoch: 17, iters: 402, time: 0.080, data: 0.094) G_GAN: 1.855 G_L1: 4.558 D_real: 0.068 D_fake: 0.813 \n",
            "(epoch: 17, iters: 502, time: 0.069, data: 0.000) G_GAN: 1.915 G_L1: 11.438 D_real: 0.093 D_fake: 0.169 \n",
            "(epoch: 17, iters: 602, time: 0.094, data: 0.000) G_GAN: 1.802 G_L1: 3.459 D_real: 0.541 D_fake: 0.085 \n",
            "(epoch: 17, iters: 702, time: 0.071, data: 0.012) G_GAN: 1.541 G_L1: 5.209 D_real: 0.205 D_fake: 0.391 \n",
            "(epoch: 17, iters: 802, time: 0.100, data: 0.000) G_GAN: 1.098 G_L1: 5.255 D_real: 0.882 D_fake: 0.167 \n",
            "(epoch: 17, iters: 902, time: 0.093, data: 0.000) G_GAN: 1.031 G_L1: 0.525 D_real: 0.926 D_fake: 0.370 \n",
            "End of epoch 17 / 200 \t Time Taken: 112 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 18, iters: 88, time: 0.085, data: 0.000) G_GAN: 0.597 G_L1: 0.008 D_real: 0.649 D_fake: 0.754 \n",
            "(epoch: 18, iters: 188, time: 0.076, data: 0.078) G_GAN: 0.571 G_L1: 3.568 D_real: 1.559 D_fake: 0.184 \n",
            "(epoch: 18, iters: 288, time: 0.079, data: 0.049) G_GAN: 2.436 G_L1: 6.123 D_real: 0.047 D_fake: 0.280 \n",
            "(epoch: 18, iters: 388, time: 0.097, data: 0.000) G_GAN: 2.319 G_L1: 5.214 D_real: 0.207 D_fake: 0.138 \n",
            "(epoch: 18, iters: 488, time: 0.090, data: 0.100) G_GAN: 2.121 G_L1: 6.105 D_real: 0.043 D_fake: 0.283 \n",
            "(epoch: 18, iters: 588, time: 0.100, data: 0.133) G_GAN: 0.661 G_L1: 0.038 D_real: 0.574 D_fake: 0.772 \n",
            "(epoch: 18, iters: 688, time: 0.100, data: 0.019) G_GAN: 0.657 G_L1: 0.008 D_real: 0.704 D_fake: 0.690 \n",
            "(epoch: 18, iters: 788, time: 0.075, data: 0.122) G_GAN: 1.452 G_L1: 2.031 D_real: 0.063 D_fake: 1.201 \n",
            "(epoch: 18, iters: 888, time: 0.095, data: 0.245) G_GAN: 1.572 G_L1: 2.748 D_real: 0.707 D_fake: 0.102 \n",
            "End of epoch 18 / 200 \t Time Taken: 112 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 19, iters: 74, time: 0.101, data: 0.004) G_GAN: 0.776 G_L1: 0.051 D_real: 0.720 D_fake: 0.635 \n",
            "(epoch: 19, iters: 174, time: 0.077, data: 0.121) G_GAN: 0.625 G_L1: 0.013 D_real: 0.622 D_fake: 0.783 \n",
            "(epoch: 19, iters: 274, time: 0.101, data: 0.165) G_GAN: 3.064 G_L1: 4.424 D_real: 0.012 D_fake: 0.873 \n",
            "(epoch: 19, iters: 374, time: 0.068, data: 0.143) G_GAN: 1.117 G_L1: 0.124 D_real: 0.713 D_fake: 0.384 \n",
            "(epoch: 19, iters: 474, time: 0.072, data: 0.136) G_GAN: 0.977 G_L1: 2.350 D_real: 0.738 D_fake: 0.237 \n",
            "(epoch: 19, iters: 574, time: 0.092, data: 0.151) G_GAN: 1.447 G_L1: 3.554 D_real: 0.182 D_fake: 0.220 \n",
            "(epoch: 19, iters: 674, time: 0.097, data: 0.000) G_GAN: 1.545 G_L1: 2.610 D_real: 0.182 D_fake: 0.720 \n",
            "(epoch: 19, iters: 774, time: 0.078, data: 0.080) G_GAN: 0.907 G_L1: 0.849 D_real: 0.560 D_fake: 0.592 \n",
            "(epoch: 19, iters: 874, time: 0.079, data: 0.166) G_GAN: 1.029 G_L1: 1.356 D_real: 0.523 D_fake: 0.376 \n",
            "End of epoch 19 / 200 \t Time Taken: 114 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 20, iters: 60, time: 0.093, data: 0.239) G_GAN: 0.636 G_L1: 0.009 D_real: 0.597 D_fake: 0.820 \n",
            "(epoch: 20, iters: 160, time: 0.081, data: 0.000) G_GAN: 0.714 G_L1: 0.015 D_real: 0.617 D_fake: 0.779 \n",
            "(epoch: 20, iters: 260, time: 0.082, data: 0.000) G_GAN: 0.802 G_L1: 0.075 D_real: 0.756 D_fake: 0.624 \n",
            "(epoch: 20, iters: 360, time: 0.102, data: 0.000) G_GAN: 0.587 G_L1: 0.011 D_real: 0.544 D_fake: 0.877 \n",
            "(epoch: 20, iters: 460, time: 0.099, data: 0.003) G_GAN: 0.773 G_L1: 0.009 D_real: 0.771 D_fake: 0.642 \n",
            "(epoch: 20, iters: 560, time: 0.099, data: 0.000) G_GAN: 1.269 G_L1: 0.115 D_real: 0.819 D_fake: 0.325 \n",
            "(epoch: 20, iters: 660, time: 0.079, data: 0.000) G_GAN: 0.699 G_L1: 1.500 D_real: 0.712 D_fake: 0.213 \n",
            "(epoch: 20, iters: 760, time: 0.093, data: 0.000) G_GAN: 2.236 G_L1: 2.319 D_real: 0.231 D_fake: 0.266 \n",
            "(epoch: 20, iters: 860, time: 0.088, data: 0.002) G_GAN: 0.880 G_L1: 0.647 D_real: 0.299 D_fake: 0.705 \n",
            "saving the latest model (epoch 20, total_iters 10000)\n",
            "End of epoch 20 / 200 \t Time Taken: 115 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 21, iters: 46, time: 0.101, data: 0.006) G_GAN: 0.787 G_L1: 0.011 D_real: 0.876 D_fake: 0.570 \n",
            "(epoch: 21, iters: 146, time: 0.085, data: 0.000) G_GAN: 1.364 G_L1: 3.022 D_real: 0.075 D_fake: 1.145 \n",
            "(epoch: 21, iters: 246, time: 0.104, data: 0.000) G_GAN: 2.032 G_L1: 2.755 D_real: 0.022 D_fake: 0.153 \n",
            "(epoch: 21, iters: 346, time: 0.090, data: 0.005) G_GAN: 3.604 G_L1: 8.842 D_real: 0.037 D_fake: 0.502 \n",
            "(epoch: 21, iters: 446, time: 0.098, data: 0.000) G_GAN: 2.915 G_L1: 1.917 D_real: 0.092 D_fake: 0.067 \n",
            "(epoch: 21, iters: 546, time: 0.098, data: 0.000) G_GAN: 2.210 G_L1: 6.333 D_real: 0.039 D_fake: 0.074 \n",
            "(epoch: 21, iters: 646, time: 0.098, data: 0.090) G_GAN: 2.176 G_L1: 2.754 D_real: 0.175 D_fake: 0.269 \n",
            "(epoch: 21, iters: 746, time: 0.079, data: 0.160) G_GAN: 1.481 G_L1: 1.558 D_real: 0.013 D_fake: 1.618 \n",
            "(epoch: 21, iters: 846, time: 0.086, data: 0.063) G_GAN: 2.155 G_L1: 6.992 D_real: 0.189 D_fake: 0.104 \n",
            "End of epoch 21 / 200 \t Time Taken: 115 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 22, iters: 32, time: 0.085, data: 0.144) G_GAN: 2.817 G_L1: 4.946 D_real: 0.118 D_fake: 0.932 \n",
            "(epoch: 22, iters: 132, time: 0.089, data: 0.194) G_GAN: 0.721 G_L1: 0.005 D_real: 0.750 D_fake: 0.646 \n",
            "(epoch: 22, iters: 232, time: 0.100, data: 0.000) G_GAN: 0.680 G_L1: 0.004 D_real: 0.675 D_fake: 0.716 \n",
            "(epoch: 22, iters: 332, time: 0.075, data: 0.000) G_GAN: 1.183 G_L1: 0.005 D_real: 0.706 D_fake: 0.700 \n",
            "(epoch: 22, iters: 432, time: 0.095, data: 0.001) G_GAN: 0.685 G_L1: 0.006 D_real: 0.664 D_fake: 0.738 \n",
            "(epoch: 22, iters: 532, time: 0.095, data: 0.088) G_GAN: 1.237 G_L1: 0.911 D_real: 0.513 D_fake: 0.485 \n",
            "(epoch: 22, iters: 632, time: 0.103, data: 0.082) G_GAN: 2.788 G_L1: 3.997 D_real: 0.351 D_fake: 0.038 \n",
            "(epoch: 22, iters: 732, time: 0.101, data: 0.115) G_GAN: 2.846 G_L1: 3.651 D_real: 0.049 D_fake: 0.117 \n",
            "(epoch: 22, iters: 832, time: 0.075, data: 0.128) G_GAN: 0.645 G_L1: 0.005 D_real: 0.572 D_fake: 0.844 \n",
            "End of epoch 22 / 200 \t Time Taken: 114 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 23, iters: 18, time: 0.069, data: 0.121) G_GAN: 1.484 G_L1: 4.488 D_real: 0.230 D_fake: 0.178 \n",
            "(epoch: 23, iters: 118, time: 0.091, data: 0.000) G_GAN: 2.662 G_L1: 4.571 D_real: 0.075 D_fake: 0.095 \n",
            "(epoch: 23, iters: 218, time: 0.083, data: 0.000) G_GAN: 1.678 G_L1: 2.392 D_real: 1.471 D_fake: 0.053 \n",
            "(epoch: 23, iters: 318, time: 0.079, data: 0.000) G_GAN: 2.544 G_L1: 11.208 D_real: 0.003 D_fake: 0.302 \n",
            "(epoch: 23, iters: 418, time: 0.076, data: 0.003) G_GAN: 0.992 G_L1: 0.018 D_real: 0.732 D_fake: 0.507 \n",
            "(epoch: 23, iters: 518, time: 0.078, data: 0.000) G_GAN: 3.036 G_L1: 5.989 D_real: 0.040 D_fake: 0.052 \n",
            "(epoch: 23, iters: 618, time: 0.081, data: 0.161) G_GAN: 1.518 G_L1: 4.285 D_real: 0.673 D_fake: 0.054 \n",
            "(epoch: 23, iters: 718, time: 0.097, data: 0.223) G_GAN: 0.807 G_L1: 0.017 D_real: 1.034 D_fake: 0.493 \n",
            "(epoch: 23, iters: 818, time: 0.117, data: 0.000) G_GAN: 0.728 G_L1: 0.008 D_real: 0.694 D_fake: 0.688 \n",
            "End of epoch 23 / 200 \t Time Taken: 114 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 24, iters: 4, time: 0.100, data: 0.000) G_GAN: 0.737 G_L1: 0.003 D_real: 0.701 D_fake: 0.708 \n",
            "(epoch: 24, iters: 104, time: 0.056, data: 0.042) G_GAN: 0.417 G_L1: 0.010 D_real: 0.347 D_fake: 1.249 \n",
            "(epoch: 24, iters: 204, time: 0.088, data: 0.000) G_GAN: 2.906 G_L1: 0.511 D_real: 0.360 D_fake: 0.060 \n",
            "(epoch: 24, iters: 304, time: 0.080, data: 0.003) G_GAN: 2.427 G_L1: 9.794 D_real: 0.123 D_fake: 0.181 \n",
            "(epoch: 24, iters: 404, time: 0.065, data: 0.000) G_GAN: 2.935 G_L1: 0.835 D_real: 0.043 D_fake: 0.105 \n",
            "(epoch: 24, iters: 504, time: 0.072, data: 0.000) G_GAN: 0.772 G_L1: 0.011 D_real: 0.670 D_fake: 0.721 \n",
            "(epoch: 24, iters: 604, time: 0.095, data: 0.009) G_GAN: 4.751 G_L1: 4.813 D_real: 0.037 D_fake: 0.014 \n",
            "(epoch: 24, iters: 704, time: 0.087, data: 0.000) G_GAN: 0.667 G_L1: 0.003 D_real: 0.653 D_fake: 0.747 \n",
            "(epoch: 24, iters: 804, time: 0.115, data: 0.000) G_GAN: 0.621 G_L1: 0.004 D_real: 0.577 D_fake: 0.881 \n",
            "(epoch: 24, iters: 904, time: 0.073, data: 0.000) G_GAN: 0.982 G_L1: 0.824 D_real: 0.336 D_fake: 1.005 \n",
            "End of epoch 24 / 200 \t Time Taken: 115 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 25, iters: 90, time: 0.077, data: 0.000) G_GAN: 0.689 G_L1: 0.003 D_real: 0.676 D_fake: 0.716 \n",
            "(epoch: 25, iters: 190, time: 0.099, data: 0.000) G_GAN: 3.564 G_L1: 5.619 D_real: 0.053 D_fake: 0.063 \n",
            "(epoch: 25, iters: 290, time: 0.098, data: 0.000) G_GAN: 2.378 G_L1: 1.454 D_real: 0.041 D_fake: 0.261 \n",
            "(epoch: 25, iters: 390, time: 0.077, data: 0.000) G_GAN: 0.654 G_L1: 0.007 D_real: 0.631 D_fake: 0.776 \n",
            "(epoch: 25, iters: 490, time: 0.107, data: 0.000) G_GAN: 4.806 G_L1: 8.660 D_real: 0.074 D_fake: 0.012 \n",
            "(epoch: 25, iters: 590, time: 0.080, data: 0.001) G_GAN: 3.836 G_L1: 3.559 D_real: 0.283 D_fake: 0.014 \n",
            "(epoch: 25, iters: 690, time: 0.083, data: 0.000) G_GAN: 2.227 G_L1: 4.203 D_real: 0.043 D_fake: 0.126 \n",
            "(epoch: 25, iters: 790, time: 0.094, data: 0.000) G_GAN: 0.719 G_L1: 0.006 D_real: 0.766 D_fake: 0.643 \n",
            "(epoch: 25, iters: 890, time: 0.080, data: 0.001) G_GAN: 2.956 G_L1: 3.252 D_real: 0.049 D_fake: 0.091 \n",
            "End of epoch 25 / 200 \t Time Taken: 115 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 26, iters: 76, time: 0.102, data: 0.000) G_GAN: 3.350 G_L1: 6.006 D_real: 0.066 D_fake: 0.023 \n",
            "(epoch: 26, iters: 176, time: 0.072, data: 0.174) G_GAN: 0.672 G_L1: 0.012 D_real: 0.563 D_fake: 0.905 \n",
            "(epoch: 26, iters: 276, time: 0.104, data: 0.036) G_GAN: 2.326 G_L1: 4.139 D_real: 0.232 D_fake: 0.052 \n",
            "(epoch: 26, iters: 376, time: 0.104, data: 0.198) G_GAN: 2.192 G_L1: 1.168 D_real: 0.427 D_fake: 0.048 \n",
            "saving the latest model (epoch 26, total_iters 15000)\n",
            "(epoch: 26, iters: 476, time: 0.081, data: 0.005) G_GAN: 0.691 G_L1: 0.002 D_real: 0.773 D_fake: 0.643 \n",
            "(epoch: 26, iters: 576, time: 0.091, data: 0.000) G_GAN: 1.054 G_L1: 1.156 D_real: 0.395 D_fake: 0.603 \n",
            "(epoch: 26, iters: 676, time: 0.114, data: 0.186) G_GAN: 0.841 G_L1: 0.258 D_real: 0.056 D_fake: 1.935 \n",
            "(epoch: 26, iters: 776, time: 0.095, data: 0.144) G_GAN: 1.951 G_L1: 1.068 D_real: 0.389 D_fake: 0.274 \n",
            "(epoch: 26, iters: 876, time: 0.086, data: 0.198) G_GAN: 4.440 G_L1: 1.330 D_real: 1.052 D_fake: 0.003 \n",
            "End of epoch 26 / 200 \t Time Taken: 118 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 27, iters: 62, time: 0.096, data: 0.200) G_GAN: 3.617 G_L1: 12.381 D_real: 0.005 D_fake: 0.147 \n",
            "(epoch: 27, iters: 162, time: 0.089, data: 0.011) G_GAN: 4.382 G_L1: 3.752 D_real: 0.232 D_fake: 0.007 \n",
            "(epoch: 27, iters: 262, time: 0.112, data: 0.001) G_GAN: 4.127 G_L1: 4.028 D_real: 0.111 D_fake: 0.020 \n",
            "(epoch: 27, iters: 362, time: 0.094, data: 0.000) G_GAN: 2.391 G_L1: 0.858 D_real: 0.426 D_fake: 0.310 \n",
            "(epoch: 27, iters: 462, time: 0.074, data: 0.000) G_GAN: 2.856 G_L1: 4.277 D_real: 0.061 D_fake: 0.385 \n",
            "(epoch: 27, iters: 562, time: 0.099, data: 0.000) G_GAN: 3.943 G_L1: 3.175 D_real: 0.126 D_fake: 0.094 \n",
            "(epoch: 27, iters: 662, time: 0.089, data: 0.000) G_GAN: 2.626 G_L1: 1.798 D_real: 0.114 D_fake: 0.143 \n",
            "(epoch: 27, iters: 762, time: 0.078, data: 0.000) G_GAN: 3.419 G_L1: 5.911 D_real: 0.040 D_fake: 0.091 \n",
            "(epoch: 27, iters: 862, time: 0.077, data: 0.000) G_GAN: 2.925 G_L1: 2.104 D_real: 0.063 D_fake: 0.059 \n",
            "End of epoch 27 / 200 \t Time Taken: 115 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 28, iters: 48, time: 0.086, data: 0.000) G_GAN: 0.599 G_L1: 0.002 D_real: 0.554 D_fake: 0.869 \n",
            "(epoch: 28, iters: 148, time: 0.079, data: 0.095) G_GAN: 4.747 G_L1: 9.467 D_real: 0.040 D_fake: 0.016 \n",
            "(epoch: 28, iters: 248, time: 0.093, data: 0.177) G_GAN: 5.584 G_L1: 2.919 D_real: 0.244 D_fake: 0.003 \n",
            "(epoch: 28, iters: 348, time: 0.078, data: 0.129) G_GAN: 2.795 G_L1: 3.423 D_real: 0.167 D_fake: 0.084 \n",
            "(epoch: 28, iters: 448, time: 0.091, data: 0.002) G_GAN: 1.001 G_L1: 0.015 D_real: 0.668 D_fake: 0.479 \n",
            "(epoch: 28, iters: 548, time: 0.071, data: 0.000) G_GAN: 4.076 G_L1: 5.231 D_real: 0.418 D_fake: 0.015 \n",
            "(epoch: 28, iters: 648, time: 0.083, data: 0.000) G_GAN: 3.814 G_L1: 3.119 D_real: 0.770 D_fake: 0.030 \n",
            "(epoch: 28, iters: 748, time: 0.081, data: 0.000) G_GAN: 4.459 G_L1: 5.025 D_real: 0.002 D_fake: 0.024 \n",
            "(epoch: 28, iters: 848, time: 0.078, data: 0.000) G_GAN: 4.974 G_L1: 6.573 D_real: 0.006 D_fake: 0.012 \n",
            "End of epoch 28 / 200 \t Time Taken: 116 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 29, iters: 34, time: 0.100, data: 0.000) G_GAN: 2.727 G_L1: 3.747 D_real: 0.019 D_fake: 0.212 \n",
            "(epoch: 29, iters: 134, time: 0.085, data: 0.000) G_GAN: 3.036 G_L1: 2.038 D_real: 0.146 D_fake: 0.075 \n",
            "(epoch: 29, iters: 234, time: 0.077, data: 0.000) G_GAN: 4.859 G_L1: 0.984 D_real: 0.031 D_fake: 0.635 \n",
            "(epoch: 29, iters: 334, time: 0.095, data: 0.000) G_GAN: 2.031 G_L1: 1.206 D_real: 0.899 D_fake: 0.036 \n",
            "(epoch: 29, iters: 434, time: 0.101, data: 0.000) G_GAN: 1.541 G_L1: 0.648 D_real: 0.128 D_fake: 1.715 \n",
            "(epoch: 29, iters: 534, time: 0.080, data: 0.000) G_GAN: 3.668 G_L1: 2.172 D_real: 0.099 D_fake: 0.034 \n",
            "(epoch: 29, iters: 634, time: 0.099, data: 0.000) G_GAN: 3.011 G_L1: 3.155 D_real: 0.092 D_fake: 0.060 \n",
            "(epoch: 29, iters: 734, time: 0.077, data: 0.000) G_GAN: 2.818 G_L1: 9.308 D_real: 0.002 D_fake: 0.281 \n",
            "(epoch: 29, iters: 834, time: 0.086, data: 0.005) G_GAN: 3.620 G_L1: 1.969 D_real: 0.130 D_fake: 0.033 \n",
            "End of epoch 29 / 200 \t Time Taken: 116 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 30, iters: 20, time: 0.078, data: 0.001) G_GAN: 2.258 G_L1: 0.813 D_real: 0.522 D_fake: 0.416 \n",
            "(epoch: 30, iters: 120, time: 0.068, data: 0.156) G_GAN: 3.223 G_L1: 0.776 D_real: 0.207 D_fake: 1.423 \n",
            "(epoch: 30, iters: 220, time: 0.102, data: 0.000) G_GAN: 4.659 G_L1: 1.332 D_real: 0.067 D_fake: 1.612 \n",
            "(epoch: 30, iters: 320, time: 0.108, data: 0.136) G_GAN: 1.978 G_L1: 5.325 D_real: 0.109 D_fake: 0.642 \n",
            "(epoch: 30, iters: 420, time: 0.079, data: 0.009) G_GAN: 2.737 G_L1: 0.442 D_real: 0.085 D_fake: 0.148 \n",
            "(epoch: 30, iters: 520, time: 0.052, data: 0.205) G_GAN: 1.003 G_L1: 0.001 D_real: 1.318 D_fake: 0.325 \n",
            "(epoch: 30, iters: 620, time: 0.089, data: 0.000) G_GAN: 0.967 G_L1: 0.406 D_real: 0.199 D_fake: 2.120 \n",
            "(epoch: 30, iters: 720, time: 0.083, data: 0.104) G_GAN: 0.678 G_L1: 0.001 D_real: 0.686 D_fake: 0.726 \n",
            "(epoch: 30, iters: 820, time: 0.080, data: 0.004) G_GAN: 0.546 G_L1: 0.001 D_real: 0.484 D_fake: 0.981 \n",
            "End of epoch 30 / 200 \t Time Taken: 117 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 31, iters: 6, time: 0.095, data: 0.225) G_GAN: 1.372 G_L1: 1.235 D_real: 0.422 D_fake: 0.780 \n",
            "(epoch: 31, iters: 106, time: 0.070, data: 0.005) G_GAN: 0.670 G_L1: 0.001 D_real: 0.472 D_fake: 1.092 \n",
            "(epoch: 31, iters: 206, time: 0.076, data: 0.014) G_GAN: 4.360 G_L1: 7.099 D_real: 0.098 D_fake: 0.015 \n",
            "(epoch: 31, iters: 306, time: 0.086, data: 0.000) G_GAN: 5.204 G_L1: 2.689 D_real: 0.103 D_fake: 0.008 \n",
            "(epoch: 31, iters: 406, time: 0.093, data: 0.000) G_GAN: 2.418 G_L1: 0.694 D_real: 0.233 D_fake: 0.132 \n",
            "(epoch: 31, iters: 506, time: 0.099, data: 0.002) G_GAN: 3.612 G_L1: 3.844 D_real: 0.018 D_fake: 0.033 \n",
            "(epoch: 31, iters: 606, time: 0.081, data: 0.012) G_GAN: 0.781 G_L1: 0.002 D_real: 0.802 D_fake: 0.612 \n",
            "(epoch: 31, iters: 706, time: 0.073, data: 0.102) G_GAN: 0.671 G_L1: 0.003 D_real: 0.669 D_fake: 0.745 \n",
            "(epoch: 31, iters: 806, time: 0.062, data: 0.136) G_GAN: 3.969 G_L1: 2.992 D_real: 0.012 D_fake: 2.449 \n",
            "saving the latest model (epoch 31, total_iters 20000)\n",
            "(epoch: 31, iters: 906, time: 0.074, data: 0.000) G_GAN: 5.052 G_L1: 7.622 D_real: 0.656 D_fake: 0.002 \n",
            "End of epoch 31 / 200 \t Time Taken: 117 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 32, iters: 92, time: 0.103, data: 0.099) G_GAN: 4.250 G_L1: 6.246 D_real: 0.020 D_fake: 0.023 \n",
            "(epoch: 32, iters: 192, time: 0.081, data: 0.118) G_GAN: 0.701 G_L1: 0.002 D_real: 0.750 D_fake: 0.662 \n",
            "(epoch: 32, iters: 292, time: 0.101, data: 0.074) G_GAN: 3.734 G_L1: 3.813 D_real: 0.006 D_fake: 0.049 \n",
            "(epoch: 32, iters: 392, time: 0.102, data: 0.003) G_GAN: 0.635 G_L1: 0.001 D_real: 0.538 D_fake: 0.891 \n",
            "(epoch: 32, iters: 492, time: 0.077, data: 0.000) G_GAN: 3.988 G_L1: 2.508 D_real: 1.463 D_fake: 0.011 \n",
            "(epoch: 32, iters: 592, time: 0.085, data: 0.000) G_GAN: 2.760 G_L1: 5.392 D_real: 0.265 D_fake: 0.035 \n",
            "(epoch: 32, iters: 692, time: 0.086, data: 0.000) G_GAN: 4.166 G_L1: 3.648 D_real: 0.214 D_fake: 0.022 \n",
            "(epoch: 32, iters: 792, time: 0.059, data: 0.001) G_GAN: 4.794 G_L1: 2.539 D_real: 0.095 D_fake: 0.030 \n",
            "(epoch: 32, iters: 892, time: 0.083, data: 0.000) G_GAN: 3.745 G_L1: 2.316 D_real: 0.030 D_fake: 2.551 \n",
            "End of epoch 32 / 200 \t Time Taken: 114 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 33, iters: 78, time: 0.071, data: 0.000) G_GAN: 4.066 G_L1: 6.451 D_real: 0.003 D_fake: 1.283 \n",
            "(epoch: 33, iters: 178, time: 0.078, data: 0.001) G_GAN: 5.394 G_L1: 4.326 D_real: 0.013 D_fake: 0.016 \n",
            "(epoch: 33, iters: 278, time: 0.071, data: 0.000) G_GAN: 1.791 G_L1: 0.896 D_real: 0.162 D_fake: 1.015 \n",
            "(epoch: 33, iters: 378, time: 0.083, data: 0.000) G_GAN: 4.035 G_L1: 7.310 D_real: 0.009 D_fake: 0.041 \n",
            "(epoch: 33, iters: 478, time: 0.056, data: 0.000) G_GAN: 0.718 G_L1: 0.001 D_real: 0.784 D_fake: 0.647 \n",
            "(epoch: 33, iters: 578, time: 0.120, data: 0.000) G_GAN: 3.905 G_L1: 4.241 D_real: 0.002 D_fake: 0.843 \n",
            "(epoch: 33, iters: 678, time: 0.067, data: 0.000) G_GAN: 6.047 G_L1: 3.896 D_real: 0.035 D_fake: 0.005 \n",
            "(epoch: 33, iters: 778, time: 0.094, data: 0.000) G_GAN: 3.333 G_L1: 2.591 D_real: 0.120 D_fake: 0.171 \n",
            "(epoch: 33, iters: 878, time: 0.085, data: 0.000) G_GAN: 3.069 G_L1: 3.219 D_real: 0.062 D_fake: 1.037 \n",
            "End of epoch 33 / 200 \t Time Taken: 112 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 34, iters: 64, time: 0.106, data: 0.000) G_GAN: 0.705 G_L1: 0.002 D_real: 0.683 D_fake: 0.709 \n",
            "(epoch: 34, iters: 164, time: 0.088, data: 0.000) G_GAN: 0.734 G_L1: 0.015 D_real: 0.592 D_fake: 0.684 \n",
            "(epoch: 34, iters: 264, time: 0.097, data: 0.230) G_GAN: 3.617 G_L1: 4.066 D_real: 0.002 D_fake: 0.529 \n",
            "(epoch: 34, iters: 364, time: 0.095, data: 0.188) G_GAN: 0.616 G_L1: 0.069 D_real: 0.688 D_fake: 0.791 \n",
            "(epoch: 34, iters: 464, time: 0.103, data: 0.145) G_GAN: 0.737 G_L1: 0.003 D_real: 0.804 D_fake: 0.620 \n",
            "(epoch: 34, iters: 564, time: 0.086, data: 0.232) G_GAN: 3.260 G_L1: 7.615 D_real: 0.011 D_fake: 0.361 \n",
            "(epoch: 34, iters: 664, time: 0.071, data: 0.211) G_GAN: 2.582 G_L1: 3.859 D_real: 0.163 D_fake: 0.374 \n",
            "(epoch: 34, iters: 764, time: 0.061, data: 0.263) G_GAN: 0.645 G_L1: 0.001 D_real: 0.655 D_fake: 0.742 \n",
            "(epoch: 34, iters: 864, time: 0.117, data: 0.112) G_GAN: 1.420 G_L1: 0.996 D_real: 0.258 D_fake: 1.302 \n",
            "End of epoch 34 / 200 \t Time Taken: 112 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 35, iters: 50, time: 0.083, data: 0.149) G_GAN: 2.528 G_L1: 1.189 D_real: 0.098 D_fake: 0.410 \n",
            "(epoch: 35, iters: 150, time: 0.107, data: 0.193) G_GAN: 4.764 G_L1: 6.491 D_real: 0.005 D_fake: 0.017 \n",
            "(epoch: 35, iters: 250, time: 0.100, data: 0.000) G_GAN: 4.762 G_L1: 7.084 D_real: 0.003 D_fake: 0.021 \n",
            "(epoch: 35, iters: 350, time: 0.109, data: 0.000) G_GAN: 0.665 G_L1: 0.002 D_real: 0.565 D_fake: 0.851 \n",
            "(epoch: 35, iters: 450, time: 0.097, data: 0.004) G_GAN: 1.483 G_L1: 2.339 D_real: 0.358 D_fake: 0.127 \n",
            "(epoch: 35, iters: 550, time: 0.099, data: 0.000) G_GAN: 5.289 G_L1: 7.249 D_real: 0.005 D_fake: 0.008 \n",
            "(epoch: 35, iters: 650, time: 0.079, data: 0.001) G_GAN: 5.505 G_L1: 6.708 D_real: 0.013 D_fake: 0.010 \n",
            "(epoch: 35, iters: 750, time: 0.108, data: 0.000) G_GAN: 0.745 G_L1: 0.010 D_real: 0.789 D_fake: 0.602 \n",
            "(epoch: 35, iters: 850, time: 0.091, data: 0.000) G_GAN: 3.728 G_L1: 2.257 D_real: 0.011 D_fake: 0.043 \n",
            "End of epoch 35 / 200 \t Time Taken: 112 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 36, iters: 36, time: 0.059, data: 0.000) G_GAN: 6.137 G_L1: 4.001 D_real: 0.012 D_fake: 0.004 \n",
            "(epoch: 36, iters: 136, time: 0.080, data: 0.000) G_GAN: 4.040 G_L1: 4.469 D_real: 0.016 D_fake: 0.025 \n",
            "(epoch: 36, iters: 236, time: 0.077, data: 0.000) G_GAN: 3.713 G_L1: 1.309 D_real: 0.074 D_fake: 0.027 \n",
            "(epoch: 36, iters: 336, time: 0.072, data: 0.000) G_GAN: 1.749 G_L1: 0.931 D_real: 0.350 D_fake: 0.982 \n",
            "(epoch: 36, iters: 436, time: 0.097, data: 0.000) G_GAN: 3.386 G_L1: 2.814 D_real: 0.272 D_fake: 0.019 \n",
            "(epoch: 36, iters: 536, time: 0.097, data: 0.000) G_GAN: 0.644 G_L1: 0.001 D_real: 0.627 D_fake: 0.776 \n",
            "(epoch: 36, iters: 636, time: 0.093, data: 0.001) G_GAN: 0.759 G_L1: 0.001 D_real: 0.745 D_fake: 0.659 \n",
            "(epoch: 36, iters: 736, time: 0.085, data: 0.001) G_GAN: 0.791 G_L1: 0.001 D_real: 0.766 D_fake: 0.638 \n",
            "(epoch: 36, iters: 836, time: 0.071, data: 0.000) G_GAN: 2.296 G_L1: 1.995 D_real: 0.575 D_fake: 0.023 \n",
            "End of epoch 36 / 200 \t Time Taken: 111 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 37, iters: 22, time: 0.090, data: 0.000) G_GAN: 4.483 G_L1: 2.070 D_real: 0.006 D_fake: 0.020 \n",
            "(epoch: 37, iters: 122, time: 0.109, data: 0.000) G_GAN: 0.812 G_L1: 0.017 D_real: 0.746 D_fake: 0.597 \n",
            "(epoch: 37, iters: 222, time: 0.095, data: 0.000) G_GAN: 6.716 G_L1: 4.646 D_real: 0.003 D_fake: 0.002 \n",
            "(epoch: 37, iters: 322, time: 0.052, data: 0.000) G_GAN: 9.199 G_L1: 1.851 D_real: 0.066 D_fake: 0.000 \n",
            "saving the latest model (epoch 37, total_iters 25000)\n",
            "(epoch: 37, iters: 422, time: 0.105, data: 0.000) G_GAN: 2.591 G_L1: 0.985 D_real: 0.015 D_fake: 0.265 \n",
            "(epoch: 37, iters: 522, time: 0.083, data: 0.000) G_GAN: 6.718 G_L1: 3.805 D_real: 0.025 D_fake: 0.002 \n",
            "(epoch: 37, iters: 622, time: 0.085, data: 0.104) G_GAN: 4.105 G_L1: 4.216 D_real: 0.483 D_fake: 0.009 \n",
            "(epoch: 37, iters: 722, time: 0.072, data: 0.121) G_GAN: 1.743 G_L1: 1.328 D_real: 0.422 D_fake: 0.096 \n",
            "(epoch: 37, iters: 822, time: 0.101, data: 0.107) G_GAN: 4.472 G_L1: 2.903 D_real: 0.082 D_fake: 0.013 \n",
            "End of epoch 37 / 200 \t Time Taken: 114 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 38, iters: 8, time: 0.076, data: 0.002) G_GAN: 1.992 G_L1: 2.953 D_real: 0.011 D_fake: 0.111 \n",
            "(epoch: 38, iters: 108, time: 0.056, data: 0.182) G_GAN: 3.078 G_L1: 3.437 D_real: 0.018 D_fake: 0.120 \n",
            "(epoch: 38, iters: 208, time: 0.098, data: 0.000) G_GAN: 3.731 G_L1: 6.582 D_real: 0.086 D_fake: 0.044 \n",
            "(epoch: 38, iters: 308, time: 0.093, data: 0.000) G_GAN: 3.527 G_L1: 2.623 D_real: 0.050 D_fake: 0.016 \n",
            "(epoch: 38, iters: 408, time: 0.087, data: 0.002) G_GAN: 4.423 G_L1: 1.939 D_real: 0.005 D_fake: 0.022 \n",
            "(epoch: 38, iters: 508, time: 0.073, data: 0.000) G_GAN: 0.562 G_L1: 0.001 D_real: 0.550 D_fake: 0.874 \n",
            "(epoch: 38, iters: 608, time: 0.075, data: 0.000) G_GAN: 2.784 G_L1: 10.442 D_real: 0.002 D_fake: 0.088 \n",
            "(epoch: 38, iters: 708, time: 0.072, data: 0.000) G_GAN: 6.673 G_L1: 4.747 D_real: 0.007 D_fake: 0.005 \n",
            "(epoch: 38, iters: 808, time: 0.057, data: 0.005) G_GAN: 2.954 G_L1: 0.636 D_real: 0.189 D_fake: 0.064 \n",
            "(epoch: 38, iters: 908, time: 0.057, data: 0.000) G_GAN: 1.469 G_L1: 3.086 D_real: 0.681 D_fake: 0.057 \n",
            "End of epoch 38 / 200 \t Time Taken: 111 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 39, iters: 94, time: 0.096, data: 0.000) G_GAN: 5.327 G_L1: 6.121 D_real: 0.047 D_fake: 0.007 \n",
            "(epoch: 39, iters: 194, time: 0.089, data: 0.000) G_GAN: 7.109 G_L1: 6.769 D_real: 0.048 D_fake: 0.002 \n",
            "(epoch: 39, iters: 294, time: 0.065, data: 0.002) G_GAN: 0.616 G_L1: 0.001 D_real: 0.564 D_fake: 0.866 \n",
            "(epoch: 39, iters: 394, time: 0.081, data: 0.001) G_GAN: 2.479 G_L1: 1.501 D_real: 0.174 D_fake: 0.308 \n",
            "(epoch: 39, iters: 494, time: 0.111, data: 0.000) G_GAN: 0.398 G_L1: 0.001 D_real: 0.369 D_fake: 1.222 \n",
            "(epoch: 39, iters: 594, time: 0.087, data: 0.000) G_GAN: 0.402 G_L1: 0.166 D_real: 1.820 D_fake: 0.103 \n",
            "(epoch: 39, iters: 694, time: 0.108, data: 0.000) G_GAN: 0.613 G_L1: 0.002 D_real: 0.617 D_fake: 0.780 \n",
            "(epoch: 39, iters: 794, time: 0.072, data: 0.004) G_GAN: 5.848 G_L1: 6.369 D_real: 0.103 D_fake: 0.005 \n",
            "(epoch: 39, iters: 894, time: 0.088, data: 0.000) G_GAN: 0.743 G_L1: 0.001 D_real: 0.811 D_fake: 0.604 \n",
            "End of epoch 39 / 200 \t Time Taken: 111 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 40, iters: 80, time: 0.108, data: 0.000) G_GAN: 0.694 G_L1: 0.001 D_real: 0.726 D_fake: 0.672 \n",
            "(epoch: 40, iters: 180, time: 0.108, data: 0.121) G_GAN: 0.676 G_L1: 0.001 D_real: 0.659 D_fake: 0.734 \n",
            "(epoch: 40, iters: 280, time: 0.096, data: 0.033) G_GAN: 2.959 G_L1: 1.708 D_real: 0.112 D_fake: 0.642 \n",
            "(epoch: 40, iters: 380, time: 0.095, data: 0.170) G_GAN: 0.655 G_L1: 0.001 D_real: 0.607 D_fake: 0.798 \n",
            "(epoch: 40, iters: 480, time: 0.091, data: 0.088) G_GAN: 0.663 G_L1: 0.002 D_real: 0.706 D_fake: 0.710 \n",
            "(epoch: 40, iters: 580, time: 0.104, data: 0.189) G_GAN: 0.669 G_L1: 0.001 D_real: 0.658 D_fake: 0.740 \n",
            "(epoch: 40, iters: 680, time: 0.083, data: 0.162) G_GAN: 7.544 G_L1: 2.913 D_real: 0.103 D_fake: 0.001 \n",
            "(epoch: 40, iters: 780, time: 0.103, data: 0.110) G_GAN: 2.286 G_L1: 0.874 D_real: 0.103 D_fake: 1.199 \n",
            "(epoch: 40, iters: 880, time: 0.086, data: 0.091) G_GAN: 2.928 G_L1: 1.243 D_real: 0.057 D_fake: 0.156 \n",
            "End of epoch 40 / 200 \t Time Taken: 112 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 41, iters: 66, time: 0.094, data: 0.162) G_GAN: 6.318 G_L1: 4.896 D_real: 0.001 D_fake: 0.004 \n",
            "(epoch: 41, iters: 166, time: 0.071, data: 0.002) G_GAN: 4.497 G_L1: 5.369 D_real: 0.014 D_fake: 0.011 \n",
            "(epoch: 41, iters: 266, time: 0.080, data: 0.000) G_GAN: 7.267 G_L1: 2.023 D_real: 0.009 D_fake: 0.001 \n",
            "(epoch: 41, iters: 366, time: 0.062, data: 0.000) G_GAN: 1.735 G_L1: 0.041 D_real: 0.746 D_fake: 0.078 \n",
            "(epoch: 41, iters: 466, time: 0.088, data: 0.000) G_GAN: 0.721 G_L1: 0.002 D_real: 0.763 D_fake: 0.642 \n",
            "(epoch: 41, iters: 566, time: 0.091, data: 0.000) G_GAN: 0.703 G_L1: 0.001 D_real: 0.729 D_fake: 0.667 \n",
            "(epoch: 41, iters: 666, time: 0.095, data: 0.000) G_GAN: 5.707 G_L1: 9.646 D_real: 0.017 D_fake: 0.012 \n",
            "(epoch: 41, iters: 766, time: 0.098, data: 0.000) G_GAN: 3.183 G_L1: 1.490 D_real: 0.005 D_fake: 0.855 \n",
            "(epoch: 41, iters: 866, time: 0.090, data: 0.000) G_GAN: 3.437 G_L1: 3.886 D_real: 0.060 D_fake: 0.157 \n",
            "End of epoch 41 / 200 \t Time Taken: 113 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 42, iters: 52, time: 0.092, data: 0.000) G_GAN: 0.558 G_L1: 0.002 D_real: 0.484 D_fake: 1.002 \n",
            "(epoch: 42, iters: 152, time: 0.099, data: 0.088) G_GAN: 0.661 G_L1: 0.001 D_real: 0.735 D_fake: 0.689 \n",
            "(epoch: 42, iters: 252, time: 0.099, data: 0.111) G_GAN: 4.772 G_L1: 2.382 D_real: 0.042 D_fake: 0.748 \n",
            "(epoch: 42, iters: 352, time: 0.086, data: 0.123) G_GAN: 0.763 G_L1: 0.001 D_real: 0.743 D_fake: 0.672 \n",
            "(epoch: 42, iters: 452, time: 0.085, data: 0.077) G_GAN: 0.797 G_L1: 0.010 D_real: 0.708 D_fake: 0.598 \n",
            "(epoch: 42, iters: 552, time: 0.062, data: 0.106) G_GAN: 1.345 G_L1: 2.890 D_real: 0.679 D_fake: 0.092 \n",
            "(epoch: 42, iters: 652, time: 0.088, data: 0.204) G_GAN: 2.728 G_L1: 2.291 D_real: 0.038 D_fake: 0.067 \n",
            "(epoch: 42, iters: 752, time: 0.094, data: 0.050) G_GAN: 4.908 G_L1: 9.065 D_real: 0.047 D_fake: 0.008 \n",
            "saving the latest model (epoch 42, total_iters 30000)\n",
            "(epoch: 42, iters: 852, time: 0.075, data: 0.004) G_GAN: 6.485 G_L1: 3.506 D_real: 0.036 D_fake: 0.003 \n",
            "End of epoch 42 / 200 \t Time Taken: 114 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 43, iters: 38, time: 0.089, data: 0.006) G_GAN: 0.712 G_L1: 0.002 D_real: 0.724 D_fake: 0.694 \n",
            "(epoch: 43, iters: 138, time: 0.067, data: 0.006) G_GAN: 3.332 G_L1: 1.892 D_real: 0.031 D_fake: 0.088 \n",
            "(epoch: 43, iters: 238, time: 0.070, data: 0.074) G_GAN: 0.674 G_L1: 0.002 D_real: 0.570 D_fake: 0.838 \n",
            "(epoch: 43, iters: 338, time: 0.066, data: 0.167) G_GAN: 3.923 G_L1: 3.653 D_real: 0.013 D_fake: 0.030 \n",
            "(epoch: 43, iters: 438, time: 0.095, data: 0.203) G_GAN: 0.782 G_L1: 0.001 D_real: 0.885 D_fake: 0.540 \n",
            "(epoch: 43, iters: 538, time: 0.077, data: 0.106) G_GAN: 5.666 G_L1: 3.528 D_real: 0.001 D_fake: 0.009 \n",
            "(epoch: 43, iters: 638, time: 0.096, data: 0.124) G_GAN: 5.128 G_L1: 9.279 D_real: 0.110 D_fake: 0.008 \n",
            "(epoch: 43, iters: 738, time: 0.111, data: 0.128) G_GAN: 4.933 G_L1: 1.214 D_real: 0.033 D_fake: 0.007 \n",
            "(epoch: 43, iters: 838, time: 0.099, data: 0.000) G_GAN: 0.665 G_L1: 0.004 D_real: 0.605 D_fake: 0.769 \n",
            "End of epoch 43 / 200 \t Time Taken: 112 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 44, iters: 24, time: 0.088, data: 0.000) G_GAN: 0.733 G_L1: 0.002 D_real: 0.793 D_fake: 0.617 \n",
            "(epoch: 44, iters: 124, time: 0.089, data: 0.139) G_GAN: 2.898 G_L1: 1.808 D_real: 0.258 D_fake: 0.036 \n",
            "(epoch: 44, iters: 224, time: 0.075, data: 0.000) G_GAN: 7.034 G_L1: 5.090 D_real: 0.009 D_fake: 0.002 \n",
            "(epoch: 44, iters: 324, time: 0.086, data: 0.000) G_GAN: 4.725 G_L1: 7.809 D_real: 0.047 D_fake: 0.016 \n",
            "(epoch: 44, iters: 424, time: 0.089, data: 0.000) G_GAN: 6.486 G_L1: 4.908 D_real: 0.020 D_fake: 0.003 \n",
            "(epoch: 44, iters: 524, time: 0.089, data: 0.000) G_GAN: 3.167 G_L1: 9.685 D_real: 0.002 D_fake: 0.114 \n",
            "(epoch: 44, iters: 624, time: 0.104, data: 0.000) G_GAN: 8.664 G_L1: 6.618 D_real: 0.221 D_fake: 0.000 \n",
            "(epoch: 44, iters: 724, time: 0.085, data: 0.000) G_GAN: 0.507 G_L1: 0.005 D_real: 0.458 D_fake: 1.035 \n",
            "(epoch: 44, iters: 824, time: 0.089, data: 0.000) G_GAN: 2.823 G_L1: 0.452 D_real: 0.575 D_fake: 0.016 \n",
            "End of epoch 44 / 200 \t Time Taken: 113 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 45, iters: 10, time: 0.089, data: 0.000) G_GAN: 5.141 G_L1: 2.119 D_real: 0.040 D_fake: 0.014 \n",
            "(epoch: 45, iters: 110, time: 0.096, data: 0.002) G_GAN: 4.588 G_L1: 4.579 D_real: 0.003 D_fake: 0.016 \n",
            "(epoch: 45, iters: 210, time: 0.086, data: 0.000) G_GAN: 0.580 G_L1: 0.012 D_real: 0.560 D_fake: 0.905 \n",
            "(epoch: 45, iters: 310, time: 0.069, data: 0.000) G_GAN: 2.288 G_L1: 0.130 D_real: 0.147 D_fake: 0.214 \n",
            "(epoch: 45, iters: 410, time: 0.089, data: 0.000) G_GAN: 0.530 G_L1: 0.001 D_real: 0.591 D_fake: 0.844 \n",
            "(epoch: 45, iters: 510, time: 0.060, data: 0.034) G_GAN: 3.950 G_L1: 1.122 D_real: 0.054 D_fake: 0.774 \n",
            "(epoch: 45, iters: 610, time: 0.057, data: 0.000) G_GAN: 3.683 G_L1: 2.390 D_real: 0.039 D_fake: 0.032 \n",
            "(epoch: 45, iters: 710, time: 0.117, data: 0.000) G_GAN: 0.654 G_L1: 0.002 D_real: 0.651 D_fake: 0.761 \n",
            "(epoch: 45, iters: 810, time: 0.083, data: 0.000) G_GAN: 0.755 G_L1: 0.002 D_real: 0.755 D_fake: 0.657 \n",
            "(epoch: 45, iters: 910, time: 0.062, data: 0.000) G_GAN: 3.509 G_L1: 2.562 D_real: 0.009 D_fake: 0.239 \n",
            "End of epoch 45 / 200 \t Time Taken: 113 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 46, iters: 96, time: 0.064, data: 0.000) G_GAN: 3.240 G_L1: 7.437 D_real: 0.002 D_fake: 0.081 \n",
            "(epoch: 46, iters: 196, time: 0.094, data: 0.066) G_GAN: 4.209 G_L1: 1.286 D_real: 0.048 D_fake: 1.981 \n",
            "(epoch: 46, iters: 296, time: 0.081, data: 0.000) G_GAN: 1.317 G_L1: 0.386 D_real: 0.632 D_fake: 0.505 \n",
            "(epoch: 46, iters: 396, time: 0.071, data: 0.002) G_GAN: 7.087 G_L1: 6.199 D_real: 0.103 D_fake: 0.001 \n",
            "(epoch: 46, iters: 496, time: 0.090, data: 0.130) G_GAN: 3.493 G_L1: 2.247 D_real: 0.019 D_fake: 0.767 \n",
            "(epoch: 46, iters: 596, time: 0.097, data: 0.090) G_GAN: 7.215 G_L1: 4.196 D_real: 0.012 D_fake: 0.002 \n",
            "(epoch: 46, iters: 696, time: 0.094, data: 0.103) G_GAN: 1.984 G_L1: 1.039 D_real: 0.164 D_fake: 0.796 \n",
            "(epoch: 46, iters: 796, time: 0.093, data: 0.077) G_GAN: 0.864 G_L1: 0.012 D_real: 0.694 D_fake: 0.531 \n",
            "(epoch: 46, iters: 896, time: 0.086, data: 0.000) G_GAN: 2.687 G_L1: 2.093 D_real: 0.108 D_fake: 0.099 \n",
            "End of epoch 46 / 200 \t Time Taken: 112 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 47, iters: 82, time: 0.076, data: 0.000) G_GAN: 3.637 G_L1: 0.766 D_real: 0.099 D_fake: 0.034 \n",
            "(epoch: 47, iters: 182, time: 0.112, data: 0.000) G_GAN: 0.670 G_L1: 0.001 D_real: 0.636 D_fake: 0.757 \n",
            "(epoch: 47, iters: 282, time: 0.090, data: 0.000) G_GAN: 6.461 G_L1: 7.101 D_real: 0.017 D_fake: 0.003 \n",
            "(epoch: 47, iters: 382, time: 0.102, data: 0.000) G_GAN: 6.544 G_L1: 3.238 D_real: 0.044 D_fake: 0.002 \n",
            "(epoch: 47, iters: 482, time: 0.089, data: 0.002) G_GAN: 3.855 G_L1: 4.307 D_real: 2.507 D_fake: 0.000 \n",
            "(epoch: 47, iters: 582, time: 0.115, data: 0.000) G_GAN: 0.762 G_L1: 0.001 D_real: 0.798 D_fake: 0.602 \n",
            "(epoch: 47, iters: 682, time: 0.076, data: 0.002) G_GAN: 0.712 G_L1: 0.002 D_real: 0.749 D_fake: 0.647 \n",
            "(epoch: 47, iters: 782, time: 0.103, data: 0.000) G_GAN: 0.813 G_L1: 0.045 D_real: 0.698 D_fake: 0.623 \n",
            "(epoch: 47, iters: 882, time: 0.070, data: 0.000) G_GAN: 3.736 G_L1: 2.398 D_real: 0.015 D_fake: 0.044 \n",
            "End of epoch 47 / 200 \t Time Taken: 112 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 48, iters: 68, time: 0.091, data: 0.000) G_GAN: 3.636 G_L1: 0.400 D_real: 0.206 D_fake: 0.035 \n",
            "(epoch: 48, iters: 168, time: 0.070, data: 0.136) G_GAN: 5.867 G_L1: 2.025 D_real: 0.742 D_fake: 0.001 \n",
            "(epoch: 48, iters: 268, time: 0.066, data: 0.180) G_GAN: 6.700 G_L1: 0.985 D_real: 0.009 D_fake: 0.003 \n",
            "saving the latest model (epoch 48, total_iters 35000)\n",
            "(epoch: 48, iters: 368, time: 0.091, data: 0.000) G_GAN: 3.838 G_L1: 1.066 D_real: 0.209 D_fake: 0.028 \n",
            "(epoch: 48, iters: 468, time: 0.090, data: 0.000) G_GAN: 5.012 G_L1: 4.250 D_real: 0.009 D_fake: 0.010 \n",
            "(epoch: 48, iters: 568, time: 0.100, data: 0.000) G_GAN: 2.764 G_L1: 2.267 D_real: 0.156 D_fake: 0.016 \n",
            "(epoch: 48, iters: 668, time: 0.098, data: 0.004) G_GAN: 4.033 G_L1: 3.214 D_real: 0.016 D_fake: 0.174 \n",
            "(epoch: 48, iters: 768, time: 0.066, data: 0.092) G_GAN: 0.736 G_L1: 0.025 D_real: 0.722 D_fake: 0.603 \n",
            "(epoch: 48, iters: 868, time: 0.088, data: 0.133) G_GAN: 3.363 G_L1: 4.202 D_real: 0.002 D_fake: 0.058 \n",
            "End of epoch 48 / 200 \t Time Taken: 114 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 49, iters: 54, time: 0.058, data: 0.132) G_GAN: 3.822 G_L1: 3.460 D_real: 0.008 D_fake: 0.053 \n",
            "(epoch: 49, iters: 154, time: 0.105, data: 0.000) G_GAN: 0.824 G_L1: 0.343 D_real: 0.205 D_fake: 2.379 \n",
            "(epoch: 49, iters: 254, time: 0.080, data: 0.001) G_GAN: 0.752 G_L1: 0.016 D_real: 0.610 D_fake: 0.690 \n",
            "(epoch: 49, iters: 354, time: 0.084, data: 0.000) G_GAN: 5.315 G_L1: 2.086 D_real: 0.013 D_fake: 0.007 \n",
            "(epoch: 49, iters: 454, time: 0.084, data: 0.002) G_GAN: 0.694 G_L1: 0.001 D_real: 0.682 D_fake: 0.707 \n",
            "(epoch: 49, iters: 554, time: 0.071, data: 0.000) G_GAN: 0.695 G_L1: 0.000 D_real: 0.698 D_fake: 0.698 \n",
            "(epoch: 49, iters: 654, time: 0.082, data: 0.000) G_GAN: 0.720 G_L1: 0.001 D_real: 0.741 D_fake: 0.653 \n",
            "(epoch: 49, iters: 754, time: 0.112, data: 0.000) G_GAN: 0.633 G_L1: 0.001 D_real: 0.594 D_fake: 0.809 \n",
            "(epoch: 49, iters: 854, time: 0.079, data: 0.000) G_GAN: 3.244 G_L1: 1.342 D_real: 0.137 D_fake: 0.034 \n",
            "End of epoch 49 / 200 \t Time Taken: 113 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 50, iters: 40, time: 0.111, data: 0.004) G_GAN: 6.834 G_L1: 6.843 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 50, iters: 140, time: 0.080, data: 0.113) G_GAN: 4.455 G_L1: 3.836 D_real: 0.004 D_fake: 0.024 \n",
            "(epoch: 50, iters: 240, time: 0.102, data: 0.131) G_GAN: 5.931 G_L1: 3.582 D_real: 0.419 D_fake: 0.001 \n",
            "(epoch: 50, iters: 340, time: 0.061, data: 0.000) G_GAN: 3.640 G_L1: 1.722 D_real: 0.048 D_fake: 0.045 \n",
            "(epoch: 50, iters: 440, time: 0.091, data: 0.000) G_GAN: 4.924 G_L1: 1.387 D_real: 0.054 D_fake: 0.010 \n",
            "(epoch: 50, iters: 540, time: 0.089, data: 0.000) G_GAN: 7.882 G_L1: 9.810 D_real: 0.007 D_fake: 0.001 \n",
            "(epoch: 50, iters: 640, time: 0.085, data: 0.000) G_GAN: 0.690 G_L1: 0.000 D_real: 0.677 D_fake: 0.718 \n",
            "(epoch: 50, iters: 740, time: 0.079, data: 0.000) G_GAN: 3.404 G_L1: 3.988 D_real: 1.350 D_fake: 0.007 \n",
            "(epoch: 50, iters: 840, time: 0.086, data: 0.316) G_GAN: 4.365 G_L1: 1.030 D_real: 0.041 D_fake: 0.015 \n",
            "End of epoch 50 / 200 \t Time Taken: 114 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 51, iters: 26, time: 0.089, data: 0.216) G_GAN: 9.473 G_L1: 3.421 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 51, iters: 126, time: 0.082, data: 0.004) G_GAN: 7.187 G_L1: 2.592 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 51, iters: 226, time: 0.063, data: 0.000) G_GAN: 7.868 G_L1: 9.356 D_real: 0.022 D_fake: 0.002 \n",
            "(epoch: 51, iters: 326, time: 0.084, data: 0.000) G_GAN: 4.618 G_L1: 10.420 D_real: 0.000 D_fake: 0.027 \n",
            "(epoch: 51, iters: 426, time: 0.107, data: 0.000) G_GAN: 2.069 G_L1: 0.816 D_real: 0.023 D_fake: 0.781 \n",
            "(epoch: 51, iters: 526, time: 0.096, data: 0.000) G_GAN: 6.461 G_L1: 6.439 D_real: 0.027 D_fake: 0.003 \n",
            "(epoch: 51, iters: 626, time: 0.082, data: 0.000) G_GAN: 3.300 G_L1: 1.341 D_real: 0.011 D_fake: 0.069 \n",
            "(epoch: 51, iters: 726, time: 0.091, data: 0.000) G_GAN: 7.103 G_L1: 1.288 D_real: 0.010 D_fake: 0.001 \n",
            "(epoch: 51, iters: 826, time: 0.077, data: 0.000) G_GAN: 3.270 G_L1: 4.988 D_real: 0.469 D_fake: 0.119 \n",
            "End of epoch 51 / 200 \t Time Taken: 113 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 52, iters: 12, time: 0.108, data: 0.000) G_GAN: 3.352 G_L1: 3.112 D_real: 0.048 D_fake: 0.077 \n",
            "(epoch: 52, iters: 112, time: 0.100, data: 0.003) G_GAN: 6.678 G_L1: 4.888 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 52, iters: 212, time: 0.089, data: 0.003) G_GAN: 0.701 G_L1: 0.002 D_real: 0.712 D_fake: 0.679 \n",
            "(epoch: 52, iters: 312, time: 0.085, data: 0.000) G_GAN: 7.559 G_L1: 5.113 D_real: 0.006 D_fake: 0.001 \n",
            "(epoch: 52, iters: 412, time: 0.073, data: 0.001) G_GAN: 5.711 G_L1: 1.054 D_real: 0.205 D_fake: 0.002 \n",
            "(epoch: 52, iters: 512, time: 0.082, data: 0.000) G_GAN: 4.602 G_L1: 1.721 D_real: 0.018 D_fake: 0.014 \n",
            "(epoch: 52, iters: 612, time: 0.073, data: 0.000) G_GAN: 2.711 G_L1: 2.172 D_real: 0.429 D_fake: 0.024 \n",
            "(epoch: 52, iters: 712, time: 0.082, data: 0.000) G_GAN: 3.804 G_L1: 2.210 D_real: 0.152 D_fake: 0.037 \n",
            "(epoch: 52, iters: 812, time: 0.071, data: 0.000) G_GAN: 5.560 G_L1: 3.300 D_real: 0.148 D_fake: 0.005 \n",
            "(epoch: 52, iters: 912, time: 0.045, data: 0.002) G_GAN: 3.622 G_L1: 6.327 D_real: 0.006 D_fake: 0.047 \n",
            "End of epoch 52 / 200 \t Time Taken: 113 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 53, iters: 98, time: 0.079, data: 0.000) G_GAN: 6.424 G_L1: 2.333 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 53, iters: 198, time: 0.090, data: 0.000) G_GAN: 2.181 G_L1: 1.783 D_real: 0.567 D_fake: 0.038 \n",
            "(epoch: 53, iters: 298, time: 0.089, data: 0.002) G_GAN: 4.880 G_L1: 8.444 D_real: 0.002 D_fake: 0.018 \n",
            "(epoch: 53, iters: 398, time: 0.083, data: 0.000) G_GAN: 0.710 G_L1: 0.001 D_real: 0.634 D_fake: 0.785 \n",
            "(epoch: 53, iters: 498, time: 0.111, data: 0.000) G_GAN: 0.720 G_L1: 0.000 D_real: 1.465 D_fake: 0.312 \n",
            "(epoch: 53, iters: 598, time: 0.097, data: 0.001) G_GAN: 6.706 G_L1: 1.354 D_real: 0.005 D_fake: 0.002 \n",
            "(epoch: 53, iters: 698, time: 0.080, data: 0.000) G_GAN: 3.978 G_L1: 3.103 D_real: 0.016 D_fake: 0.712 \n",
            "saving the latest model (epoch 53, total_iters 40000)\n",
            "(epoch: 53, iters: 798, time: 0.062, data: 0.002) G_GAN: 2.130 G_L1: 0.847 D_real: 0.281 D_fake: 0.130 \n",
            "(epoch: 53, iters: 898, time: 0.091, data: 0.000) G_GAN: 1.751 G_L1: 0.356 D_real: 0.460 D_fake: 0.195 \n",
            "End of epoch 53 / 200 \t Time Taken: 115 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 54, iters: 84, time: 0.073, data: 0.000) G_GAN: 7.149 G_L1: 1.149 D_real: 0.659 D_fake: 0.000 \n",
            "(epoch: 54, iters: 184, time: 0.096, data: 0.096) G_GAN: 0.851 G_L1: 0.000 D_real: 1.099 D_fake: 0.451 \n",
            "(epoch: 54, iters: 284, time: 0.090, data: 0.122) G_GAN: 4.329 G_L1: 3.421 D_real: 0.007 D_fake: 0.018 \n",
            "(epoch: 54, iters: 384, time: 0.094, data: 0.062) G_GAN: 3.305 G_L1: 3.943 D_real: 0.186 D_fake: 0.034 \n",
            "(epoch: 54, iters: 484, time: 0.073, data: 0.001) G_GAN: 3.815 G_L1: 2.648 D_real: 0.000 D_fake: 0.037 \n",
            "(epoch: 54, iters: 584, time: 0.094, data: 0.000) G_GAN: 9.133 G_L1: 3.069 D_real: 0.018 D_fake: 0.000 \n",
            "(epoch: 54, iters: 684, time: 0.092, data: 0.115) G_GAN: 5.476 G_L1: 5.667 D_real: 0.116 D_fake: 0.005 \n",
            "(epoch: 54, iters: 784, time: 0.078, data: 0.000) G_GAN: 3.781 G_L1: 1.020 D_real: 1.355 D_fake: 0.001 \n",
            "(epoch: 54, iters: 884, time: 0.093, data: 0.020) G_GAN: 3.721 G_L1: 5.345 D_real: 0.014 D_fake: 0.101 \n",
            "End of epoch 54 / 200 \t Time Taken: 112 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 55, iters: 70, time: 0.107, data: 0.003) G_GAN: 5.931 G_L1: 4.112 D_real: 0.010 D_fake: 0.004 \n",
            "(epoch: 55, iters: 170, time: 0.104, data: 0.000) G_GAN: 7.385 G_L1: 3.374 D_real: 0.014 D_fake: 0.001 \n",
            "(epoch: 55, iters: 270, time: 0.077, data: 0.000) G_GAN: 7.019 G_L1: 2.143 D_real: 0.068 D_fake: 0.002 \n",
            "(epoch: 55, iters: 370, time: 0.100, data: 0.000) G_GAN: 6.679 G_L1: 1.851 D_real: 0.013 D_fake: 0.005 \n",
            "(epoch: 55, iters: 470, time: 0.066, data: 0.000) G_GAN: 7.260 G_L1: 2.801 D_real: 0.006 D_fake: 0.001 \n",
            "(epoch: 55, iters: 570, time: 0.092, data: 0.000) G_GAN: 0.647 G_L1: 0.001 D_real: 0.687 D_fake: 0.718 \n",
            "(epoch: 55, iters: 670, time: 0.076, data: 0.001) G_GAN: 2.835 G_L1: 0.932 D_real: 0.014 D_fake: 0.671 \n",
            "(epoch: 55, iters: 770, time: 0.095, data: 0.000) G_GAN: 8.812 G_L1: 1.529 D_real: 0.258 D_fake: 0.000 \n",
            "(epoch: 55, iters: 870, time: 0.093, data: 0.000) G_GAN: 0.686 G_L1: 0.000 D_real: 0.660 D_fake: 0.756 \n",
            "End of epoch 55 / 200 \t Time Taken: 112 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 56, iters: 56, time: 0.096, data: 0.000) G_GAN: 2.586 G_L1: 0.730 D_real: 0.148 D_fake: 0.116 \n",
            "(epoch: 56, iters: 156, time: 0.091, data: 0.018) G_GAN: 0.639 G_L1: 0.001 D_real: 0.623 D_fake: 0.779 \n",
            "(epoch: 56, iters: 256, time: 0.091, data: 0.003) G_GAN: 5.034 G_L1: 5.242 D_real: 0.070 D_fake: 0.008 \n",
            "(epoch: 56, iters: 356, time: 0.083, data: 0.081) G_GAN: 3.567 G_L1: 7.286 D_real: 0.004 D_fake: 0.091 \n",
            "(epoch: 56, iters: 456, time: 0.065, data: 0.000) G_GAN: 4.529 G_L1: 7.676 D_real: 0.029 D_fake: 0.020 \n",
            "(epoch: 56, iters: 556, time: 0.099, data: 0.000) G_GAN: 4.012 G_L1: 1.176 D_real: 0.001 D_fake: 0.337 \n",
            "(epoch: 56, iters: 656, time: 0.104, data: 0.000) G_GAN: 6.665 G_L1: 2.770 D_real: 0.026 D_fake: 0.003 \n",
            "(epoch: 56, iters: 756, time: 0.090, data: 0.028) G_GAN: 0.713 G_L1: 0.000 D_real: 0.757 D_fake: 0.641 \n",
            "(epoch: 56, iters: 856, time: 0.093, data: 0.167) G_GAN: 3.405 G_L1: 1.541 D_real: 0.023 D_fake: 0.066 \n",
            "End of epoch 56 / 200 \t Time Taken: 112 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 57, iters: 42, time: 0.084, data: 0.084) G_GAN: 3.904 G_L1: 0.751 D_real: 0.107 D_fake: 0.024 \n",
            "(epoch: 57, iters: 142, time: 0.101, data: 0.000) G_GAN: 0.674 G_L1: 0.000 D_real: 0.764 D_fake: 0.631 \n",
            "(epoch: 57, iters: 242, time: 0.083, data: 0.000) G_GAN: 4.934 G_L1: 2.254 D_real: 0.001 D_fake: 0.010 \n",
            "(epoch: 57, iters: 342, time: 0.066, data: 0.000) G_GAN: 0.762 G_L1: 0.001 D_real: 0.854 D_fake: 0.568 \n",
            "(epoch: 57, iters: 442, time: 0.087, data: 0.000) G_GAN: 7.587 G_L1: 3.779 D_real: 0.005 D_fake: 0.001 \n",
            "(epoch: 57, iters: 542, time: 0.100, data: 0.000) G_GAN: 0.708 G_L1: 0.000 D_real: 0.723 D_fake: 0.677 \n",
            "(epoch: 57, iters: 642, time: 0.063, data: 0.000) G_GAN: 0.621 G_L1: 0.000 D_real: 0.668 D_fake: 0.735 \n",
            "(epoch: 57, iters: 742, time: 0.080, data: 0.000) G_GAN: 3.707 G_L1: 0.999 D_real: 0.089 D_fake: 0.024 \n",
            "(epoch: 57, iters: 842, time: 0.092, data: 0.000) G_GAN: 7.497 G_L1: 6.180 D_real: 0.007 D_fake: 0.001 \n",
            "End of epoch 57 / 200 \t Time Taken: 114 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 58, iters: 28, time: 0.080, data: 0.000) G_GAN: 4.606 G_L1: 2.286 D_real: 0.059 D_fake: 0.015 \n",
            "(epoch: 58, iters: 128, time: 0.106, data: 0.144) G_GAN: 4.621 G_L1: 4.057 D_real: 0.036 D_fake: 0.014 \n",
            "(epoch: 58, iters: 228, time: 0.092, data: 0.140) G_GAN: 0.680 G_L1: 0.001 D_real: 0.679 D_fake: 0.716 \n",
            "(epoch: 58, iters: 328, time: 0.108, data: 0.099) G_GAN: 4.159 G_L1: 1.078 D_real: 0.063 D_fake: 0.287 \n",
            "(epoch: 58, iters: 428, time: 0.075, data: 0.000) G_GAN: 6.425 G_L1: 0.746 D_real: 0.005 D_fake: 0.002 \n",
            "(epoch: 58, iters: 528, time: 0.098, data: 0.000) G_GAN: 4.965 G_L1: 1.277 D_real: 0.012 D_fake: 0.908 \n",
            "(epoch: 58, iters: 628, time: 0.091, data: 0.000) G_GAN: 5.360 G_L1: 4.953 D_real: 0.010 D_fake: 0.010 \n",
            "(epoch: 58, iters: 728, time: 0.087, data: 0.115) G_GAN: 0.836 G_L1: 0.001 D_real: 0.948 D_fake: 0.509 \n",
            "(epoch: 58, iters: 828, time: 0.102, data: 0.004) G_GAN: 5.676 G_L1: 4.866 D_real: 0.009 D_fake: 0.005 \n",
            "End of epoch 58 / 200 \t Time Taken: 115 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 59, iters: 14, time: 0.087, data: 0.123) G_GAN: 11.125 G_L1: 5.094 D_real: 0.064 D_fake: 0.000 \n",
            "(epoch: 59, iters: 114, time: 0.082, data: 0.000) G_GAN: 4.690 G_L1: 1.835 D_real: 0.021 D_fake: 0.016 \n",
            "(epoch: 59, iters: 214, time: 0.088, data: 0.000) G_GAN: 0.861 G_L1: 0.000 D_real: 0.792 D_fake: 0.629 \n",
            "saving the latest model (epoch 59, total_iters 45000)\n",
            "(epoch: 59, iters: 314, time: 0.093, data: 0.000) G_GAN: 0.687 G_L1: 0.000 D_real: 0.672 D_fake: 0.719 \n",
            "(epoch: 59, iters: 414, time: 0.098, data: 0.000) G_GAN: 5.003 G_L1: 1.043 D_real: 0.122 D_fake: 0.007 \n",
            "(epoch: 59, iters: 514, time: 0.082, data: 0.000) G_GAN: 3.286 G_L1: 0.805 D_real: 0.458 D_fake: 0.008 \n",
            "(epoch: 59, iters: 614, time: 0.077, data: 0.000) G_GAN: 8.853 G_L1: 1.176 D_real: 0.026 D_fake: 0.000 \n",
            "(epoch: 59, iters: 714, time: 0.096, data: 0.000) G_GAN: 5.369 G_L1: 1.882 D_real: 0.056 D_fake: 0.753 \n",
            "(epoch: 59, iters: 814, time: 0.104, data: 0.000) G_GAN: 3.425 G_L1: 2.588 D_real: 0.141 D_fake: 0.193 \n",
            "(epoch: 59, iters: 914, time: 0.068, data: 0.151) G_GAN: 0.654 G_L1: 0.000 D_real: 0.787 D_fake: 0.617 \n",
            "End of epoch 59 / 200 \t Time Taken: 115 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 60, iters: 100, time: 0.092, data: 0.666) G_GAN: 4.472 G_L1: 5.660 D_real: 0.008 D_fake: 0.019 \n",
            "(epoch: 60, iters: 200, time: 0.081, data: 0.137) G_GAN: 4.105 G_L1: 11.634 D_real: 0.200 D_fake: 0.017 \n",
            "(epoch: 60, iters: 300, time: 0.102, data: 0.001) G_GAN: 0.858 G_L1: 0.000 D_real: 0.908 D_fake: 0.544 \n",
            "(epoch: 60, iters: 400, time: 0.112, data: 0.000) G_GAN: 4.978 G_L1: 0.588 D_real: 0.020 D_fake: 1.061 \n",
            "(epoch: 60, iters: 500, time: 0.098, data: 0.000) G_GAN: 0.802 G_L1: 0.000 D_real: 0.765 D_fake: 0.637 \n",
            "(epoch: 60, iters: 600, time: 0.089, data: 0.000) G_GAN: 4.219 G_L1: 1.180 D_real: 0.015 D_fake: 0.027 \n",
            "(epoch: 60, iters: 700, time: 0.059, data: 0.000) G_GAN: 4.467 G_L1: 11.192 D_real: 0.003 D_fake: 0.027 \n",
            "(epoch: 60, iters: 800, time: 0.088, data: 0.000) G_GAN: 0.720 G_L1: 0.004 D_real: 0.674 D_fake: 0.676 \n",
            "(epoch: 60, iters: 900, time: 0.086, data: 0.000) G_GAN: 0.535 G_L1: 0.001 D_real: 0.433 D_fake: 1.076 \n",
            "End of epoch 60 / 200 \t Time Taken: 114 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 61, iters: 86, time: 0.079, data: 0.000) G_GAN: 0.841 G_L1: 0.001 D_real: 0.826 D_fake: 0.584 \n",
            "(epoch: 61, iters: 186, time: 0.095, data: 0.192) G_GAN: 6.137 G_L1: 4.956 D_real: 0.012 D_fake: 0.005 \n",
            "(epoch: 61, iters: 286, time: 0.093, data: 0.160) G_GAN: 3.889 G_L1: 11.543 D_real: 0.006 D_fake: 0.047 \n",
            "(epoch: 61, iters: 386, time: 0.112, data: 0.191) G_GAN: 0.689 G_L1: 0.000 D_real: 0.682 D_fake: 0.744 \n",
            "(epoch: 61, iters: 486, time: 0.111, data: 0.041) G_GAN: 5.204 G_L1: 5.633 D_real: 0.006 D_fake: 0.011 \n",
            "(epoch: 61, iters: 586, time: 0.101, data: 0.107) G_GAN: 0.696 G_L1: 0.000 D_real: 0.715 D_fake: 0.684 \n",
            "(epoch: 61, iters: 686, time: 0.075, data: 0.116) G_GAN: 0.481 G_L1: 0.000 D_real: 0.509 D_fake: 0.980 \n",
            "(epoch: 61, iters: 786, time: 0.105, data: 0.147) G_GAN: 3.764 G_L1: 5.778 D_real: 0.006 D_fake: 0.289 \n",
            "(epoch: 61, iters: 886, time: 0.087, data: 0.140) G_GAN: 0.464 G_L1: 0.000 D_real: 0.400 D_fake: 1.129 \n",
            "End of epoch 61 / 200 \t Time Taken: 114 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 62, iters: 72, time: 0.074, data: 0.151) G_GAN: 6.870 G_L1: 4.581 D_real: 0.128 D_fake: 0.001 \n",
            "(epoch: 62, iters: 172, time: 0.103, data: 0.000) G_GAN: 0.712 G_L1: 0.001 D_real: 0.602 D_fake: 0.809 \n",
            "(epoch: 62, iters: 272, time: 0.073, data: 0.100) G_GAN: 2.001 G_L1: 0.103 D_real: 0.283 D_fake: 0.261 \n",
            "(epoch: 62, iters: 372, time: 0.088, data: 0.002) G_GAN: 3.279 G_L1: 2.453 D_real: 0.103 D_fake: 0.023 \n",
            "(epoch: 62, iters: 472, time: 0.089, data: 0.000) G_GAN: 8.656 G_L1: 3.313 D_real: 0.022 D_fake: 0.000 \n",
            "(epoch: 62, iters: 572, time: 0.080, data: 0.000) G_GAN: 5.249 G_L1: 3.274 D_real: 0.004 D_fake: 0.009 \n",
            "(epoch: 62, iters: 672, time: 0.089, data: 0.000) G_GAN: 0.688 G_L1: 0.000 D_real: 0.678 D_fake: 0.723 \n",
            "(epoch: 62, iters: 772, time: 0.056, data: 0.000) G_GAN: 2.579 G_L1: 4.226 D_real: 0.275 D_fake: 0.080 \n",
            "(epoch: 62, iters: 872, time: 0.076, data: 0.000) G_GAN: 4.119 G_L1: 1.014 D_real: 0.009 D_fake: 0.027 \n",
            "End of epoch 62 / 200 \t Time Taken: 114 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 63, iters: 58, time: 0.086, data: 0.139) G_GAN: 0.549 G_L1: 0.000 D_real: 0.565 D_fake: 0.861 \n",
            "(epoch: 63, iters: 158, time: 0.104, data: 0.000) G_GAN: 1.241 G_L1: 0.876 D_real: 0.963 D_fake: 0.028 \n",
            "(epoch: 63, iters: 258, time: 0.082, data: 0.000) G_GAN: 6.659 G_L1: 5.851 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 63, iters: 358, time: 0.087, data: 0.000) G_GAN: 0.644 G_L1: 0.000 D_real: 0.596 D_fake: 0.849 \n",
            "(epoch: 63, iters: 458, time: 0.091, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.741 D_fake: 0.699 \n",
            "(epoch: 63, iters: 558, time: 0.098, data: 0.000) G_GAN: 4.067 G_L1: 1.847 D_real: 0.003 D_fake: 0.105 \n",
            "(epoch: 63, iters: 658, time: 0.091, data: 0.000) G_GAN: 0.727 G_L1: 0.001 D_real: 0.717 D_fake: 0.683 \n",
            "(epoch: 63, iters: 758, time: 0.093, data: 0.000) G_GAN: 4.033 G_L1: 2.583 D_real: 0.001 D_fake: 0.034 \n",
            "(epoch: 63, iters: 858, time: 0.075, data: 0.000) G_GAN: 0.662 G_L1: 0.000 D_real: 0.641 D_fake: 0.786 \n",
            "End of epoch 63 / 200 \t Time Taken: 114 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 64, iters: 44, time: 0.085, data: 0.000) G_GAN: 4.546 G_L1: 2.669 D_real: 0.003 D_fake: 0.011 \n",
            "(epoch: 64, iters: 144, time: 0.095, data: 0.000) G_GAN: 8.573 G_L1: 1.048 D_real: 0.800 D_fake: 0.001 \n",
            "(epoch: 64, iters: 244, time: 0.103, data: 0.000) G_GAN: 4.346 G_L1: 1.951 D_real: 0.007 D_fake: 0.028 \n",
            "(epoch: 64, iters: 344, time: 0.103, data: 0.000) G_GAN: 0.613 G_L1: 0.000 D_real: 0.579 D_fake: 0.826 \n",
            "(epoch: 64, iters: 444, time: 0.080, data: 0.000) G_GAN: 0.699 G_L1: 0.000 D_real: 0.698 D_fake: 0.691 \n",
            "(epoch: 64, iters: 544, time: 0.091, data: 0.000) G_GAN: 0.829 G_L1: 0.000 D_real: 0.813 D_fake: 0.598 \n",
            "(epoch: 64, iters: 644, time: 0.099, data: 0.000) G_GAN: 4.875 G_L1: 0.758 D_real: 0.087 D_fake: 0.011 \n",
            "saving the latest model (epoch 64, total_iters 50000)\n",
            "(epoch: 64, iters: 744, time: 0.064, data: 0.000) G_GAN: 0.710 G_L1: 0.000 D_real: 0.794 D_fake: 0.623 \n",
            "(epoch: 64, iters: 844, time: 0.062, data: 0.000) G_GAN: 4.573 G_L1: 2.928 D_real: 0.015 D_fake: 0.015 \n",
            "End of epoch 64 / 200 \t Time Taken: 115 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 65, iters: 30, time: 0.083, data: 0.000) G_GAN: 6.165 G_L1: 12.267 D_real: 0.001 D_fake: 0.005 \n",
            "(epoch: 65, iters: 130, time: 0.090, data: 0.000) G_GAN: 5.670 G_L1: 2.461 D_real: 0.001 D_fake: 0.005 \n",
            "(epoch: 65, iters: 230, time: 0.073, data: 0.000) G_GAN: 0.858 G_L1: 0.000 D_real: 0.886 D_fake: 0.564 \n",
            "(epoch: 65, iters: 330, time: 0.084, data: 0.000) G_GAN: 8.863 G_L1: 11.156 D_real: 0.004 D_fake: 0.000 \n",
            "(epoch: 65, iters: 430, time: 0.107, data: 0.002) G_GAN: 6.650 G_L1: 2.804 D_real: 0.004 D_fake: 0.002 \n",
            "(epoch: 65, iters: 530, time: 0.066, data: 0.157) G_GAN: 4.290 G_L1: 15.987 D_real: 0.192 D_fake: 0.161 \n",
            "(epoch: 65, iters: 630, time: 0.096, data: 0.113) G_GAN: 8.640 G_L1: 5.867 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 65, iters: 730, time: 0.099, data: 0.000) G_GAN: 3.793 G_L1: 3.051 D_real: 0.189 D_fake: 0.011 \n",
            "(epoch: 65, iters: 830, time: 0.088, data: 0.000) G_GAN: 1.514 G_L1: 0.127 D_real: 0.214 D_fake: 0.787 \n",
            "End of epoch 65 / 200 \t Time Taken: 113 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 66, iters: 16, time: 0.111, data: 0.001) G_GAN: 7.387 G_L1: 0.849 D_real: 0.133 D_fake: 0.001 \n",
            "(epoch: 66, iters: 116, time: 0.120, data: 0.152) G_GAN: 1.463 G_L1: 0.086 D_real: 0.586 D_fake: 0.146 \n",
            "(epoch: 66, iters: 216, time: 0.076, data: 0.000) G_GAN: 6.946 G_L1: 7.768 D_real: 0.002 D_fake: 0.003 \n",
            "(epoch: 66, iters: 316, time: 0.084, data: 0.000) G_GAN: 3.018 G_L1: 1.020 D_real: 0.011 D_fake: 0.135 \n",
            "(epoch: 66, iters: 416, time: 0.077, data: 0.000) G_GAN: 5.069 G_L1: 0.472 D_real: 0.056 D_fake: 0.008 \n",
            "(epoch: 66, iters: 516, time: 0.100, data: 0.000) G_GAN: 0.613 G_L1: 1.259 D_real: 0.802 D_fake: 0.021 \n",
            "(epoch: 66, iters: 616, time: 0.092, data: 0.000) G_GAN: 5.658 G_L1: 4.978 D_real: 0.001 D_fake: 0.006 \n",
            "(epoch: 66, iters: 716, time: 0.097, data: 0.000) G_GAN: 6.916 G_L1: 2.803 D_real: 0.003 D_fake: 0.002 \n",
            "(epoch: 66, iters: 816, time: 0.078, data: 0.000) G_GAN: 3.735 G_L1: 1.881 D_real: 0.306 D_fake: 0.003 \n",
            "End of epoch 66 / 200 \t Time Taken: 114 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 67, iters: 2, time: 0.105, data: 0.000) G_GAN: 4.613 G_L1: 4.711 D_real: 0.018 D_fake: 0.021 \n",
            "(epoch: 67, iters: 102, time: 0.073, data: 0.002) G_GAN: 4.978 G_L1: 3.624 D_real: 0.008 D_fake: 0.008 \n",
            "(epoch: 67, iters: 202, time: 0.083, data: 0.040) G_GAN: 6.393 G_L1: 1.748 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 67, iters: 302, time: 0.085, data: 0.061) G_GAN: 3.705 G_L1: 8.941 D_real: 0.001 D_fake: 0.081 \n",
            "(epoch: 67, iters: 402, time: 0.063, data: 0.205) G_GAN: 3.289 G_L1: 0.412 D_real: 0.033 D_fake: 0.629 \n",
            "(epoch: 67, iters: 502, time: 0.112, data: 0.154) G_GAN: 2.700 G_L1: 10.402 D_real: 0.001 D_fake: 0.044 \n",
            "(epoch: 67, iters: 602, time: 0.100, data: 0.149) G_GAN: 5.075 G_L1: 2.942 D_real: 0.000 D_fake: 1.424 \n",
            "(epoch: 67, iters: 702, time: 0.105, data: 0.089) G_GAN: 3.997 G_L1: 0.988 D_real: 0.034 D_fake: 1.062 \n",
            "(epoch: 67, iters: 802, time: 0.101, data: 0.002) G_GAN: 8.831 G_L1: 0.814 D_real: 0.039 D_fake: 0.000 \n",
            "(epoch: 67, iters: 902, time: 0.092, data: 0.003) G_GAN: 7.971 G_L1: 4.699 D_real: 0.009 D_fake: 0.001 \n",
            "End of epoch 67 / 200 \t Time Taken: 115 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 68, iters: 88, time: 0.101, data: 0.189) G_GAN: 4.211 G_L1: 4.657 D_real: 0.002 D_fake: 0.032 \n",
            "(epoch: 68, iters: 188, time: 0.081, data: 0.000) G_GAN: 3.828 G_L1: 1.586 D_real: 0.002 D_fake: 0.186 \n",
            "(epoch: 68, iters: 288, time: 0.107, data: 0.019) G_GAN: 4.995 G_L1: 2.764 D_real: 0.051 D_fake: 0.008 \n",
            "(epoch: 68, iters: 388, time: 0.091, data: 0.003) G_GAN: 0.986 G_L1: 0.102 D_real: 0.589 D_fake: 0.717 \n",
            "(epoch: 68, iters: 488, time: 0.097, data: 0.002) G_GAN: 3.119 G_L1: 0.578 D_real: 0.075 D_fake: 0.059 \n",
            "(epoch: 68, iters: 588, time: 0.071, data: 0.000) G_GAN: 5.100 G_L1: 0.825 D_real: 0.814 D_fake: 0.004 \n",
            "(epoch: 68, iters: 688, time: 0.082, data: 0.000) G_GAN: 3.652 G_L1: 1.320 D_real: 0.004 D_fake: 0.056 \n",
            "(epoch: 68, iters: 788, time: 0.096, data: 0.000) G_GAN: 1.782 G_L1: 1.087 D_real: 0.033 D_fake: 1.827 \n",
            "(epoch: 68, iters: 888, time: 0.066, data: 0.131) G_GAN: 5.332 G_L1: 4.493 D_real: 0.000 D_fake: 0.009 \n",
            "End of epoch 68 / 200 \t Time Taken: 113 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 69, iters: 74, time: 0.071, data: 0.124) G_GAN: 0.786 G_L1: 1.460 D_real: 1.792 D_fake: 0.011 \n",
            "(epoch: 69, iters: 174, time: 0.054, data: 0.000) G_GAN: 7.575 G_L1: 2.384 D_real: 0.002 D_fake: 0.001 \n",
            "(epoch: 69, iters: 274, time: 0.077, data: 0.000) G_GAN: 3.989 G_L1: 0.747 D_real: 0.046 D_fake: 0.548 \n",
            "(epoch: 69, iters: 374, time: 0.095, data: 0.000) G_GAN: 8.856 G_L1: 5.190 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 69, iters: 474, time: 0.081, data: 0.001) G_GAN: 8.636 G_L1: 6.212 D_real: 0.013 D_fake: 0.000 \n",
            "(epoch: 69, iters: 574, time: 0.099, data: 0.000) G_GAN: 7.776 G_L1: 5.253 D_real: 0.124 D_fake: 0.001 \n",
            "(epoch: 69, iters: 674, time: 0.102, data: 0.000) G_GAN: 1.821 G_L1: 0.551 D_real: 0.340 D_fake: 0.606 \n",
            "(epoch: 69, iters: 774, time: 0.102, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.806 D_fake: 0.602 \n",
            "(epoch: 69, iters: 874, time: 0.076, data: 0.177) G_GAN: 0.606 G_L1: 0.001 D_real: 0.663 D_fake: 0.824 \n",
            "End of epoch 69 / 200 \t Time Taken: 113 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 70, iters: 60, time: 0.096, data: 0.126) G_GAN: 3.929 G_L1: 2.263 D_real: 0.001 D_fake: 0.083 \n",
            "(epoch: 70, iters: 160, time: 0.059, data: 0.000) G_GAN: 8.272 G_L1: 8.526 D_real: 0.002 D_fake: 0.001 \n",
            "saving the latest model (epoch 70, total_iters 55000)\n",
            "(epoch: 70, iters: 260, time: 0.105, data: 0.000) G_GAN: 3.977 G_L1: 1.101 D_real: 0.007 D_fake: 0.053 \n",
            "(epoch: 70, iters: 360, time: 0.087, data: 0.107) G_GAN: 5.579 G_L1: 1.939 D_real: 0.036 D_fake: 0.004 \n",
            "(epoch: 70, iters: 460, time: 0.086, data: 0.108) G_GAN: 2.022 G_L1: 0.825 D_real: 0.206 D_fake: 0.249 \n",
            "(epoch: 70, iters: 560, time: 0.075, data: 0.000) G_GAN: 0.757 G_L1: 0.001 D_real: 0.815 D_fake: 0.619 \n",
            "(epoch: 70, iters: 660, time: 0.080, data: 0.000) G_GAN: 2.094 G_L1: 3.577 D_real: 0.002 D_fake: 0.110 \n",
            "(epoch: 70, iters: 760, time: 0.090, data: 0.000) G_GAN: 4.455 G_L1: 3.478 D_real: 0.060 D_fake: 0.022 \n",
            "(epoch: 70, iters: 860, time: 0.090, data: 0.000) G_GAN: 0.799 G_L1: 0.000 D_real: 0.838 D_fake: 0.572 \n",
            "End of epoch 70 / 200 \t Time Taken: 114 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 71, iters: 46, time: 0.082, data: 0.000) G_GAN: 1.129 G_L1: 0.330 D_real: 0.569 D_fake: 0.691 \n",
            "(epoch: 71, iters: 146, time: 0.112, data: 0.002) G_GAN: 3.816 G_L1: 1.167 D_real: 0.014 D_fake: 0.336 \n",
            "(epoch: 71, iters: 246, time: 0.082, data: 0.000) G_GAN: 3.651 G_L1: 8.089 D_real: 0.065 D_fake: 2.081 \n",
            "(epoch: 71, iters: 346, time: 0.083, data: 0.000) G_GAN: 4.721 G_L1: 1.251 D_real: 0.095 D_fake: 0.012 \n",
            "(epoch: 71, iters: 446, time: 0.079, data: 0.000) G_GAN: 3.347 G_L1: 1.771 D_real: 0.035 D_fake: 0.064 \n",
            "(epoch: 71, iters: 546, time: 0.094, data: 0.000) G_GAN: 0.665 G_L1: 0.000 D_real: 0.615 D_fake: 0.785 \n",
            "(epoch: 71, iters: 646, time: 0.093, data: 0.000) G_GAN: 7.385 G_L1: 4.548 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 71, iters: 746, time: 0.101, data: 0.000) G_GAN: 4.561 G_L1: 1.923 D_real: 0.007 D_fake: 0.027 \n",
            "(epoch: 71, iters: 846, time: 0.092, data: 0.000) G_GAN: 6.454 G_L1: 1.283 D_real: 0.042 D_fake: 0.005 \n",
            "End of epoch 71 / 200 \t Time Taken: 114 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 72, iters: 32, time: 0.092, data: 0.007) G_GAN: 6.694 G_L1: 1.205 D_real: 0.133 D_fake: 0.001 \n",
            "(epoch: 72, iters: 132, time: 0.101, data: 0.214) G_GAN: 7.978 G_L1: 3.274 D_real: 0.312 D_fake: 0.000 \n",
            "(epoch: 72, iters: 232, time: 0.098, data: 0.000) G_GAN: 6.525 G_L1: 1.539 D_real: 0.004 D_fake: 0.002 \n",
            "(epoch: 72, iters: 332, time: 0.107, data: 0.000) G_GAN: 0.707 G_L1: 0.000 D_real: 0.715 D_fake: 0.712 \n",
            "(epoch: 72, iters: 432, time: 0.095, data: 0.000) G_GAN: 9.594 G_L1: 5.969 D_real: 0.023 D_fake: 0.000 \n",
            "(epoch: 72, iters: 532, time: 0.084, data: 0.000) G_GAN: 0.717 G_L1: 0.001 D_real: 0.564 D_fake: 0.890 \n",
            "(epoch: 72, iters: 632, time: 0.085, data: 0.000) G_GAN: 7.315 G_L1: 1.317 D_real: 0.064 D_fake: 0.001 \n",
            "(epoch: 72, iters: 732, time: 0.079, data: 0.000) G_GAN: 3.983 G_L1: 2.261 D_real: 0.456 D_fake: 0.004 \n",
            "(epoch: 72, iters: 832, time: 0.082, data: 0.000) G_GAN: 6.964 G_L1: 7.038 D_real: 0.005 D_fake: 0.002 \n",
            "End of epoch 72 / 200 \t Time Taken: 112 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 73, iters: 18, time: 0.084, data: 0.000) G_GAN: 8.653 G_L1: 2.685 D_real: 0.020 D_fake: 0.000 \n",
            "(epoch: 73, iters: 118, time: 0.071, data: 0.000) G_GAN: 5.525 G_L1: 34.363 D_real: 1.103 D_fake: 0.003 \n",
            "(epoch: 73, iters: 218, time: 0.084, data: 0.000) G_GAN: 5.066 G_L1: 4.121 D_real: 0.002 D_fake: 0.010 \n",
            "(epoch: 73, iters: 318, time: 0.092, data: 0.000) G_GAN: 10.414 G_L1: 6.436 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 73, iters: 418, time: 0.078, data: 0.012) G_GAN: 5.375 G_L1: 2.281 D_real: 0.028 D_fake: 0.006 \n",
            "(epoch: 73, iters: 518, time: 0.071, data: 0.120) G_GAN: 0.658 G_L1: 0.000 D_real: 0.645 D_fake: 0.760 \n",
            "(epoch: 73, iters: 618, time: 0.090, data: 0.163) G_GAN: 0.806 G_L1: 0.000 D_real: 0.863 D_fake: 0.554 \n",
            "(epoch: 73, iters: 718, time: 0.094, data: 0.001) G_GAN: 7.429 G_L1: 7.564 D_real: 0.007 D_fake: 0.001 \n",
            "(epoch: 73, iters: 818, time: 0.089, data: 0.000) G_GAN: 7.660 G_L1: 4.352 D_real: 0.013 D_fake: 0.001 \n",
            "End of epoch 73 / 200 \t Time Taken: 110 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 74, iters: 4, time: 0.085, data: 0.000) G_GAN: 2.432 G_L1: 2.094 D_real: 0.135 D_fake: 0.125 \n",
            "(epoch: 74, iters: 104, time: 0.084, data: 0.219) G_GAN: 0.773 G_L1: 0.015 D_real: 0.724 D_fake: 0.629 \n",
            "(epoch: 74, iters: 204, time: 0.076, data: 0.003) G_GAN: 6.676 G_L1: 3.739 D_real: 0.164 D_fake: 0.001 \n",
            "(epoch: 74, iters: 304, time: 0.099, data: 0.154) G_GAN: 3.530 G_L1: 5.291 D_real: 0.002 D_fake: 0.058 \n",
            "(epoch: 74, iters: 404, time: 0.089, data: 0.232) G_GAN: 0.722 G_L1: 0.000 D_real: 0.773 D_fake: 0.625 \n",
            "(epoch: 74, iters: 504, time: 0.073, data: 0.095) G_GAN: 6.923 G_L1: 1.770 D_real: 0.016 D_fake: 1.185 \n",
            "(epoch: 74, iters: 604, time: 0.104, data: 0.195) G_GAN: 0.780 G_L1: 0.000 D_real: 0.857 D_fake: 0.562 \n",
            "(epoch: 74, iters: 704, time: 0.068, data: 0.041) G_GAN: 7.514 G_L1: 15.475 D_real: 0.008 D_fake: 0.001 \n",
            "(epoch: 74, iters: 804, time: 0.094, data: 0.288) G_GAN: 7.242 G_L1: 6.043 D_real: 0.026 D_fake: 0.001 \n",
            "(epoch: 74, iters: 904, time: 0.080, data: 0.032) G_GAN: 4.905 G_L1: 5.558 D_real: 0.012 D_fake: 0.014 \n",
            "End of epoch 74 / 200 \t Time Taken: 110 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 75, iters: 90, time: 0.088, data: 0.102) G_GAN: 7.031 G_L1: 6.093 D_real: 0.018 D_fake: 0.002 \n",
            "(epoch: 75, iters: 190, time: 0.081, data: 0.000) G_GAN: 2.383 G_L1: 0.650 D_real: 0.193 D_fake: 0.160 \n",
            "(epoch: 75, iters: 290, time: 0.073, data: 0.000) G_GAN: 5.368 G_L1: 1.534 D_real: 0.097 D_fake: 0.003 \n",
            "(epoch: 75, iters: 390, time: 0.086, data: 0.001) G_GAN: 4.375 G_L1: 1.679 D_real: 0.005 D_fake: 0.012 \n",
            "(epoch: 75, iters: 490, time: 0.092, data: 0.001) G_GAN: 5.475 G_L1: 3.061 D_real: 0.002 D_fake: 0.006 \n",
            "(epoch: 75, iters: 590, time: 0.078, data: 0.000) G_GAN: 4.859 G_L1: 9.906 D_real: 0.001 D_fake: 0.015 \n",
            "saving the latest model (epoch 75, total_iters 60000)\n",
            "(epoch: 75, iters: 690, time: 0.104, data: 0.000) G_GAN: 3.703 G_L1: 1.043 D_real: 0.016 D_fake: 0.168 \n",
            "(epoch: 75, iters: 790, time: 0.076, data: 0.000) G_GAN: 3.959 G_L1: 3.055 D_real: 0.003 D_fake: 0.040 \n",
            "(epoch: 75, iters: 890, time: 0.079, data: 0.000) G_GAN: 0.688 G_L1: 0.000 D_real: 0.680 D_fake: 0.714 \n",
            "End of epoch 75 / 200 \t Time Taken: 113 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 76, iters: 76, time: 0.083, data: 0.000) G_GAN: 4.773 G_L1: 0.942 D_real: 0.010 D_fake: 0.037 \n",
            "(epoch: 76, iters: 176, time: 0.078, data: 0.000) G_GAN: 2.748 G_L1: 0.733 D_real: 0.048 D_fake: 0.186 \n",
            "(epoch: 76, iters: 276, time: 0.084, data: 0.000) G_GAN: 2.540 G_L1: 1.547 D_real: 0.144 D_fake: 0.276 \n",
            "(epoch: 76, iters: 376, time: 0.104, data: 0.000) G_GAN: 0.848 G_L1: 0.000 D_real: 0.899 D_fake: 0.552 \n",
            "(epoch: 76, iters: 476, time: 0.094, data: 0.000) G_GAN: 3.206 G_L1: 1.391 D_real: 0.123 D_fake: 0.024 \n",
            "(epoch: 76, iters: 576, time: 0.091, data: 0.000) G_GAN: 3.750 G_L1: 0.837 D_real: 0.013 D_fake: 1.035 \n",
            "(epoch: 76, iters: 676, time: 0.070, data: 0.000) G_GAN: 5.150 G_L1: 2.508 D_real: 0.000 D_fake: 0.581 \n",
            "(epoch: 76, iters: 776, time: 0.070, data: 0.000) G_GAN: 4.422 G_L1: 2.956 D_real: 0.001 D_fake: 0.017 \n",
            "(epoch: 76, iters: 876, time: 0.095, data: 0.001) G_GAN: 1.064 G_L1: 0.676 D_real: 1.253 D_fake: 0.049 \n",
            "End of epoch 76 / 200 \t Time Taken: 111 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 77, iters: 62, time: 0.093, data: 0.001) G_GAN: 6.908 G_L1: 3.241 D_real: 0.071 D_fake: 0.000 \n",
            "(epoch: 77, iters: 162, time: 0.088, data: 0.000) G_GAN: 5.874 G_L1: 1.823 D_real: 0.036 D_fake: 0.002 \n",
            "(epoch: 77, iters: 262, time: 0.106, data: 0.000) G_GAN: 0.687 G_L1: 0.000 D_real: 0.677 D_fake: 0.715 \n",
            "(epoch: 77, iters: 362, time: 0.088, data: 0.000) G_GAN: 5.639 G_L1: 1.177 D_real: 0.030 D_fake: 0.005 \n",
            "(epoch: 77, iters: 462, time: 0.104, data: 0.001) G_GAN: 3.326 G_L1: 8.885 D_real: 0.001 D_fake: 0.702 \n",
            "(epoch: 77, iters: 562, time: 0.098, data: 0.000) G_GAN: 4.984 G_L1: 6.333 D_real: 0.006 D_fake: 0.015 \n",
            "(epoch: 77, iters: 662, time: 0.102, data: 0.000) G_GAN: 0.629 G_L1: 0.000 D_real: 0.615 D_fake: 0.801 \n",
            "(epoch: 77, iters: 762, time: 0.087, data: 0.000) G_GAN: 6.054 G_L1: 11.104 D_real: 0.166 D_fake: 0.003 \n",
            "(epoch: 77, iters: 862, time: 0.091, data: 0.000) G_GAN: 0.664 G_L1: 0.000 D_real: 0.667 D_fake: 0.734 \n",
            "End of epoch 77 / 200 \t Time Taken: 113 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 78, iters: 48, time: 0.075, data: 0.000) G_GAN: 8.902 G_L1: 3.363 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 78, iters: 148, time: 0.074, data: 0.059) G_GAN: 0.676 G_L1: 0.000 D_real: 0.696 D_fake: 0.708 \n",
            "(epoch: 78, iters: 248, time: 0.068, data: 0.072) G_GAN: 4.651 G_L1: 1.848 D_real: 0.246 D_fake: 0.002 \n",
            "(epoch: 78, iters: 348, time: 0.085, data: 0.001) G_GAN: 4.608 G_L1: 7.171 D_real: 0.001 D_fake: 0.005 \n",
            "(epoch: 78, iters: 448, time: 0.095, data: 0.000) G_GAN: 3.513 G_L1: 3.956 D_real: 0.047 D_fake: 0.063 \n",
            "(epoch: 78, iters: 548, time: 0.106, data: 0.000) G_GAN: 9.132 G_L1: 4.538 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 78, iters: 648, time: 0.108, data: 0.000) G_GAN: 7.465 G_L1: 6.084 D_real: 0.115 D_fake: 0.001 \n",
            "(epoch: 78, iters: 748, time: 0.088, data: 0.000) G_GAN: 0.755 G_L1: 0.000 D_real: 0.787 D_fake: 0.621 \n",
            "(epoch: 78, iters: 848, time: 0.107, data: 0.000) G_GAN: 5.942 G_L1: 3.170 D_real: 0.002 D_fake: 0.003 \n",
            "End of epoch 78 / 200 \t Time Taken: 112 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 79, iters: 34, time: 0.078, data: 0.000) G_GAN: 0.618 G_L1: 0.000 D_real: 0.594 D_fake: 0.830 \n",
            "(epoch: 79, iters: 134, time: 0.080, data: 0.000) G_GAN: 9.545 G_L1: 2.646 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 79, iters: 234, time: 0.094, data: 0.000) G_GAN: 6.828 G_L1: 5.709 D_real: 0.038 D_fake: 0.004 \n",
            "(epoch: 79, iters: 334, time: 0.084, data: 0.014) G_GAN: 4.452 G_L1: 4.288 D_real: 0.001 D_fake: 0.031 \n",
            "(epoch: 79, iters: 434, time: 0.105, data: 0.211) G_GAN: 4.451 G_L1: 0.375 D_real: 0.142 D_fake: 0.008 \n",
            "(epoch: 79, iters: 534, time: 0.085, data: 0.150) G_GAN: 7.238 G_L1: 2.812 D_real: 0.028 D_fake: 0.001 \n",
            "(epoch: 79, iters: 634, time: 0.106, data: 0.082) G_GAN: 6.561 G_L1: 5.307 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 79, iters: 734, time: 0.077, data: 0.123) G_GAN: 0.722 G_L1: 0.000 D_real: 0.754 D_fake: 0.651 \n",
            "(epoch: 79, iters: 834, time: 0.068, data: 0.125) G_GAN: 6.988 G_L1: 0.037 D_real: 0.590 D_fake: 0.001 \n",
            "End of epoch 79 / 200 \t Time Taken: 114 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 80, iters: 20, time: 0.080, data: 0.174) G_GAN: 2.677 G_L1: 1.225 D_real: 0.140 D_fake: 0.674 \n",
            "(epoch: 80, iters: 120, time: 0.104, data: 0.192) G_GAN: 3.982 G_L1: 5.719 D_real: 0.001 D_fake: 0.063 \n",
            "(epoch: 80, iters: 220, time: 0.080, data: 0.099) G_GAN: 3.813 G_L1: 8.485 D_real: 0.000 D_fake: 0.082 \n",
            "(epoch: 80, iters: 320, time: 0.095, data: 0.133) G_GAN: 0.666 G_L1: 0.000 D_real: 0.678 D_fake: 0.721 \n",
            "(epoch: 80, iters: 420, time: 0.085, data: 0.203) G_GAN: 8.971 G_L1: 0.758 D_real: 0.110 D_fake: 0.000 \n",
            "(epoch: 80, iters: 520, time: 0.079, data: 0.005) G_GAN: 7.076 G_L1: 3.807 D_real: 0.008 D_fake: 0.001 \n",
            "(epoch: 80, iters: 620, time: 0.092, data: 0.000) G_GAN: 7.835 G_L1: 6.837 D_real: 0.008 D_fake: 0.001 \n",
            "(epoch: 80, iters: 720, time: 0.097, data: 0.000) G_GAN: 8.874 G_L1: 2.811 D_real: 0.005 D_fake: 0.000 \n",
            "(epoch: 80, iters: 820, time: 0.069, data: 0.099) G_GAN: 6.188 G_L1: 8.454 D_real: 0.001 D_fake: 0.004 \n",
            "End of epoch 80 / 200 \t Time Taken: 115 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 81, iters: 6, time: 0.077, data: 0.000) G_GAN: 9.183 G_L1: 4.289 D_real: 1.927 D_fake: 0.000 \n",
            "(epoch: 81, iters: 106, time: 0.060, data: 0.000) G_GAN: 6.769 G_L1: 9.257 D_real: 0.014 D_fake: 0.002 \n",
            "saving the latest model (epoch 81, total_iters 65000)\n",
            "(epoch: 81, iters: 206, time: 0.077, data: 0.003) G_GAN: 5.011 G_L1: 1.587 D_real: 0.061 D_fake: 0.009 \n",
            "(epoch: 81, iters: 306, time: 0.112, data: 0.214) G_GAN: 0.692 G_L1: 0.000 D_real: 0.694 D_fake: 0.704 \n",
            "(epoch: 81, iters: 406, time: 0.073, data: 0.029) G_GAN: 9.639 G_L1: 2.147 D_real: 0.191 D_fake: 0.000 \n",
            "(epoch: 81, iters: 506, time: 0.100, data: 0.095) G_GAN: 0.884 G_L1: 0.001 D_real: 0.997 D_fake: 0.498 \n",
            "(epoch: 81, iters: 606, time: 0.069, data: 0.171) G_GAN: 5.868 G_L1: 5.256 D_real: 0.148 D_fake: 0.002 \n",
            "(epoch: 81, iters: 706, time: 0.108, data: 0.164) G_GAN: 3.294 G_L1: 1.993 D_real: 0.002 D_fake: 0.285 \n",
            "(epoch: 81, iters: 806, time: 0.097, data: 0.076) G_GAN: 0.423 G_L1: 0.005 D_real: 0.333 D_fake: 1.279 \n",
            "(epoch: 81, iters: 906, time: 0.068, data: 0.150) G_GAN: 4.466 G_L1: 7.304 D_real: 0.005 D_fake: 0.039 \n",
            "End of epoch 81 / 200 \t Time Taken: 116 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 82, iters: 92, time: 0.088, data: 0.090) G_GAN: 7.835 G_L1: 6.560 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 82, iters: 192, time: 0.073, data: 0.200) G_GAN: 3.035 G_L1: 0.796 D_real: 0.042 D_fake: 0.126 \n",
            "(epoch: 82, iters: 292, time: 0.092, data: 0.000) G_GAN: 5.310 G_L1: 3.148 D_real: 0.004 D_fake: 1.554 \n",
            "(epoch: 82, iters: 392, time: 0.078, data: 0.000) G_GAN: 8.258 G_L1: 4.161 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 82, iters: 492, time: 0.095, data: 0.000) G_GAN: 8.528 G_L1: 6.936 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 82, iters: 592, time: 0.090, data: 0.002) G_GAN: 8.334 G_L1: 1.997 D_real: 0.002 D_fake: 0.001 \n",
            "(epoch: 82, iters: 692, time: 0.085, data: 0.000) G_GAN: 7.233 G_L1: 4.668 D_real: 0.039 D_fake: 0.001 \n",
            "(epoch: 82, iters: 792, time: 0.079, data: 0.000) G_GAN: 4.753 G_L1: 1.183 D_real: 0.146 D_fake: 0.007 \n",
            "(epoch: 82, iters: 892, time: 0.080, data: 0.000) G_GAN: 6.030 G_L1: 1.555 D_real: 0.004 D_fake: 0.325 \n",
            "End of epoch 82 / 200 \t Time Taken: 114 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 83, iters: 78, time: 0.087, data: 0.000) G_GAN: 4.001 G_L1: 2.409 D_real: 0.000 D_fake: 0.339 \n",
            "(epoch: 83, iters: 178, time: 0.104, data: 0.000) G_GAN: 0.691 G_L1: 0.000 D_real: 0.672 D_fake: 0.728 \n",
            "(epoch: 83, iters: 278, time: 0.089, data: 0.000) G_GAN: 4.822 G_L1: 5.297 D_real: 0.000 D_fake: 0.044 \n",
            "(epoch: 83, iters: 378, time: 0.072, data: 0.000) G_GAN: 4.794 G_L1: 2.968 D_real: 0.010 D_fake: 0.014 \n",
            "(epoch: 83, iters: 478, time: 0.104, data: 0.000) G_GAN: 9.317 G_L1: 3.353 D_real: 0.029 D_fake: 0.000 \n",
            "(epoch: 83, iters: 578, time: 0.095, data: 0.000) G_GAN: 9.874 G_L1: 1.812 D_real: 0.288 D_fake: 0.000 \n",
            "(epoch: 83, iters: 678, time: 0.100, data: 0.001) G_GAN: 0.713 G_L1: 0.001 D_real: 0.729 D_fake: 0.664 \n",
            "(epoch: 83, iters: 778, time: 0.093, data: 0.005) G_GAN: 8.188 G_L1: 6.542 D_real: 0.047 D_fake: 0.001 \n",
            "(epoch: 83, iters: 878, time: 0.087, data: 0.000) G_GAN: 6.608 G_L1: 2.346 D_real: 0.004 D_fake: 0.003 \n",
            "End of epoch 83 / 200 \t Time Taken: 115 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 84, iters: 64, time: 0.115, data: 0.000) G_GAN: 0.724 G_L1: 0.000 D_real: 0.760 D_fake: 0.638 \n",
            "(epoch: 84, iters: 164, time: 0.089, data: 0.186) G_GAN: 6.382 G_L1: 6.557 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 84, iters: 264, time: 0.084, data: 0.200) G_GAN: 7.440 G_L1: 1.480 D_real: 0.046 D_fake: 0.001 \n",
            "(epoch: 84, iters: 364, time: 0.099, data: 0.300) G_GAN: 6.947 G_L1: 1.847 D_real: 0.027 D_fake: 0.001 \n",
            "(epoch: 84, iters: 464, time: 0.080, data: 0.002) G_GAN: 4.085 G_L1: 0.604 D_real: 0.835 D_fake: 0.000 \n",
            "(epoch: 84, iters: 564, time: 0.077, data: 0.000) G_GAN: 2.062 G_L1: 0.086 D_real: 0.956 D_fake: 0.064 \n",
            "(epoch: 84, iters: 664, time: 0.072, data: 0.197) G_GAN: 0.701 G_L1: 0.000 D_real: 0.730 D_fake: 0.689 \n",
            "(epoch: 84, iters: 764, time: 0.063, data: 0.168) G_GAN: 6.389 G_L1: 4.654 D_real: 0.003 D_fake: 0.002 \n",
            "(epoch: 84, iters: 864, time: 0.098, data: 0.202) G_GAN: 0.800 G_L1: 0.004 D_real: 0.807 D_fake: 0.596 \n",
            "End of epoch 84 / 200 \t Time Taken: 116 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 85, iters: 50, time: 0.052, data: 0.003) G_GAN: 7.864 G_L1: 3.023 D_real: 0.006 D_fake: 0.001 \n",
            "(epoch: 85, iters: 150, time: 0.074, data: 0.000) G_GAN: 0.608 G_L1: 0.001 D_real: 0.582 D_fake: 0.914 \n",
            "(epoch: 85, iters: 250, time: 0.077, data: 0.000) G_GAN: 8.243 G_L1: 7.208 D_real: 0.007 D_fake: 0.000 \n",
            "(epoch: 85, iters: 350, time: 0.071, data: 0.000) G_GAN: 5.479 G_L1: 1.493 D_real: 0.006 D_fake: 0.890 \n",
            "(epoch: 85, iters: 450, time: 0.091, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.682 D_fake: 0.726 \n",
            "(epoch: 85, iters: 550, time: 0.081, data: 0.000) G_GAN: 10.929 G_L1: 1.227 D_real: 0.012 D_fake: 0.000 \n",
            "(epoch: 85, iters: 650, time: 0.090, data: 0.001) G_GAN: 3.255 G_L1: 1.601 D_real: 0.053 D_fake: 0.091 \n",
            "(epoch: 85, iters: 750, time: 0.070, data: 0.000) G_GAN: 4.873 G_L1: 2.900 D_real: 0.002 D_fake: 0.012 \n",
            "(epoch: 85, iters: 850, time: 0.106, data: 0.000) G_GAN: 1.733 G_L1: 1.541 D_real: 0.925 D_fake: 0.008 \n",
            "End of epoch 85 / 200 \t Time Taken: 115 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 86, iters: 36, time: 0.096, data: 0.000) G_GAN: 6.320 G_L1: 15.167 D_real: 0.029 D_fake: 0.004 \n",
            "(epoch: 86, iters: 136, time: 0.102, data: 0.000) G_GAN: 4.274 G_L1: 3.167 D_real: 0.264 D_fake: 0.006 \n",
            "(epoch: 86, iters: 236, time: 0.080, data: 0.000) G_GAN: 4.864 G_L1: 1.920 D_real: 0.004 D_fake: 0.010 \n",
            "(epoch: 86, iters: 336, time: 0.099, data: 0.000) G_GAN: 0.726 G_L1: 0.000 D_real: 0.685 D_fake: 0.707 \n",
            "(epoch: 86, iters: 436, time: 0.099, data: 0.004) G_GAN: 3.817 G_L1: 10.430 D_real: 0.000 D_fake: 0.050 \n",
            "(epoch: 86, iters: 536, time: 0.088, data: 0.002) G_GAN: 4.175 G_L1: 0.238 D_real: 0.032 D_fake: 0.013 \n",
            "saving the latest model (epoch 86, total_iters 70000)\n",
            "(epoch: 86, iters: 636, time: 0.088, data: 0.000) G_GAN: 3.688 G_L1: 2.465 D_real: 0.003 D_fake: 0.052 \n",
            "(epoch: 86, iters: 736, time: 0.089, data: 0.054) G_GAN: 5.434 G_L1: 2.626 D_real: 0.001 D_fake: 0.007 \n",
            "(epoch: 86, iters: 836, time: 0.100, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.832 D_fake: 0.577 \n",
            "End of epoch 86 / 200 \t Time Taken: 117 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 87, iters: 22, time: 0.097, data: 0.003) G_GAN: 9.025 G_L1: 4.790 D_real: 0.110 D_fake: 0.000 \n",
            "(epoch: 87, iters: 122, time: 0.105, data: 0.000) G_GAN: 2.672 G_L1: 0.141 D_real: 0.123 D_fake: 1.104 \n",
            "(epoch: 87, iters: 222, time: 0.106, data: 0.000) G_GAN: 3.476 G_L1: 1.986 D_real: 0.048 D_fake: 0.101 \n",
            "(epoch: 87, iters: 322, time: 0.097, data: 0.000) G_GAN: 5.039 G_L1: 1.055 D_real: 0.018 D_fake: 0.437 \n",
            "(epoch: 87, iters: 422, time: 0.100, data: 0.003) G_GAN: 3.199 G_L1: 1.345 D_real: 0.243 D_fake: 0.009 \n",
            "(epoch: 87, iters: 522, time: 0.086, data: 0.003) G_GAN: 3.151 G_L1: 1.606 D_real: 0.154 D_fake: 0.030 \n",
            "(epoch: 87, iters: 622, time: 0.098, data: 0.044) G_GAN: 5.759 G_L1: 2.876 D_real: 0.000 D_fake: 1.869 \n",
            "(epoch: 87, iters: 722, time: 0.101, data: 0.005) G_GAN: 6.895 G_L1: 6.522 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 87, iters: 822, time: 0.086, data: 0.003) G_GAN: 6.411 G_L1: 0.404 D_real: 0.201 D_fake: 0.001 \n",
            "End of epoch 87 / 200 \t Time Taken: 113 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 88, iters: 8, time: 0.100, data: 0.000) G_GAN: 7.405 G_L1: 3.774 D_real: 0.109 D_fake: 0.000 \n",
            "(epoch: 88, iters: 108, time: 0.086, data: 0.096) G_GAN: 4.082 G_L1: 0.909 D_real: 0.023 D_fake: 0.022 \n",
            "(epoch: 88, iters: 208, time: 0.099, data: 0.002) G_GAN: 2.058 G_L1: 0.740 D_real: 0.302 D_fake: 0.009 \n",
            "(epoch: 88, iters: 308, time: 0.092, data: 0.134) G_GAN: 6.163 G_L1: 12.150 D_real: 0.001 D_fake: 0.005 \n",
            "(epoch: 88, iters: 408, time: 0.074, data: 0.069) G_GAN: 9.003 G_L1: 1.825 D_real: 0.025 D_fake: 0.000 \n",
            "(epoch: 88, iters: 508, time: 0.070, data: 0.130) G_GAN: 0.727 G_L1: 0.000 D_real: 0.737 D_fake: 0.712 \n",
            "(epoch: 88, iters: 608, time: 0.103, data: 0.002) G_GAN: 2.064 G_L1: 1.917 D_real: 2.040 D_fake: 0.003 \n",
            "(epoch: 88, iters: 708, time: 0.090, data: 0.000) G_GAN: 9.565 G_L1: 11.287 D_real: 0.018 D_fake: 0.000 \n",
            "(epoch: 88, iters: 808, time: 0.070, data: 0.000) G_GAN: 1.699 G_L1: 0.085 D_real: 0.511 D_fake: 0.158 \n",
            "(epoch: 88, iters: 908, time: 0.068, data: 0.000) G_GAN: 0.849 G_L1: 0.000 D_real: 1.039 D_fake: 0.481 \n",
            "End of epoch 88 / 200 \t Time Taken: 113 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 89, iters: 94, time: 0.060, data: 0.001) G_GAN: 3.486 G_L1: 1.718 D_real: 0.022 D_fake: 0.535 \n",
            "(epoch: 89, iters: 194, time: 0.094, data: 0.000) G_GAN: 3.560 G_L1: 1.016 D_real: 0.025 D_fake: 0.381 \n",
            "(epoch: 89, iters: 294, time: 0.104, data: 0.000) G_GAN: 0.625 G_L1: 0.000 D_real: 0.565 D_fake: 0.875 \n",
            "(epoch: 89, iters: 394, time: 0.082, data: 0.000) G_GAN: 6.689 G_L1: 1.062 D_real: 0.397 D_fake: 0.001 \n",
            "(epoch: 89, iters: 494, time: 0.098, data: 0.000) G_GAN: 7.665 G_L1: 5.005 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 89, iters: 594, time: 0.057, data: 0.000) G_GAN: 9.121 G_L1: 2.532 D_real: 0.039 D_fake: 0.000 \n",
            "(epoch: 89, iters: 694, time: 0.096, data: 0.000) G_GAN: 6.853 G_L1: 5.761 D_real: 0.003 D_fake: 0.003 \n",
            "(epoch: 89, iters: 794, time: 0.077, data: 0.001) G_GAN: 6.781 G_L1: 7.081 D_real: 0.044 D_fake: 0.001 \n",
            "(epoch: 89, iters: 894, time: 0.088, data: 0.000) G_GAN: 9.319 G_L1: 5.840 D_real: 0.001 D_fake: 0.000 \n",
            "End of epoch 89 / 200 \t Time Taken: 113 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 90, iters: 80, time: 0.065, data: 0.000) G_GAN: 4.192 G_L1: 1.717 D_real: 0.100 D_fake: 0.034 \n",
            "(epoch: 90, iters: 180, time: 0.059, data: 0.093) G_GAN: 3.408 G_L1: 4.683 D_real: 0.004 D_fake: 0.070 \n",
            "(epoch: 90, iters: 280, time: 0.096, data: 0.000) G_GAN: 0.686 G_L1: 0.000 D_real: 0.687 D_fake: 0.703 \n",
            "(epoch: 90, iters: 380, time: 0.079, data: 0.001) G_GAN: 0.693 G_L1: 0.001 D_real: 0.723 D_fake: 0.689 \n",
            "(epoch: 90, iters: 480, time: 0.093, data: 0.000) G_GAN: 0.545 G_L1: 0.000 D_real: 0.503 D_fake: 0.944 \n",
            "(epoch: 90, iters: 580, time: 0.088, data: 0.000) G_GAN: 6.709 G_L1: 1.119 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 90, iters: 680, time: 0.107, data: 0.000) G_GAN: 6.048 G_L1: 3.334 D_real: 0.610 D_fake: 0.000 \n",
            "(epoch: 90, iters: 780, time: 0.057, data: 0.003) G_GAN: 3.452 G_L1: 1.834 D_real: 0.003 D_fake: 0.474 \n",
            "(epoch: 90, iters: 880, time: 0.081, data: 0.008) G_GAN: 3.867 G_L1: 1.508 D_real: 0.046 D_fake: 0.748 \n",
            "End of epoch 90 / 200 \t Time Taken: 113 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 91, iters: 66, time: 0.105, data: 0.000) G_GAN: 10.551 G_L1: 1.325 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 91, iters: 166, time: 0.100, data: 0.000) G_GAN: 6.787 G_L1: 1.585 D_real: 0.093 D_fake: 0.002 \n",
            "(epoch: 91, iters: 266, time: 0.103, data: 0.000) G_GAN: 0.903 G_L1: 0.296 D_real: 1.053 D_fake: 0.091 \n",
            "(epoch: 91, iters: 366, time: 0.089, data: 0.000) G_GAN: 7.792 G_L1: 11.862 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 91, iters: 466, time: 0.086, data: 0.000) G_GAN: 6.414 G_L1: 2.462 D_real: 0.010 D_fake: 0.004 \n",
            "(epoch: 91, iters: 566, time: 0.098, data: 0.000) G_GAN: 8.397 G_L1: 2.449 D_real: 0.004 D_fake: 0.000 \n",
            "(epoch: 91, iters: 666, time: 0.110, data: 0.000) G_GAN: 5.318 G_L1: 7.222 D_real: 0.000 D_fake: 0.021 \n",
            "(epoch: 91, iters: 766, time: 0.099, data: 0.000) G_GAN: 3.853 G_L1: 2.358 D_real: 0.052 D_fake: 0.036 \n",
            "(epoch: 91, iters: 866, time: 0.113, data: 0.000) G_GAN: 6.987 G_L1: 3.018 D_real: 0.002 D_fake: 0.002 \n",
            "End of epoch 91 / 200 \t Time Taken: 112 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 92, iters: 52, time: 0.113, data: 0.000) G_GAN: 0.656 G_L1: 0.001 D_real: 0.646 D_fake: 0.790 \n",
            "saving the latest model (epoch 92, total_iters 75000)\n",
            "(epoch: 92, iters: 152, time: 0.084, data: 0.005) G_GAN: 4.002 G_L1: 2.529 D_real: 0.014 D_fake: 0.704 \n",
            "(epoch: 92, iters: 252, time: 0.076, data: 0.002) G_GAN: 7.819 G_L1: 4.608 D_real: 0.011 D_fake: 0.003 \n",
            "(epoch: 92, iters: 352, time: 0.082, data: 0.216) G_GAN: 0.765 G_L1: 0.000 D_real: 0.846 D_fake: 0.574 \n",
            "(epoch: 92, iters: 452, time: 0.095, data: 0.133) G_GAN: 6.022 G_L1: 2.709 D_real: 0.042 D_fake: 0.004 \n",
            "(epoch: 92, iters: 552, time: 0.089, data: 0.111) G_GAN: 3.424 G_L1: 2.570 D_real: 0.001 D_fake: 0.247 \n",
            "(epoch: 92, iters: 652, time: 0.071, data: 0.116) G_GAN: 2.909 G_L1: 0.568 D_real: 0.139 D_fake: 0.459 \n",
            "(epoch: 92, iters: 752, time: 0.087, data: 0.118) G_GAN: 10.324 G_L1: 4.237 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 92, iters: 852, time: 0.061, data: 0.116) G_GAN: 6.372 G_L1: 3.558 D_real: 0.011 D_fake: 0.005 \n",
            "End of epoch 92 / 200 \t Time Taken: 112 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 93, iters: 38, time: 0.100, data: 0.098) G_GAN: 9.116 G_L1: 2.710 D_real: 0.003 D_fake: 0.000 \n",
            "(epoch: 93, iters: 138, time: 0.098, data: 0.000) G_GAN: 0.745 G_L1: 0.000 D_real: 0.754 D_fake: 0.643 \n",
            "(epoch: 93, iters: 238, time: 0.099, data: 0.000) G_GAN: 3.103 G_L1: 0.708 D_real: 0.051 D_fake: 0.428 \n",
            "(epoch: 93, iters: 338, time: 0.089, data: 0.000) G_GAN: 9.664 G_L1: 1.511 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 93, iters: 438, time: 0.068, data: 0.000) G_GAN: 7.675 G_L1: 2.729 D_real: 0.000 D_fake: 0.997 \n",
            "(epoch: 93, iters: 538, time: 0.098, data: 0.000) G_GAN: 7.387 G_L1: 4.702 D_real: 0.002 D_fake: 0.001 \n",
            "(epoch: 93, iters: 638, time: 0.093, data: 0.000) G_GAN: 5.755 G_L1: 3.538 D_real: 0.054 D_fake: 0.004 \n",
            "(epoch: 93, iters: 738, time: 0.077, data: 0.002) G_GAN: 5.790 G_L1: 11.970 D_real: 0.411 D_fake: 0.001 \n",
            "(epoch: 93, iters: 838, time: 0.053, data: 0.000) G_GAN: 0.704 G_L1: 0.000 D_real: 0.694 D_fake: 0.706 \n",
            "End of epoch 93 / 200 \t Time Taken: 110 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 94, iters: 24, time: 0.090, data: 0.000) G_GAN: 6.635 G_L1: 4.044 D_real: 0.025 D_fake: 0.003 \n",
            "(epoch: 94, iters: 124, time: 0.089, data: 0.002) G_GAN: 6.473 G_L1: 3.716 D_real: 0.255 D_fake: 0.001 \n",
            "(epoch: 94, iters: 224, time: 0.081, data: 0.000) G_GAN: 5.570 G_L1: 10.625 D_real: 0.006 D_fake: 0.006 \n",
            "(epoch: 94, iters: 324, time: 0.085, data: 0.130) G_GAN: 9.437 G_L1: 5.463 D_real: 0.029 D_fake: 0.000 \n",
            "(epoch: 94, iters: 424, time: 0.091, data: 0.163) G_GAN: 3.449 G_L1: 0.708 D_real: 0.016 D_fake: 0.108 \n",
            "(epoch: 94, iters: 524, time: 0.100, data: 0.185) G_GAN: 8.678 G_L1: 4.245 D_real: 0.009 D_fake: 0.000 \n",
            "(epoch: 94, iters: 624, time: 0.076, data: 0.191) G_GAN: 3.807 G_L1: 3.101 D_real: 1.416 D_fake: 0.004 \n",
            "(epoch: 94, iters: 724, time: 0.105, data: 0.089) G_GAN: 4.576 G_L1: 0.352 D_real: 0.062 D_fake: 0.016 \n",
            "(epoch: 94, iters: 824, time: 0.071, data: 0.215) G_GAN: 3.681 G_L1: 3.181 D_real: 0.025 D_fake: 2.641 \n",
            "End of epoch 94 / 200 \t Time Taken: 109 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 95, iters: 10, time: 0.101, data: 0.049) G_GAN: 4.918 G_L1: 6.553 D_real: 0.001 D_fake: 0.014 \n",
            "(epoch: 95, iters: 110, time: 0.097, data: 0.000) G_GAN: 4.059 G_L1: 1.539 D_real: 0.169 D_fake: 0.021 \n",
            "(epoch: 95, iters: 210, time: 0.110, data: 0.001) G_GAN: 6.442 G_L1: 1.444 D_real: 0.081 D_fake: 0.002 \n",
            "(epoch: 95, iters: 310, time: 0.074, data: 0.000) G_GAN: 2.645 G_L1: 1.175 D_real: 0.255 D_fake: 0.049 \n",
            "(epoch: 95, iters: 410, time: 0.070, data: 0.180) G_GAN: 5.821 G_L1: 1.804 D_real: 0.237 D_fake: 0.002 \n",
            "(epoch: 95, iters: 510, time: 0.097, data: 0.150) G_GAN: 4.405 G_L1: 0.776 D_real: 0.077 D_fake: 0.493 \n",
            "(epoch: 95, iters: 610, time: 0.085, data: 0.117) G_GAN: 0.715 G_L1: 0.000 D_real: 0.733 D_fake: 0.669 \n",
            "(epoch: 95, iters: 710, time: 0.060, data: 0.000) G_GAN: 5.781 G_L1: 1.782 D_real: 0.018 D_fake: 0.003 \n",
            "(epoch: 95, iters: 810, time: 0.091, data: 0.000) G_GAN: 8.316 G_L1: 7.136 D_real: 0.002 D_fake: 0.001 \n",
            "(epoch: 95, iters: 910, time: 0.077, data: 0.000) G_GAN: 4.211 G_L1: 5.001 D_real: 0.000 D_fake: 0.442 \n",
            "End of epoch 95 / 200 \t Time Taken: 112 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 96, iters: 96, time: 0.087, data: 0.000) G_GAN: 3.422 G_L1: 1.091 D_real: 0.176 D_fake: 0.282 \n",
            "(epoch: 96, iters: 196, time: 0.069, data: 0.000) G_GAN: 6.651 G_L1: 4.220 D_real: 0.002 D_fake: 0.002 \n",
            "(epoch: 96, iters: 296, time: 0.105, data: 0.000) G_GAN: 0.618 G_L1: 0.001 D_real: 0.587 D_fake: 0.846 \n",
            "(epoch: 96, iters: 396, time: 0.081, data: 0.000) G_GAN: 3.976 G_L1: 3.041 D_real: 0.002 D_fake: 0.043 \n",
            "(epoch: 96, iters: 496, time: 0.091, data: 0.000) G_GAN: 5.968 G_L1: 6.214 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 96, iters: 596, time: 0.078, data: 0.000) G_GAN: 4.650 G_L1: 9.036 D_real: 0.007 D_fake: 0.013 \n",
            "(epoch: 96, iters: 696, time: 0.070, data: 0.000) G_GAN: 3.525 G_L1: 1.730 D_real: 0.191 D_fake: 0.052 \n",
            "(epoch: 96, iters: 796, time: 0.102, data: 0.000) G_GAN: 3.957 G_L1: 1.081 D_real: 0.005 D_fake: 0.640 \n",
            "(epoch: 96, iters: 896, time: 0.104, data: 0.000) G_GAN: 10.333 G_L1: 3.172 D_real: 0.066 D_fake: 0.000 \n",
            "End of epoch 96 / 200 \t Time Taken: 107 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 97, iters: 82, time: 0.094, data: 0.000) G_GAN: 0.658 G_L1: 0.000 D_real: 0.629 D_fake: 0.770 \n",
            "(epoch: 97, iters: 182, time: 0.075, data: 0.142) G_GAN: 3.424 G_L1: 1.343 D_real: 0.360 D_fake: 0.007 \n",
            "(epoch: 97, iters: 282, time: 0.087, data: 0.155) G_GAN: 10.042 G_L1: 1.563 D_real: 0.082 D_fake: 0.000 \n",
            "(epoch: 97, iters: 382, time: 0.078, data: 0.159) G_GAN: 3.026 G_L1: 3.405 D_real: 0.144 D_fake: 0.074 \n",
            "(epoch: 97, iters: 482, time: 0.095, data: 0.007) G_GAN: 0.694 G_L1: 0.000 D_real: 0.690 D_fake: 0.703 \n",
            "saving the latest model (epoch 97, total_iters 80000)\n",
            "(epoch: 97, iters: 582, time: 0.091, data: 0.000) G_GAN: 0.686 G_L1: 0.000 D_real: 0.681 D_fake: 0.709 \n",
            "(epoch: 97, iters: 682, time: 0.087, data: 0.003) G_GAN: 6.533 G_L1: 1.667 D_real: 0.002 D_fake: 0.002 \n",
            "(epoch: 97, iters: 782, time: 0.067, data: 0.000) G_GAN: 7.877 G_L1: 2.909 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 97, iters: 882, time: 0.094, data: 0.000) G_GAN: 0.699 G_L1: 0.000 D_real: 0.697 D_fake: 0.701 \n",
            "End of epoch 97 / 200 \t Time Taken: 107 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 98, iters: 68, time: 0.104, data: 0.000) G_GAN: 7.932 G_L1: 3.785 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 98, iters: 168, time: 0.070, data: 0.130) G_GAN: 4.975 G_L1: 2.927 D_real: 0.001 D_fake: 1.381 \n",
            "(epoch: 98, iters: 268, time: 0.098, data: 0.258) G_GAN: 5.615 G_L1: 2.343 D_real: 0.004 D_fake: 0.007 \n",
            "(epoch: 98, iters: 368, time: 0.075, data: 0.012) G_GAN: 3.807 G_L1: 1.915 D_real: 0.051 D_fake: 0.030 \n",
            "(epoch: 98, iters: 468, time: 0.103, data: 0.000) G_GAN: 6.941 G_L1: 3.618 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 98, iters: 568, time: 0.063, data: 0.003) G_GAN: 0.672 G_L1: 0.000 D_real: 0.671 D_fake: 0.718 \n",
            "(epoch: 98, iters: 668, time: 0.110, data: 0.100) G_GAN: 7.260 G_L1: 5.894 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 98, iters: 768, time: 0.071, data: 0.073) G_GAN: 9.749 G_L1: 1.629 D_real: 0.242 D_fake: 0.000 \n",
            "(epoch: 98, iters: 868, time: 0.067, data: 0.002) G_GAN: 4.440 G_L1: 1.643 D_real: 0.045 D_fake: 0.046 \n",
            "End of epoch 98 / 200 \t Time Taken: 105 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 99, iters: 54, time: 0.068, data: 0.000) G_GAN: 8.296 G_L1: 2.463 D_real: 0.009 D_fake: 0.001 \n",
            "(epoch: 99, iters: 154, time: 0.082, data: 0.033) G_GAN: 7.172 G_L1: 5.942 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 99, iters: 254, time: 0.076, data: 0.000) G_GAN: 6.983 G_L1: 7.835 D_real: 0.002 D_fake: 0.002 \n",
            "(epoch: 99, iters: 354, time: 0.070, data: 0.000) G_GAN: 5.564 G_L1: 1.911 D_real: 0.058 D_fake: 0.009 \n",
            "(epoch: 99, iters: 454, time: 0.066, data: 0.000) G_GAN: 4.949 G_L1: 7.414 D_real: 0.000 D_fake: 1.883 \n",
            "(epoch: 99, iters: 554, time: 0.088, data: 0.000) G_GAN: 3.983 G_L1: 4.000 D_real: 0.009 D_fake: 0.179 \n",
            "(epoch: 99, iters: 654, time: 0.073, data: 0.154) G_GAN: 5.149 G_L1: 0.537 D_real: 0.147 D_fake: 0.005 \n",
            "(epoch: 99, iters: 754, time: 0.079, data: 0.174) G_GAN: 3.260 G_L1: 0.645 D_real: 0.197 D_fake: 0.026 \n",
            "(epoch: 99, iters: 854, time: 0.068, data: 0.171) G_GAN: 0.722 G_L1: 0.000 D_real: 0.749 D_fake: 0.648 \n",
            "End of epoch 99 / 200 \t Time Taken: 106 sec\n",
            "learning rate 0.0002000 -> 0.0001980\n",
            "(epoch: 100, iters: 40, time: 0.104, data: 0.003) G_GAN: 0.786 G_L1: 0.000 D_real: 0.843 D_fake: 0.580 \n",
            "(epoch: 100, iters: 140, time: 0.080, data: 0.011) G_GAN: 7.025 G_L1: 0.988 D_real: 0.003 D_fake: 0.613 \n",
            "(epoch: 100, iters: 240, time: 0.080, data: 0.000) G_GAN: 5.715 G_L1: 4.465 D_real: 0.003 D_fake: 0.008 \n",
            "(epoch: 100, iters: 340, time: 0.063, data: 0.000) G_GAN: 3.483 G_L1: 0.713 D_real: 0.019 D_fake: 0.077 \n",
            "(epoch: 100, iters: 440, time: 0.085, data: 0.000) G_GAN: 8.060 G_L1: 1.453 D_real: 0.003 D_fake: 0.001 \n",
            "(epoch: 100, iters: 540, time: 0.083, data: 0.000) G_GAN: 3.230 G_L1: 1.756 D_real: 0.009 D_fake: 2.151 \n",
            "(epoch: 100, iters: 640, time: 0.063, data: 0.000) G_GAN: 4.735 G_L1: 2.149 D_real: 0.015 D_fake: 0.678 \n",
            "(epoch: 100, iters: 740, time: 0.095, data: 0.000) G_GAN: 3.523 G_L1: 1.093 D_real: 0.056 D_fake: 0.070 \n",
            "(epoch: 100, iters: 840, time: 0.082, data: 0.000) G_GAN: 0.937 G_L1: 0.000 D_real: 1.235 D_fake: 0.364 \n",
            "saving the model at the end of epoch 100, iters 83174\n",
            "End of epoch 100 / 200 \t Time Taken: 110 sec\n",
            "learning rate 0.0001980 -> 0.0001960\n",
            "(epoch: 101, iters: 26, time: 0.074, data: 0.000) G_GAN: 0.678 G_L1: 0.000 D_real: 0.681 D_fake: 0.709 \n",
            "(epoch: 101, iters: 126, time: 0.099, data: 0.000) G_GAN: 2.695 G_L1: 1.393 D_real: 0.277 D_fake: 0.019 \n",
            "(epoch: 101, iters: 226, time: 0.063, data: 0.000) G_GAN: 2.423 G_L1: 1.096 D_real: 0.066 D_fake: 1.088 \n",
            "(epoch: 101, iters: 326, time: 0.071, data: 0.000) G_GAN: 3.841 G_L1: 2.675 D_real: 0.010 D_fake: 0.037 \n",
            "(epoch: 101, iters: 426, time: 0.088, data: 0.001) G_GAN: 9.813 G_L1: 3.976 D_real: 0.029 D_fake: 0.000 \n",
            "(epoch: 101, iters: 526, time: 0.077, data: 0.063) G_GAN: 0.667 G_L1: 0.000 D_real: 0.671 D_fake: 0.721 \n",
            "(epoch: 101, iters: 626, time: 0.076, data: 0.045) G_GAN: 9.097 G_L1: 2.307 D_real: 0.008 D_fake: 0.000 \n",
            "(epoch: 101, iters: 726, time: 0.107, data: 0.002) G_GAN: 0.686 G_L1: 0.038 D_real: 0.130 D_fake: 1.861 \n",
            "(epoch: 101, iters: 826, time: 0.105, data: 0.000) G_GAN: 5.516 G_L1: 1.974 D_real: 0.001 D_fake: 3.611 \n",
            "End of epoch 101 / 200 \t Time Taken: 107 sec\n",
            "learning rate 0.0001960 -> 0.0001941\n",
            "(epoch: 102, iters: 12, time: 0.073, data: 0.003) G_GAN: 3.750 G_L1: 0.750 D_real: 0.015 D_fake: 0.915 \n",
            "(epoch: 102, iters: 112, time: 0.104, data: 0.074) G_GAN: 0.761 G_L1: 0.000 D_real: 0.767 D_fake: 0.630 \n",
            "(epoch: 102, iters: 212, time: 0.085, data: 0.002) G_GAN: 6.112 G_L1: 3.302 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 102, iters: 312, time: 0.106, data: 0.001) G_GAN: 3.775 G_L1: 11.403 D_real: 0.011 D_fake: 0.056 \n",
            "(epoch: 102, iters: 412, time: 0.074, data: 0.000) G_GAN: 3.825 G_L1: 1.968 D_real: 0.042 D_fake: 0.032 \n",
            "(epoch: 102, iters: 512, time: 0.087, data: 0.004) G_GAN: 5.216 G_L1: 2.472 D_real: 0.000 D_fake: 0.009 \n",
            "(epoch: 102, iters: 612, time: 0.085, data: 0.000) G_GAN: 4.958 G_L1: 2.074 D_real: 0.009 D_fake: 0.014 \n",
            "(epoch: 102, iters: 712, time: 0.070, data: 0.000) G_GAN: 0.906 G_L1: 0.000 D_real: 0.910 D_fake: 0.529 \n",
            "(epoch: 102, iters: 812, time: 0.112, data: 0.001) G_GAN: 0.684 G_L1: 0.000 D_real: 0.680 D_fake: 0.720 \n",
            "(epoch: 102, iters: 912, time: 0.068, data: 0.000) G_GAN: 3.095 G_L1: 2.228 D_real: 0.000 D_fake: 0.185 \n",
            "saving the latest model (epoch 102, total_iters 85000)\n",
            "End of epoch 102 / 200 \t Time Taken: 107 sec\n",
            "learning rate 0.0001941 -> 0.0001921\n",
            "(epoch: 103, iters: 98, time: 0.076, data: 0.000) G_GAN: 2.761 G_L1: 6.521 D_real: 0.007 D_fake: 0.319 \n",
            "(epoch: 103, iters: 198, time: 0.090, data: 0.000) G_GAN: 5.193 G_L1: 1.193 D_real: 0.975 D_fake: 0.000 \n",
            "(epoch: 103, iters: 298, time: 0.095, data: 0.000) G_GAN: 5.404 G_L1: 2.909 D_real: 0.000 D_fake: 0.009 \n",
            "(epoch: 103, iters: 398, time: 0.073, data: 0.000) G_GAN: 0.812 G_L1: 0.000 D_real: 0.818 D_fake: 0.592 \n",
            "(epoch: 103, iters: 498, time: 0.081, data: 0.000) G_GAN: 0.666 G_L1: 0.001 D_real: 0.666 D_fake: 0.727 \n",
            "(epoch: 103, iters: 598, time: 0.115, data: 0.000) G_GAN: 3.611 G_L1: 1.129 D_real: 0.018 D_fake: 0.726 \n",
            "(epoch: 103, iters: 698, time: 0.114, data: 0.000) G_GAN: 0.837 G_L1: 0.000 D_real: 0.888 D_fake: 0.536 \n",
            "(epoch: 103, iters: 798, time: 0.088, data: 0.003) G_GAN: 3.147 G_L1: 1.107 D_real: 0.422 D_fake: 0.023 \n",
            "(epoch: 103, iters: 898, time: 0.094, data: 0.000) G_GAN: 4.510 G_L1: 2.398 D_real: 0.001 D_fake: 1.708 \n",
            "End of epoch 103 / 200 \t Time Taken: 112 sec\n",
            "learning rate 0.0001921 -> 0.0001901\n",
            "(epoch: 104, iters: 84, time: 0.097, data: 0.000) G_GAN: 4.652 G_L1: 3.540 D_real: 0.049 D_fake: 0.014 \n",
            "(epoch: 104, iters: 184, time: 0.114, data: 0.000) G_GAN: 7.813 G_L1: 2.030 D_real: 0.126 D_fake: 0.000 \n",
            "(epoch: 104, iters: 284, time: 0.099, data: 0.000) G_GAN: 0.674 G_L1: 0.000 D_real: 0.667 D_fake: 0.735 \n",
            "(epoch: 104, iters: 384, time: 0.102, data: 0.000) G_GAN: 5.221 G_L1: 3.497 D_real: 0.000 D_fake: 0.010 \n",
            "(epoch: 104, iters: 484, time: 0.090, data: 0.000) G_GAN: 7.191 G_L1: 2.671 D_real: 0.046 D_fake: 0.001 \n",
            "(epoch: 104, iters: 584, time: 0.074, data: 0.001) G_GAN: 3.935 G_L1: 6.875 D_real: 0.001 D_fake: 0.254 \n",
            "(epoch: 104, iters: 684, time: 0.076, data: 0.000) G_GAN: 3.797 G_L1: 5.340 D_real: 0.000 D_fake: 0.103 \n",
            "(epoch: 104, iters: 784, time: 0.106, data: 0.000) G_GAN: 9.116 G_L1: 11.922 D_real: 0.012 D_fake: 0.000 \n",
            "(epoch: 104, iters: 884, time: 0.062, data: 0.076) G_GAN: 4.685 G_L1: 5.279 D_real: 0.005 D_fake: 0.060 \n",
            "End of epoch 104 / 200 \t Time Taken: 115 sec\n",
            "learning rate 0.0001901 -> 0.0001881\n",
            "(epoch: 105, iters: 70, time: 0.080, data: 0.000) G_GAN: 7.120 G_L1: 8.011 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 105, iters: 170, time: 0.078, data: 0.001) G_GAN: 13.862 G_L1: 3.770 D_real: 0.007 D_fake: 0.000 \n",
            "(epoch: 105, iters: 270, time: 0.080, data: 0.004) G_GAN: 3.700 G_L1: 3.604 D_real: 0.017 D_fake: 0.261 \n",
            "(epoch: 105, iters: 370, time: 0.089, data: 0.008) G_GAN: 5.284 G_L1: 2.172 D_real: 0.000 D_fake: 0.009 \n",
            "(epoch: 105, iters: 470, time: 0.095, data: 0.047) G_GAN: 0.768 G_L1: 0.000 D_real: 0.767 D_fake: 0.631 \n",
            "(epoch: 105, iters: 570, time: 0.086, data: 0.180) G_GAN: 7.257 G_L1: 3.269 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 105, iters: 670, time: 0.069, data: 0.148) G_GAN: 6.136 G_L1: 3.815 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 105, iters: 770, time: 0.075, data: 0.168) G_GAN: 3.960 G_L1: 1.032 D_real: 0.013 D_fake: 0.218 \n",
            "(epoch: 105, iters: 870, time: 0.109, data: 0.099) G_GAN: 0.660 G_L1: 0.000 D_real: 0.638 D_fake: 0.763 \n",
            "End of epoch 105 / 200 \t Time Taken: 113 sec\n",
            "learning rate 0.0001881 -> 0.0001861\n",
            "(epoch: 106, iters: 56, time: 0.100, data: 0.009) G_GAN: 6.191 G_L1: 9.541 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 106, iters: 156, time: 0.120, data: 0.155) G_GAN: 8.729 G_L1: 5.864 D_real: 0.009 D_fake: 0.000 \n",
            "(epoch: 106, iters: 256, time: 0.090, data: 0.000) G_GAN: 4.160 G_L1: 0.552 D_real: 0.006 D_fake: 0.023 \n",
            "(epoch: 106, iters: 356, time: 0.090, data: 0.174) G_GAN: 4.247 G_L1: 0.967 D_real: 0.002 D_fake: 1.471 \n",
            "(epoch: 106, iters: 456, time: 0.098, data: 0.093) G_GAN: 2.265 G_L1: 0.955 D_real: 0.195 D_fake: 0.048 \n",
            "(epoch: 106, iters: 556, time: 0.089, data: 0.000) G_GAN: 5.948 G_L1: 2.209 D_real: 0.295 D_fake: 0.002 \n",
            "(epoch: 106, iters: 656, time: 0.105, data: 0.000) G_GAN: 2.801 G_L1: 0.781 D_real: 0.215 D_fake: 0.871 \n",
            "(epoch: 106, iters: 756, time: 0.091, data: 0.109) G_GAN: 0.740 G_L1: 0.001 D_real: 0.798 D_fake: 0.638 \n",
            "(epoch: 106, iters: 856, time: 0.099, data: 0.230) G_GAN: 6.217 G_L1: 6.243 D_real: 0.000 D_fake: 0.004 \n",
            "End of epoch 106 / 200 \t Time Taken: 112 sec\n",
            "learning rate 0.0001861 -> 0.0001842\n",
            "(epoch: 107, iters: 42, time: 0.088, data: 0.116) G_GAN: 6.568 G_L1: 6.735 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 107, iters: 142, time: 0.086, data: 0.005) G_GAN: 4.658 G_L1: 2.238 D_real: 0.002 D_fake: 0.017 \n",
            "(epoch: 107, iters: 242, time: 0.085, data: 0.000) G_GAN: 6.816 G_L1: 0.691 D_real: 0.014 D_fake: 0.002 \n",
            "(epoch: 107, iters: 342, time: 0.098, data: 0.002) G_GAN: 6.182 G_L1: 4.785 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 107, iters: 442, time: 0.109, data: 0.001) G_GAN: 0.519 G_L1: 0.856 D_real: 1.354 D_fake: 0.151 \n",
            "(epoch: 107, iters: 542, time: 0.100, data: 0.002) G_GAN: 4.410 G_L1: 3.070 D_real: 0.001 D_fake: 0.025 \n",
            "(epoch: 107, iters: 642, time: 0.090, data: 0.000) G_GAN: 7.127 G_L1: 2.536 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 107, iters: 742, time: 0.087, data: 0.112) G_GAN: 7.546 G_L1: 6.187 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 107, iters: 842, time: 0.070, data: 0.130) G_GAN: 0.712 G_L1: 0.001 D_real: 0.705 D_fake: 0.701 \n",
            "End of epoch 107 / 200 \t Time Taken: 113 sec\n",
            "learning rate 0.0001842 -> 0.0001822\n",
            "(epoch: 108, iters: 28, time: 0.074, data: 0.169) G_GAN: 3.536 G_L1: 2.313 D_real: 0.182 D_fake: 0.025 \n",
            "(epoch: 108, iters: 128, time: 0.067, data: 0.174) G_GAN: 4.047 G_L1: 0.966 D_real: 0.004 D_fake: 0.174 \n",
            "(epoch: 108, iters: 228, time: 0.086, data: 0.174) G_GAN: 8.712 G_L1: 5.984 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 108, iters: 328, time: 0.093, data: 0.002) G_GAN: 0.780 G_L1: 0.000 D_real: 0.838 D_fake: 0.586 \n",
            "(epoch: 108, iters: 428, time: 0.094, data: 0.000) G_GAN: 3.711 G_L1: 2.531 D_real: 0.310 D_fake: 0.011 \n",
            "saving the latest model (epoch 108, total_iters 90000)\n",
            "(epoch: 108, iters: 528, time: 0.071, data: 0.003) G_GAN: 7.606 G_L1: 2.740 D_real: 0.018 D_fake: 0.001 \n",
            "(epoch: 108, iters: 628, time: 0.078, data: 0.000) G_GAN: 4.646 G_L1: 2.631 D_real: 0.010 D_fake: 0.016 \n",
            "(epoch: 108, iters: 728, time: 0.099, data: 0.000) G_GAN: 8.586 G_L1: 3.437 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 108, iters: 828, time: 0.070, data: 0.001) G_GAN: 0.707 G_L1: 0.000 D_real: 0.705 D_fake: 0.696 \n",
            "End of epoch 108 / 200 \t Time Taken: 114 sec\n",
            "learning rate 0.0001822 -> 0.0001802\n",
            "(epoch: 109, iters: 14, time: 0.098, data: 0.000) G_GAN: 8.441 G_L1: 4.839 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 109, iters: 114, time: 0.077, data: 0.003) G_GAN: 4.273 G_L1: 5.966 D_real: 0.000 D_fake: 0.068 \n",
            "(epoch: 109, iters: 214, time: 0.100, data: 0.078) G_GAN: 0.647 G_L1: 0.000 D_real: 0.633 D_fake: 0.776 \n",
            "(epoch: 109, iters: 314, time: 0.063, data: 0.003) G_GAN: 0.691 G_L1: 0.000 D_real: 0.728 D_fake: 0.674 \n",
            "(epoch: 109, iters: 414, time: 0.088, data: 0.000) G_GAN: 0.718 G_L1: 0.000 D_real: 0.734 D_fake: 0.663 \n",
            "(epoch: 109, iters: 514, time: 0.084, data: 0.000) G_GAN: 3.755 G_L1: 1.472 D_real: 0.039 D_fake: 0.379 \n",
            "(epoch: 109, iters: 614, time: 0.078, data: 0.001) G_GAN: 10.444 G_L1: 3.286 D_real: 0.064 D_fake: 0.000 \n",
            "(epoch: 109, iters: 714, time: 0.081, data: 0.000) G_GAN: 4.530 G_L1: 1.904 D_real: 0.001 D_fake: 1.236 \n",
            "(epoch: 109, iters: 814, time: 0.095, data: 0.000) G_GAN: 8.126 G_L1: 8.086 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 109, iters: 914, time: 0.066, data: 0.000) G_GAN: 6.028 G_L1: 3.712 D_real: 0.047 D_fake: 0.004 \n",
            "End of epoch 109 / 200 \t Time Taken: 113 sec\n",
            "learning rate 0.0001802 -> 0.0001782\n",
            "(epoch: 110, iters: 100, time: 0.078, data: 0.678) G_GAN: 6.186 G_L1: 8.285 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 110, iters: 200, time: 0.086, data: 0.008) G_GAN: 3.688 G_L1: 3.646 D_real: 0.013 D_fake: 0.085 \n",
            "(epoch: 110, iters: 300, time: 0.095, data: 0.155) G_GAN: 8.849 G_L1: 3.664 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 110, iters: 400, time: 0.075, data: 0.121) G_GAN: 0.721 G_L1: 0.000 D_real: 0.749 D_fake: 0.654 \n",
            "(epoch: 110, iters: 500, time: 0.089, data: 0.000) G_GAN: 5.300 G_L1: 3.319 D_real: 0.001 D_fake: 0.010 \n",
            "(epoch: 110, iters: 600, time: 0.103, data: 0.000) G_GAN: 4.373 G_L1: 1.911 D_real: 0.136 D_fake: 0.007 \n",
            "(epoch: 110, iters: 700, time: 0.082, data: 0.000) G_GAN: 0.701 G_L1: 0.001 D_real: 0.702 D_fake: 0.687 \n",
            "(epoch: 110, iters: 800, time: 0.095, data: 0.000) G_GAN: 7.370 G_L1: 1.866 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 110, iters: 900, time: 0.074, data: 0.002) G_GAN: 0.678 G_L1: 0.001 D_real: 0.667 D_fake: 0.726 \n",
            "End of epoch 110 / 200 \t Time Taken: 116 sec\n",
            "learning rate 0.0001782 -> 0.0001762\n",
            "(epoch: 111, iters: 86, time: 0.070, data: 0.001) G_GAN: 9.060 G_L1: 6.411 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 111, iters: 186, time: 0.075, data: 0.173) G_GAN: 5.803 G_L1: 0.633 D_real: 0.029 D_fake: 0.886 \n",
            "(epoch: 111, iters: 286, time: 0.087, data: 0.239) G_GAN: 0.688 G_L1: 0.000 D_real: 0.693 D_fake: 0.697 \n",
            "(epoch: 111, iters: 386, time: 0.085, data: 0.135) G_GAN: 2.992 G_L1: 0.412 D_real: 0.095 D_fake: 0.211 \n",
            "(epoch: 111, iters: 486, time: 0.073, data: 0.220) G_GAN: 0.636 G_L1: 0.001 D_real: 0.626 D_fake: 0.775 \n",
            "(epoch: 111, iters: 586, time: 0.094, data: 0.227) G_GAN: 3.840 G_L1: 2.574 D_real: 0.001 D_fake: 0.125 \n",
            "(epoch: 111, iters: 686, time: 0.095, data: 0.102) G_GAN: 2.523 G_L1: 1.517 D_real: 0.474 D_fake: 0.025 \n",
            "(epoch: 111, iters: 786, time: 0.073, data: 0.178) G_GAN: 5.457 G_L1: 2.147 D_real: 0.003 D_fake: 1.247 \n",
            "(epoch: 111, iters: 886, time: 0.076, data: 0.077) G_GAN: 0.699 G_L1: 0.000 D_real: 0.655 D_fake: 0.742 \n",
            "End of epoch 111 / 200 \t Time Taken: 115 sec\n",
            "learning rate 0.0001762 -> 0.0001743\n",
            "(epoch: 112, iters: 72, time: 0.080, data: 0.171) G_GAN: 7.953 G_L1: 5.732 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 112, iters: 172, time: 0.070, data: 0.011) G_GAN: 4.364 G_L1: 2.656 D_real: 0.012 D_fake: 0.022 \n",
            "(epoch: 112, iters: 272, time: 0.080, data: 0.021) G_GAN: 4.199 G_L1: 1.584 D_real: 0.001 D_fake: 0.036 \n",
            "(epoch: 112, iters: 372, time: 0.076, data: 0.000) G_GAN: 6.568 G_L1: 4.500 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 112, iters: 472, time: 0.070, data: 0.000) G_GAN: 10.130 G_L1: 0.705 D_real: 0.025 D_fake: 0.000 \n",
            "(epoch: 112, iters: 572, time: 0.088, data: 0.000) G_GAN: 7.214 G_L1: 7.939 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 112, iters: 672, time: 0.106, data: 0.002) G_GAN: 8.752 G_L1: 2.707 D_real: 0.045 D_fake: 0.000 \n",
            "(epoch: 112, iters: 772, time: 0.077, data: 0.000) G_GAN: 5.075 G_L1: 1.786 D_real: 0.004 D_fake: 0.009 \n",
            "(epoch: 112, iters: 872, time: 0.091, data: 0.063) G_GAN: 3.040 G_L1: 0.310 D_real: 0.195 D_fake: 0.368 \n",
            "End of epoch 112 / 200 \t Time Taken: 113 sec\n",
            "learning rate 0.0001743 -> 0.0001723\n",
            "(epoch: 113, iters: 58, time: 0.090, data: 0.001) G_GAN: 9.549 G_L1: 5.901 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 113, iters: 158, time: 0.096, data: 0.000) G_GAN: 14.363 G_L1: 1.189 D_real: 0.004 D_fake: 0.000 \n",
            "(epoch: 113, iters: 258, time: 0.098, data: 0.000) G_GAN: 0.697 G_L1: 0.000 D_real: 0.693 D_fake: 0.707 \n",
            "(epoch: 113, iters: 358, time: 0.085, data: 0.000) G_GAN: 5.971 G_L1: 4.418 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 113, iters: 458, time: 0.085, data: 0.000) G_GAN: 3.687 G_L1: 2.115 D_real: 0.004 D_fake: 0.169 \n",
            "(epoch: 113, iters: 558, time: 0.084, data: 0.000) G_GAN: 9.018 G_L1: 2.188 D_real: 0.120 D_fake: 0.000 \n",
            "(epoch: 113, iters: 658, time: 0.071, data: 0.000) G_GAN: 10.765 G_L1: 2.751 D_real: 0.099 D_fake: 0.000 \n",
            "(epoch: 113, iters: 758, time: 0.099, data: 0.001) G_GAN: 0.678 G_L1: 0.000 D_real: 0.674 D_fake: 0.740 \n",
            "(epoch: 113, iters: 858, time: 0.101, data: 0.002) G_GAN: 12.529 G_L1: 3.611 D_real: 0.518 D_fake: 0.000 \n",
            "saving the latest model (epoch 113, total_iters 95000)\n",
            "End of epoch 113 / 200 \t Time Taken: 117 sec\n",
            "learning rate 0.0001723 -> 0.0001703\n",
            "(epoch: 114, iters: 44, time: 0.110, data: 0.000) G_GAN: 6.706 G_L1: 2.815 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 114, iters: 144, time: 0.095, data: 0.067) G_GAN: 3.398 G_L1: 0.082 D_real: 0.129 D_fake: 0.034 \n",
            "(epoch: 114, iters: 244, time: 0.104, data: 0.090) G_GAN: 4.066 G_L1: 9.585 D_real: 0.001 D_fake: 0.060 \n",
            "(epoch: 114, iters: 344, time: 0.070, data: 0.000) G_GAN: 8.971 G_L1: 1.428 D_real: 0.003 D_fake: 0.000 \n",
            "(epoch: 114, iters: 444, time: 0.071, data: 0.000) G_GAN: 5.720 G_L1: 5.839 D_real: 0.000 D_fake: 0.008 \n",
            "(epoch: 114, iters: 544, time: 0.095, data: 0.000) G_GAN: 0.692 G_L1: 0.000 D_real: 0.724 D_fake: 0.705 \n",
            "(epoch: 114, iters: 644, time: 0.072, data: 0.000) G_GAN: 0.745 G_L1: 0.001 D_real: 0.748 D_fake: 0.650 \n",
            "(epoch: 114, iters: 744, time: 0.099, data: 0.001) G_GAN: 3.015 G_L1: 3.422 D_real: 0.000 D_fake: 0.036 \n",
            "(epoch: 114, iters: 844, time: 0.084, data: 0.000) G_GAN: 9.155 G_L1: 4.022 D_real: 0.000 D_fake: 0.000 \n",
            "End of epoch 114 / 200 \t Time Taken: 118 sec\n",
            "learning rate 0.0001703 -> 0.0001683\n",
            "(epoch: 115, iters: 30, time: 0.093, data: 0.002) G_GAN: 6.006 G_L1: 0.430 D_real: 0.121 D_fake: 0.002 \n",
            "(epoch: 115, iters: 130, time: 0.086, data: 0.000) G_GAN: 0.668 G_L1: 0.000 D_real: 0.662 D_fake: 0.744 \n",
            "(epoch: 115, iters: 230, time: 0.113, data: 0.000) G_GAN: 10.130 G_L1: 10.957 D_real: 0.014 D_fake: 0.000 \n",
            "(epoch: 115, iters: 330, time: 0.103, data: 0.000) G_GAN: 5.743 G_L1: 3.775 D_real: 0.010 D_fake: 0.011 \n",
            "(epoch: 115, iters: 430, time: 0.078, data: 0.000) G_GAN: 2.951 G_L1: 0.395 D_real: 0.012 D_fake: 0.129 \n",
            "(epoch: 115, iters: 530, time: 0.086, data: 0.000) G_GAN: 0.590 G_L1: 0.000 D_real: 0.592 D_fake: 0.819 \n",
            "(epoch: 115, iters: 630, time: 0.081, data: 0.000) G_GAN: 7.323 G_L1: 2.050 D_real: 0.003 D_fake: 0.001 \n",
            "(epoch: 115, iters: 730, time: 0.086, data: 0.001) G_GAN: 9.265 G_L1: 3.948 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 115, iters: 830, time: 0.095, data: 0.000) G_GAN: 10.337 G_L1: 11.318 D_real: 0.022 D_fake: 0.000 \n",
            "End of epoch 115 / 200 \t Time Taken: 116 sec\n",
            "learning rate 0.0001683 -> 0.0001663\n",
            "(epoch: 116, iters: 16, time: 0.108, data: 0.000) G_GAN: 5.475 G_L1: 1.665 D_real: 0.003 D_fake: 0.323 \n",
            "(epoch: 116, iters: 116, time: 0.104, data: 0.002) G_GAN: 7.341 G_L1: 10.287 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 116, iters: 216, time: 0.085, data: 0.000) G_GAN: 0.702 G_L1: 0.000 D_real: 0.722 D_fake: 0.672 \n",
            "(epoch: 116, iters: 316, time: 0.094, data: 0.000) G_GAN: 4.645 G_L1: 3.564 D_real: 0.001 D_fake: 0.023 \n",
            "(epoch: 116, iters: 416, time: 0.105, data: 0.000) G_GAN: 10.126 G_L1: 2.506 D_real: 0.004 D_fake: 0.000 \n",
            "(epoch: 116, iters: 516, time: 0.107, data: 0.002) G_GAN: 9.030 G_L1: 3.990 D_real: 0.006 D_fake: 0.000 \n",
            "(epoch: 116, iters: 616, time: 0.111, data: 0.001) G_GAN: 7.554 G_L1: 7.092 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 116, iters: 716, time: 0.108, data: 0.000) G_GAN: 0.707 G_L1: 0.000 D_real: 0.710 D_fake: 0.729 \n",
            "(epoch: 116, iters: 816, time: 0.072, data: 0.000) G_GAN: 0.716 G_L1: 0.000 D_real: 0.728 D_fake: 0.693 \n",
            "End of epoch 116 / 200 \t Time Taken: 117 sec\n",
            "learning rate 0.0001663 -> 0.0001644\n",
            "(epoch: 117, iters: 2, time: 0.068, data: 0.000) G_GAN: 6.792 G_L1: 2.835 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 117, iters: 102, time: 0.087, data: 0.006) G_GAN: 7.179 G_L1: 5.953 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 117, iters: 202, time: 0.114, data: 0.000) G_GAN: 0.679 G_L1: 0.000 D_real: 0.698 D_fake: 0.705 \n",
            "(epoch: 117, iters: 302, time: 0.077, data: 0.000) G_GAN: 8.193 G_L1: 5.306 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 117, iters: 402, time: 0.097, data: 0.000) G_GAN: 7.670 G_L1: 0.578 D_real: 0.241 D_fake: 0.000 \n",
            "(epoch: 117, iters: 502, time: 0.101, data: 0.000) G_GAN: 5.020 G_L1: 1.762 D_real: 0.001 D_fake: 0.009 \n",
            "(epoch: 117, iters: 602, time: 0.093, data: 0.000) G_GAN: 6.293 G_L1: 0.745 D_real: 0.013 D_fake: 0.003 \n",
            "(epoch: 117, iters: 702, time: 0.075, data: 0.000) G_GAN: 5.519 G_L1: 4.502 D_real: 0.002 D_fake: 0.008 \n",
            "(epoch: 117, iters: 802, time: 0.072, data: 0.005) G_GAN: 0.761 G_L1: 0.000 D_real: 0.795 D_fake: 0.615 \n",
            "(epoch: 117, iters: 902, time: 0.084, data: 0.000) G_GAN: 1.833 G_L1: 0.250 D_real: 0.361 D_fake: 0.197 \n",
            "End of epoch 117 / 200 \t Time Taken: 116 sec\n",
            "learning rate 0.0001644 -> 0.0001624\n",
            "(epoch: 118, iters: 88, time: 0.080, data: 0.000) G_GAN: 4.991 G_L1: 2.065 D_real: 0.352 D_fake: 0.004 \n",
            "(epoch: 118, iters: 188, time: 0.120, data: 0.125) G_GAN: 5.521 G_L1: 1.135 D_real: 0.026 D_fake: 0.006 \n",
            "(epoch: 118, iters: 288, time: 0.092, data: 0.000) G_GAN: 7.780 G_L1: 4.320 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 118, iters: 388, time: 0.096, data: 0.130) G_GAN: 2.431 G_L1: 0.923 D_real: 0.481 D_fake: 0.008 \n",
            "(epoch: 118, iters: 488, time: 0.080, data: 0.000) G_GAN: 6.967 G_L1: 6.617 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 118, iters: 588, time: 0.106, data: 0.000) G_GAN: 8.858 G_L1: 4.336 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 118, iters: 688, time: 0.101, data: 0.000) G_GAN: 5.142 G_L1: 3.531 D_real: 0.007 D_fake: 0.010 \n",
            "(epoch: 118, iters: 788, time: 0.077, data: 0.000) G_GAN: 7.038 G_L1: 1.473 D_real: 0.301 D_fake: 0.001 \n",
            "(epoch: 118, iters: 888, time: 0.102, data: 0.000) G_GAN: 0.736 G_L1: 0.000 D_real: 0.727 D_fake: 0.678 \n",
            "End of epoch 118 / 200 \t Time Taken: 118 sec\n",
            "learning rate 0.0001624 -> 0.0001604\n",
            "(epoch: 119, iters: 74, time: 0.081, data: 0.000) G_GAN: 5.201 G_L1: 1.885 D_real: 0.003 D_fake: 0.008 \n",
            "(epoch: 119, iters: 174, time: 0.096, data: 0.010) G_GAN: 8.257 G_L1: 9.538 D_real: 0.009 D_fake: 0.001 \n",
            "(epoch: 119, iters: 274, time: 0.090, data: 0.004) G_GAN: 0.739 G_L1: 0.002 D_real: 0.763 D_fake: 0.638 \n",
            "(epoch: 119, iters: 374, time: 0.099, data: 0.003) G_GAN: 0.700 G_L1: 0.000 D_real: 0.723 D_fake: 0.669 \n",
            "saving the latest model (epoch 119, total_iters 100000)\n",
            "(epoch: 119, iters: 474, time: 0.071, data: 0.000) G_GAN: 2.927 G_L1: 1.374 D_real: 0.065 D_fake: 0.114 \n",
            "(epoch: 119, iters: 574, time: 0.076, data: 0.064) G_GAN: 0.759 G_L1: 0.359 D_real: 1.007 D_fake: 0.072 \n",
            "(epoch: 119, iters: 674, time: 0.105, data: 0.219) G_GAN: 7.062 G_L1: 6.057 D_real: 0.061 D_fake: 0.000 \n",
            "(epoch: 119, iters: 774, time: 0.099, data: 0.071) G_GAN: 8.042 G_L1: 0.938 D_real: 2.115 D_fake: 0.000 \n",
            "(epoch: 119, iters: 874, time: 0.109, data: 0.016) G_GAN: 10.697 G_L1: 7.824 D_real: 0.005 D_fake: 0.000 \n",
            "End of epoch 119 / 200 \t Time Taken: 118 sec\n",
            "learning rate 0.0001604 -> 0.0001584\n",
            "(epoch: 120, iters: 60, time: 0.074, data: 0.143) G_GAN: 12.008 G_L1: 2.173 D_real: 0.019 D_fake: 0.000 \n",
            "(epoch: 120, iters: 160, time: 0.099, data: 0.003) G_GAN: 7.361 G_L1: 8.259 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 120, iters: 260, time: 0.080, data: 0.000) G_GAN: 9.653 G_L1: 6.467 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 120, iters: 360, time: 0.086, data: 0.001) G_GAN: 6.035 G_L1: 0.519 D_real: 0.016 D_fake: 0.816 \n",
            "(epoch: 120, iters: 460, time: 0.086, data: 0.000) G_GAN: 0.675 G_L1: 0.001 D_real: 0.664 D_fake: 0.729 \n",
            "(epoch: 120, iters: 560, time: 0.086, data: 0.121) G_GAN: 7.625 G_L1: 1.258 D_real: 0.083 D_fake: 0.000 \n",
            "(epoch: 120, iters: 660, time: 0.102, data: 0.002) G_GAN: 5.890 G_L1: 2.383 D_real: 0.163 D_fake: 0.003 \n",
            "(epoch: 120, iters: 760, time: 0.085, data: 0.071) G_GAN: 0.661 G_L1: 0.000 D_real: 0.654 D_fake: 0.739 \n",
            "(epoch: 120, iters: 860, time: 0.089, data: 0.117) G_GAN: 11.035 G_L1: 0.906 D_real: 0.014 D_fake: 0.000 \n",
            "End of epoch 120 / 200 \t Time Taken: 116 sec\n",
            "learning rate 0.0001584 -> 0.0001564\n",
            "(epoch: 121, iters: 46, time: 0.085, data: 0.132) G_GAN: 8.333 G_L1: 7.244 D_real: 0.027 D_fake: 0.001 \n",
            "(epoch: 121, iters: 146, time: 0.086, data: 0.162) G_GAN: 12.200 G_L1: 2.002 D_real: 0.071 D_fake: 0.000 \n",
            "(epoch: 121, iters: 246, time: 0.093, data: 0.138) G_GAN: 3.150 G_L1: 0.675 D_real: 0.004 D_fake: 0.213 \n",
            "(epoch: 121, iters: 346, time: 0.092, data: 0.243) G_GAN: 3.285 G_L1: 3.422 D_real: 0.002 D_fake: 0.184 \n",
            "(epoch: 121, iters: 446, time: 0.094, data: 0.231) G_GAN: 8.652 G_L1: 5.778 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 121, iters: 546, time: 0.079, data: 0.239) G_GAN: 9.104 G_L1: 4.774 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 121, iters: 646, time: 0.102, data: 0.198) G_GAN: 0.572 G_L1: 0.000 D_real: 0.550 D_fake: 0.873 \n",
            "(epoch: 121, iters: 746, time: 0.118, data: 0.111) G_GAN: 4.473 G_L1: 3.976 D_real: 0.000 D_fake: 0.025 \n",
            "(epoch: 121, iters: 846, time: 0.080, data: 0.077) G_GAN: 4.095 G_L1: 2.401 D_real: 0.000 D_fake: 0.029 \n",
            "End of epoch 121 / 200 \t Time Taken: 116 sec\n",
            "learning rate 0.0001564 -> 0.0001545\n",
            "(epoch: 122, iters: 32, time: 0.091, data: 0.174) G_GAN: 1.359 G_L1: 1.582 D_real: 0.601 D_fake: 0.017 \n",
            "(epoch: 122, iters: 132, time: 0.100, data: 0.002) G_GAN: 6.369 G_L1: 2.209 D_real: 0.058 D_fake: 0.002 \n",
            "(epoch: 122, iters: 232, time: 0.095, data: 0.000) G_GAN: 5.480 G_L1: 2.240 D_real: 0.007 D_fake: 0.008 \n",
            "(epoch: 122, iters: 332, time: 0.084, data: 0.000) G_GAN: 8.000 G_L1: 3.635 D_real: 0.005 D_fake: 0.001 \n",
            "(epoch: 122, iters: 432, time: 0.082, data: 0.000) G_GAN: 8.283 G_L1: 1.252 D_real: 0.348 D_fake: 0.000 \n",
            "(epoch: 122, iters: 532, time: 0.075, data: 0.003) G_GAN: 3.074 G_L1: 2.259 D_real: 0.079 D_fake: 0.100 \n",
            "(epoch: 122, iters: 632, time: 0.098, data: 0.000) G_GAN: 0.661 G_L1: 0.000 D_real: 0.651 D_fake: 0.742 \n",
            "(epoch: 122, iters: 732, time: 0.088, data: 0.002) G_GAN: 4.167 G_L1: 2.064 D_real: 0.035 D_fake: 0.024 \n",
            "(epoch: 122, iters: 832, time: 0.105, data: 0.002) G_GAN: 0.701 G_L1: 0.000 D_real: 0.716 D_fake: 0.677 \n",
            "End of epoch 122 / 200 \t Time Taken: 116 sec\n",
            "learning rate 0.0001545 -> 0.0001525\n",
            "(epoch: 123, iters: 18, time: 0.107, data: 0.000) G_GAN: 5.018 G_L1: 5.385 D_real: 0.022 D_fake: 0.012 \n",
            "(epoch: 123, iters: 118, time: 0.097, data: 0.000) G_GAN: 7.673 G_L1: 6.620 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 123, iters: 218, time: 0.071, data: 0.001) G_GAN: 8.244 G_L1: 9.797 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 123, iters: 318, time: 0.100, data: 0.000) G_GAN: 0.680 G_L1: 0.000 D_real: 0.689 D_fake: 0.700 \n",
            "(epoch: 123, iters: 418, time: 0.067, data: 0.000) G_GAN: 9.365 G_L1: 2.864 D_real: 0.003 D_fake: 0.000 \n",
            "(epoch: 123, iters: 518, time: 0.097, data: 0.000) G_GAN: 0.810 G_L1: 0.000 D_real: 0.814 D_fake: 0.595 \n",
            "(epoch: 123, iters: 618, time: 0.093, data: 0.000) G_GAN: 0.645 G_L1: 0.000 D_real: 0.653 D_fake: 0.749 \n",
            "(epoch: 123, iters: 718, time: 0.096, data: 0.000) G_GAN: 7.915 G_L1: 0.921 D_real: 0.036 D_fake: 0.000 \n",
            "(epoch: 123, iters: 818, time: 0.089, data: 0.000) G_GAN: 10.687 G_L1: 2.496 D_real: 0.000 D_fake: 0.000 \n",
            "End of epoch 123 / 200 \t Time Taken: 116 sec\n",
            "learning rate 0.0001525 -> 0.0001505\n",
            "(epoch: 124, iters: 4, time: 0.093, data: 0.000) G_GAN: 3.179 G_L1: 2.270 D_real: 0.000 D_fake: 0.215 \n",
            "(epoch: 124, iters: 104, time: 0.067, data: 0.018) G_GAN: 4.781 G_L1: 2.887 D_real: 0.006 D_fake: 0.018 \n",
            "(epoch: 124, iters: 204, time: 0.089, data: 0.000) G_GAN: 8.928 G_L1: 3.867 D_real: 0.006 D_fake: 0.000 \n",
            "(epoch: 124, iters: 304, time: 0.080, data: 0.000) G_GAN: 6.104 G_L1: 4.749 D_real: 0.001 D_fake: 0.007 \n",
            "(epoch: 124, iters: 404, time: 0.100, data: 0.106) G_GAN: 4.783 G_L1: 2.302 D_real: 0.043 D_fake: 0.012 \n",
            "(epoch: 124, iters: 504, time: 0.089, data: 0.135) G_GAN: 6.308 G_L1: 4.680 D_real: 0.001 D_fake: 0.004 \n",
            "(epoch: 124, iters: 604, time: 0.116, data: 0.127) G_GAN: 7.025 G_L1: 1.053 D_real: 0.000 D_fake: 1.328 \n",
            "(epoch: 124, iters: 704, time: 0.098, data: 0.107) G_GAN: 2.579 G_L1: 2.714 D_real: 0.216 D_fake: 0.054 \n",
            "(epoch: 124, iters: 804, time: 0.077, data: 0.059) G_GAN: 4.371 G_L1: 1.776 D_real: 0.001 D_fake: 0.031 \n",
            "saving the latest model (epoch 124, total_iters 105000)\n",
            "(epoch: 124, iters: 904, time: 0.084, data: 0.000) G_GAN: 1.057 G_L1: 0.052 D_real: 0.695 D_fake: 0.351 \n",
            "End of epoch 124 / 200 \t Time Taken: 117 sec\n",
            "learning rate 0.0001505 -> 0.0001485\n",
            "(epoch: 125, iters: 90, time: 0.083, data: 0.137) G_GAN: 8.202 G_L1: 0.707 D_real: 0.011 D_fake: 1.399 \n",
            "(epoch: 125, iters: 190, time: 0.075, data: 0.016) G_GAN: 6.137 G_L1: 11.751 D_real: 0.132 D_fake: 0.006 \n",
            "(epoch: 125, iters: 290, time: 0.082, data: 0.233) G_GAN: 6.708 G_L1: 2.819 D_real: 0.026 D_fake: 0.002 \n",
            "(epoch: 125, iters: 390, time: 0.085, data: 0.232) G_GAN: 3.884 G_L1: 2.771 D_real: 0.000 D_fake: 0.080 \n",
            "(epoch: 125, iters: 490, time: 0.086, data: 0.147) G_GAN: 10.341 G_L1: 1.127 D_real: 0.029 D_fake: 0.000 \n",
            "(epoch: 125, iters: 590, time: 0.096, data: 0.086) G_GAN: 11.068 G_L1: 2.798 D_real: 0.011 D_fake: 0.000 \n",
            "(epoch: 125, iters: 690, time: 0.105, data: 0.178) G_GAN: 0.632 G_L1: 0.000 D_real: 0.627 D_fake: 0.766 \n",
            "(epoch: 125, iters: 790, time: 0.104, data: 0.156) G_GAN: 0.566 G_L1: 0.000 D_real: 0.533 D_fake: 0.896 \n",
            "(epoch: 125, iters: 890, time: 0.094, data: 0.087) G_GAN: 5.405 G_L1: 1.299 D_real: 0.524 D_fake: 0.001 \n",
            "End of epoch 125 / 200 \t Time Taken: 116 sec\n",
            "learning rate 0.0001485 -> 0.0001465\n",
            "(epoch: 126, iters: 76, time: 0.086, data: 0.163) G_GAN: 6.125 G_L1: 0.543 D_real: 0.004 D_fake: 0.003 \n",
            "(epoch: 126, iters: 176, time: 0.096, data: 0.057) G_GAN: 0.668 G_L1: 0.000 D_real: 0.652 D_fake: 0.745 \n",
            "(epoch: 126, iters: 276, time: 0.090, data: 0.141) G_GAN: 3.207 G_L1: 1.052 D_real: 0.006 D_fake: 0.185 \n",
            "(epoch: 126, iters: 376, time: 0.086, data: 0.070) G_GAN: 4.071 G_L1: 0.932 D_real: 0.009 D_fake: 0.218 \n",
            "(epoch: 126, iters: 476, time: 0.085, data: 0.105) G_GAN: 10.438 G_L1: 6.796 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 126, iters: 576, time: 0.097, data: 0.000) G_GAN: 7.079 G_L1: 5.095 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 126, iters: 676, time: 0.098, data: 0.110) G_GAN: 6.021 G_L1: 0.921 D_real: 0.005 D_fake: 0.004 \n",
            "(epoch: 126, iters: 776, time: 0.101, data: 0.000) G_GAN: 7.083 G_L1: 2.500 D_real: 0.005 D_fake: 0.002 \n",
            "(epoch: 126, iters: 876, time: 0.100, data: 0.000) G_GAN: 4.404 G_L1: 2.767 D_real: 0.002 D_fake: 0.030 \n",
            "End of epoch 126 / 200 \t Time Taken: 115 sec\n",
            "learning rate 0.0001465 -> 0.0001446\n",
            "(epoch: 127, iters: 62, time: 0.085, data: 0.000) G_GAN: 1.896 G_L1: 1.138 D_real: 0.260 D_fake: 0.331 \n",
            "(epoch: 127, iters: 162, time: 0.087, data: 0.001) G_GAN: 11.744 G_L1: 0.953 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 127, iters: 262, time: 0.118, data: 0.000) G_GAN: 7.842 G_L1: 2.414 D_real: 0.049 D_fake: 0.001 \n",
            "(epoch: 127, iters: 362, time: 0.093, data: 0.000) G_GAN: 10.132 G_L1: 1.436 D_real: 0.086 D_fake: 0.000 \n",
            "(epoch: 127, iters: 462, time: 0.095, data: 0.000) G_GAN: 3.738 G_L1: 2.574 D_real: 0.001 D_fake: 0.168 \n",
            "(epoch: 127, iters: 562, time: 0.099, data: 0.000) G_GAN: 4.323 G_L1: 3.331 D_real: 0.005 D_fake: 0.034 \n",
            "(epoch: 127, iters: 662, time: 0.096, data: 0.000) G_GAN: 9.014 G_L1: 3.197 D_real: 0.005 D_fake: 0.000 \n",
            "(epoch: 127, iters: 762, time: 0.082, data: 0.000) G_GAN: 5.426 G_L1: 1.620 D_real: 0.036 D_fake: 0.006 \n",
            "(epoch: 127, iters: 862, time: 0.091, data: 0.000) G_GAN: 5.425 G_L1: 0.377 D_real: 0.060 D_fake: 0.006 \n",
            "End of epoch 127 / 200 \t Time Taken: 119 sec\n",
            "learning rate 0.0001446 -> 0.0001426\n",
            "(epoch: 128, iters: 48, time: 0.072, data: 0.011) G_GAN: 0.703 G_L1: 0.000 D_real: 0.697 D_fake: 0.702 \n",
            "(epoch: 128, iters: 148, time: 0.107, data: 0.168) G_GAN: 3.120 G_L1: 1.158 D_real: 0.008 D_fake: 0.753 \n",
            "(epoch: 128, iters: 248, time: 0.081, data: 0.119) G_GAN: 0.683 G_L1: 0.000 D_real: 0.682 D_fake: 0.706 \n",
            "(epoch: 128, iters: 348, time: 0.103, data: 0.056) G_GAN: 0.415 G_L1: 0.796 D_real: 0.832 D_fake: 0.041 \n",
            "(epoch: 128, iters: 448, time: 0.109, data: 0.000) G_GAN: 5.282 G_L1: 2.973 D_real: 0.007 D_fake: 0.011 \n",
            "(epoch: 128, iters: 548, time: 0.111, data: 0.000) G_GAN: 7.141 G_L1: 5.824 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 128, iters: 648, time: 0.091, data: 0.000) G_GAN: 8.308 G_L1: 3.682 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 128, iters: 748, time: 0.086, data: 0.000) G_GAN: 4.567 G_L1: 1.292 D_real: 0.194 D_fake: 0.004 \n",
            "(epoch: 128, iters: 848, time: 0.098, data: 0.005) G_GAN: 2.020 G_L1: 1.302 D_real: 0.287 D_fake: 0.068 \n",
            "End of epoch 128 / 200 \t Time Taken: 119 sec\n",
            "learning rate 0.0001426 -> 0.0001406\n",
            "(epoch: 129, iters: 34, time: 0.078, data: 0.000) G_GAN: 3.277 G_L1: 1.456 D_real: 0.054 D_fake: 0.484 \n",
            "(epoch: 129, iters: 134, time: 0.098, data: 0.000) G_GAN: 4.616 G_L1: 1.761 D_real: 0.002 D_fake: 0.012 \n",
            "(epoch: 129, iters: 234, time: 0.083, data: 0.056) G_GAN: 6.400 G_L1: 2.092 D_real: 0.002 D_fake: 0.006 \n",
            "(epoch: 129, iters: 334, time: 0.079, data: 0.029) G_GAN: 5.235 G_L1: 2.298 D_real: 0.504 D_fake: 0.001 \n",
            "(epoch: 129, iters: 434, time: 0.099, data: 0.000) G_GAN: 7.724 G_L1: 2.078 D_real: 0.003 D_fake: 0.001 \n",
            "(epoch: 129, iters: 534, time: 0.066, data: 0.000) G_GAN: 0.640 G_L1: 0.001 D_real: 0.626 D_fake: 0.772 \n",
            "(epoch: 129, iters: 634, time: 0.088, data: 0.103) G_GAN: 2.947 G_L1: 1.401 D_real: 1.029 D_fake: 0.014 \n",
            "(epoch: 129, iters: 734, time: 0.090, data: 0.000) G_GAN: 5.290 G_L1: 3.132 D_real: 0.001 D_fake: 0.008 \n",
            "(epoch: 129, iters: 834, time: 0.114, data: 0.000) G_GAN: 2.659 G_L1: 0.515 D_real: 1.481 D_fake: 0.003 \n",
            "End of epoch 129 / 200 \t Time Taken: 117 sec\n",
            "learning rate 0.0001406 -> 0.0001386\n",
            "(epoch: 130, iters: 20, time: 0.087, data: 0.037) G_GAN: 3.487 G_L1: 1.122 D_real: 0.015 D_fake: 0.064 \n",
            "(epoch: 130, iters: 120, time: 0.100, data: 0.061) G_GAN: 7.469 G_L1: 0.867 D_real: 0.001 D_fake: 1.307 \n",
            "(epoch: 130, iters: 220, time: 0.070, data: 0.003) G_GAN: 7.804 G_L1: 4.022 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 130, iters: 320, time: 0.083, data: 0.000) G_GAN: 0.652 G_L1: 0.000 D_real: 0.635 D_fake: 0.766 \n",
            "saving the latest model (epoch 130, total_iters 110000)\n",
            "(epoch: 130, iters: 420, time: 0.086, data: 0.000) G_GAN: 0.747 G_L1: 0.001 D_real: 0.751 D_fake: 0.665 \n",
            "(epoch: 130, iters: 520, time: 0.092, data: 0.086) G_GAN: 8.688 G_L1: 3.586 D_real: 0.010 D_fake: 0.000 \n",
            "(epoch: 130, iters: 620, time: 0.101, data: 0.002) G_GAN: 9.575 G_L1: 2.076 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 130, iters: 720, time: 0.074, data: 0.000) G_GAN: 9.475 G_L1: 1.183 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 130, iters: 820, time: 0.092, data: 0.000) G_GAN: 6.220 G_L1: 0.683 D_real: 0.002 D_fake: 0.008 \n",
            "End of epoch 130 / 200 \t Time Taken: 119 sec\n",
            "learning rate 0.0001386 -> 0.0001366\n",
            "(epoch: 131, iters: 6, time: 0.071, data: 0.000) G_GAN: 4.239 G_L1: 2.837 D_real: 0.010 D_fake: 0.036 \n",
            "(epoch: 131, iters: 106, time: 0.088, data: 0.000) G_GAN: 10.535 G_L1: 6.852 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 131, iters: 206, time: 0.105, data: 0.120) G_GAN: 8.051 G_L1: 5.231 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 131, iters: 306, time: 0.093, data: 0.211) G_GAN: 9.307 G_L1: 5.584 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 131, iters: 406, time: 0.098, data: 0.176) G_GAN: 7.466 G_L1: 2.546 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 131, iters: 506, time: 0.102, data: 0.009) G_GAN: 3.749 G_L1: 8.035 D_real: 0.000 D_fake: 0.029 \n",
            "(epoch: 131, iters: 606, time: 0.075, data: 0.000) G_GAN: 6.885 G_L1: 3.598 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 131, iters: 706, time: 0.116, data: 0.004) G_GAN: 7.302 G_L1: 2.372 D_real: 0.006 D_fake: 0.001 \n",
            "(epoch: 131, iters: 806, time: 0.070, data: 0.067) G_GAN: 9.468 G_L1: 5.130 D_real: 0.006 D_fake: 0.000 \n",
            "(epoch: 131, iters: 906, time: 0.085, data: 0.003) G_GAN: 10.189 G_L1: 6.483 D_real: 0.002 D_fake: 0.000 \n",
            "End of epoch 131 / 200 \t Time Taken: 120 sec\n",
            "learning rate 0.0001366 -> 0.0001347\n",
            "(epoch: 132, iters: 92, time: 0.097, data: 0.000) G_GAN: 0.604 G_L1: 0.000 D_real: 0.585 D_fake: 0.820 \n",
            "(epoch: 132, iters: 192, time: 0.068, data: 0.000) G_GAN: 6.029 G_L1: 4.603 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 132, iters: 292, time: 0.087, data: 0.000) G_GAN: 0.790 G_L1: 0.000 D_real: 0.731 D_fake: 0.668 \n",
            "(epoch: 132, iters: 392, time: 0.099, data: 0.000) G_GAN: 5.030 G_L1: 1.868 D_real: 0.215 D_fake: 0.006 \n",
            "(epoch: 132, iters: 492, time: 0.103, data: 0.006) G_GAN: 6.035 G_L1: 1.123 D_real: 0.016 D_fake: 0.003 \n",
            "(epoch: 132, iters: 592, time: 0.078, data: 0.000) G_GAN: 1.098 G_L1: 1.221 D_real: 0.587 D_fake: 0.061 \n",
            "(epoch: 132, iters: 692, time: 0.092, data: 0.000) G_GAN: 0.575 G_L1: 0.002 D_real: 0.568 D_fake: 0.861 \n",
            "(epoch: 132, iters: 792, time: 0.093, data: 0.000) G_GAN: 0.685 G_L1: 0.000 D_real: 0.691 D_fake: 0.699 \n",
            "(epoch: 132, iters: 892, time: 0.077, data: 0.011) G_GAN: 5.282 G_L1: 0.707 D_real: 0.008 D_fake: 0.006 \n",
            "End of epoch 132 / 200 \t Time Taken: 120 sec\n",
            "learning rate 0.0001347 -> 0.0001327\n",
            "(epoch: 133, iters: 78, time: 0.076, data: 0.255) G_GAN: 0.693 G_L1: 0.000 D_real: 0.696 D_fake: 0.693 \n",
            "(epoch: 133, iters: 178, time: 0.103, data: 0.000) G_GAN: 2.852 G_L1: 0.324 D_real: 0.024 D_fake: 1.089 \n",
            "(epoch: 133, iters: 278, time: 0.101, data: 0.156) G_GAN: 11.047 G_L1: 5.684 D_real: 0.018 D_fake: 0.000 \n",
            "(epoch: 133, iters: 378, time: 0.098, data: 0.161) G_GAN: 0.576 G_L1: 0.000 D_real: 0.540 D_fake: 0.876 \n",
            "(epoch: 133, iters: 478, time: 0.085, data: 0.045) G_GAN: 8.165 G_L1: 3.737 D_real: 0.126 D_fake: 0.000 \n",
            "(epoch: 133, iters: 578, time: 0.095, data: 0.019) G_GAN: 6.811 G_L1: 8.172 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 133, iters: 678, time: 0.085, data: 0.168) G_GAN: 4.710 G_L1: 3.665 D_real: 0.000 D_fake: 0.026 \n",
            "(epoch: 133, iters: 778, time: 0.098, data: 0.134) G_GAN: 9.109 G_L1: 3.594 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 133, iters: 878, time: 0.094, data: 0.022) G_GAN: 9.103 G_L1: 2.740 D_real: 0.432 D_fake: 0.000 \n",
            "End of epoch 133 / 200 \t Time Taken: 118 sec\n",
            "learning rate 0.0001327 -> 0.0001307\n",
            "(epoch: 134, iters: 64, time: 0.081, data: 0.248) G_GAN: 0.433 G_L1: 0.000 D_real: 0.388 D_fake: 1.169 \n",
            "(epoch: 134, iters: 164, time: 0.087, data: 0.003) G_GAN: 4.633 G_L1: 0.754 D_real: 0.004 D_fake: 0.590 \n",
            "(epoch: 134, iters: 264, time: 0.079, data: 0.165) G_GAN: 0.658 G_L1: 0.000 D_real: 0.661 D_fake: 0.745 \n",
            "(epoch: 134, iters: 364, time: 0.097, data: 0.094) G_GAN: 0.667 G_L1: 0.000 D_real: 0.657 D_fake: 0.738 \n",
            "(epoch: 134, iters: 464, time: 0.094, data: 0.003) G_GAN: 12.333 G_L1: 1.024 D_real: 0.006 D_fake: 0.000 \n",
            "(epoch: 134, iters: 564, time: 0.096, data: 0.000) G_GAN: 11.642 G_L1: 7.711 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 134, iters: 664, time: 0.076, data: 0.000) G_GAN: 3.565 G_L1: 0.256 D_real: 2.222 D_fake: 0.001 \n",
            "(epoch: 134, iters: 764, time: 0.096, data: 0.000) G_GAN: 7.929 G_L1: 0.637 D_real: 0.040 D_fake: 0.000 \n",
            "(epoch: 134, iters: 864, time: 0.068, data: 0.124) G_GAN: 4.419 G_L1: 1.567 D_real: 0.017 D_fake: 0.413 \n",
            "End of epoch 134 / 200 \t Time Taken: 117 sec\n",
            "learning rate 0.0001307 -> 0.0001287\n",
            "(epoch: 135, iters: 50, time: 0.109, data: 0.000) G_GAN: 5.608 G_L1: 2.553 D_real: 0.000 D_fake: 0.007 \n",
            "(epoch: 135, iters: 150, time: 0.098, data: 0.000) G_GAN: 2.691 G_L1: 0.753 D_real: 0.009 D_fake: 0.120 \n",
            "(epoch: 135, iters: 250, time: 0.106, data: 0.000) G_GAN: 7.222 G_L1: 4.183 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 135, iters: 350, time: 0.082, data: 0.000) G_GAN: 12.490 G_L1: 2.852 D_real: 0.028 D_fake: 0.000 \n",
            "(epoch: 135, iters: 450, time: 0.075, data: 0.001) G_GAN: 6.919 G_L1: 3.068 D_real: 0.002 D_fake: 0.002 \n",
            "(epoch: 135, iters: 550, time: 0.103, data: 0.191) G_GAN: 6.184 G_L1: 2.116 D_real: 0.001 D_fake: 0.005 \n",
            "(epoch: 135, iters: 650, time: 0.084, data: 0.038) G_GAN: 0.720 G_L1: 0.000 D_real: 0.738 D_fake: 0.658 \n",
            "(epoch: 135, iters: 750, time: 0.090, data: 0.002) G_GAN: 9.562 G_L1: 3.668 D_real: 0.562 D_fake: 0.000 \n",
            "saving the latest model (epoch 135, total_iters 115000)\n",
            "(epoch: 135, iters: 850, time: 0.104, data: 0.007) G_GAN: 0.679 G_L1: 0.000 D_real: 0.669 D_fake: 0.725 \n",
            "End of epoch 135 / 200 \t Time Taken: 125 sec\n",
            "learning rate 0.0001287 -> 0.0001267\n",
            "(epoch: 136, iters: 36, time: 0.073, data: 0.012) G_GAN: 0.689 G_L1: 0.000 D_real: 0.685 D_fake: 0.710 \n",
            "(epoch: 136, iters: 136, time: 0.102, data: 0.186) G_GAN: 0.519 G_L1: 0.000 D_real: 0.476 D_fake: 0.984 \n",
            "(epoch: 136, iters: 236, time: 0.087, data: 0.188) G_GAN: 0.698 G_L1: 0.000 D_real: 0.719 D_fake: 0.671 \n",
            "(epoch: 136, iters: 336, time: 0.093, data: 0.024) G_GAN: 9.197 G_L1: 3.630 D_real: 0.008 D_fake: 0.000 \n",
            "(epoch: 136, iters: 436, time: 0.108, data: 0.064) G_GAN: 0.696 G_L1: 0.000 D_real: 0.705 D_fake: 0.686 \n",
            "(epoch: 136, iters: 536, time: 0.083, data: 0.000) G_GAN: 0.636 G_L1: 0.000 D_real: 0.641 D_fake: 0.767 \n",
            "(epoch: 136, iters: 636, time: 0.084, data: 0.000) G_GAN: 10.419 G_L1: 3.452 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 136, iters: 736, time: 0.090, data: 0.000) G_GAN: 0.819 G_L1: 0.058 D_real: 0.021 D_fake: 0.703 \n",
            "(epoch: 136, iters: 836, time: 0.086, data: 0.000) G_GAN: 3.623 G_L1: 0.150 D_real: 0.160 D_fake: 0.500 \n",
            "End of epoch 136 / 200 \t Time Taken: 118 sec\n",
            "learning rate 0.0001267 -> 0.0001248\n",
            "(epoch: 137, iters: 22, time: 0.101, data: 0.000) G_GAN: 7.706 G_L1: 2.254 D_real: 0.022 D_fake: 0.002 \n",
            "(epoch: 137, iters: 122, time: 0.082, data: 0.000) G_GAN: 5.159 G_L1: 5.647 D_real: 0.000 D_fake: 0.013 \n",
            "(epoch: 137, iters: 222, time: 0.091, data: 0.000) G_GAN: 7.546 G_L1: 5.773 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 137, iters: 322, time: 0.106, data: 0.059) G_GAN: 1.490 G_L1: 1.135 D_real: 0.661 D_fake: 0.029 \n",
            "(epoch: 137, iters: 422, time: 0.095, data: 0.161) G_GAN: 2.634 G_L1: 0.472 D_real: 0.031 D_fake: 0.199 \n",
            "(epoch: 137, iters: 522, time: 0.077, data: 0.105) G_GAN: 0.557 G_L1: 1.983 D_real: 1.200 D_fake: 0.151 \n",
            "(epoch: 137, iters: 622, time: 0.094, data: 0.120) G_GAN: 7.948 G_L1: 9.996 D_real: 0.033 D_fake: 0.001 \n",
            "(epoch: 137, iters: 722, time: 0.093, data: 0.045) G_GAN: 8.138 G_L1: 0.708 D_real: 0.137 D_fake: 0.001 \n",
            "(epoch: 137, iters: 822, time: 0.081, data: 0.138) G_GAN: 0.610 G_L1: 0.000 D_real: 0.610 D_fake: 0.794 \n",
            "End of epoch 137 / 200 \t Time Taken: 119 sec\n",
            "learning rate 0.0001248 -> 0.0001228\n",
            "(epoch: 138, iters: 8, time: 0.103, data: 0.088) G_GAN: 7.802 G_L1: 7.400 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 138, iters: 108, time: 0.106, data: 0.002) G_GAN: 8.068 G_L1: 4.158 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 138, iters: 208, time: 0.103, data: 0.000) G_GAN: 0.795 G_L1: 0.001 D_real: 0.798 D_fake: 0.604 \n",
            "(epoch: 138, iters: 308, time: 0.056, data: 0.000) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.701 \n",
            "(epoch: 138, iters: 408, time: 0.077, data: 0.187) G_GAN: 4.470 G_L1: 4.070 D_real: 0.000 D_fake: 0.022 \n",
            "(epoch: 138, iters: 508, time: 0.099, data: 0.000) G_GAN: 10.120 G_L1: 6.321 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 138, iters: 608, time: 0.079, data: 0.003) G_GAN: 0.873 G_L1: 0.000 D_real: 0.932 D_fake: 0.510 \n",
            "(epoch: 138, iters: 708, time: 0.094, data: 0.000) G_GAN: 0.674 G_L1: 0.000 D_real: 0.647 D_fake: 0.752 \n",
            "(epoch: 138, iters: 808, time: 0.095, data: 0.000) G_GAN: 0.629 G_L1: 0.000 D_real: 0.621 D_fake: 0.778 \n",
            "(epoch: 138, iters: 908, time: 0.073, data: 0.067) G_GAN: 5.184 G_L1: 0.369 D_real: 2.820 D_fake: 0.000 \n",
            "End of epoch 138 / 200 \t Time Taken: 118 sec\n",
            "learning rate 0.0001228 -> 0.0001208\n",
            "(epoch: 139, iters: 94, time: 0.106, data: 0.041) G_GAN: 9.629 G_L1: 1.878 D_real: 0.016 D_fake: 0.000 \n",
            "(epoch: 139, iters: 194, time: 0.086, data: 0.000) G_GAN: 10.748 G_L1: 10.889 D_real: 0.007 D_fake: 0.000 \n",
            "(epoch: 139, iters: 294, time: 0.109, data: 0.000) G_GAN: 0.741 G_L1: 0.000 D_real: 0.775 D_fake: 0.622 \n",
            "(epoch: 139, iters: 394, time: 0.094, data: 0.002) G_GAN: 7.096 G_L1: 1.735 D_real: 0.021 D_fake: 0.001 \n",
            "(epoch: 139, iters: 494, time: 0.066, data: 0.000) G_GAN: 2.676 G_L1: 1.146 D_real: 0.045 D_fake: 0.258 \n",
            "(epoch: 139, iters: 594, time: 0.091, data: 0.000) G_GAN: 6.038 G_L1: 1.684 D_real: 0.016 D_fake: 0.003 \n",
            "(epoch: 139, iters: 694, time: 0.095, data: 0.000) G_GAN: 12.094 G_L1: 1.221 D_real: 0.008 D_fake: 0.000 \n",
            "(epoch: 139, iters: 794, time: 0.101, data: 0.000) G_GAN: 13.179 G_L1: 0.832 D_real: 0.091 D_fake: 0.000 \n",
            "(epoch: 139, iters: 894, time: 0.086, data: 0.008) G_GAN: 2.414 G_L1: 0.372 D_real: 0.145 D_fake: 0.313 \n",
            "End of epoch 139 / 200 \t Time Taken: 118 sec\n",
            "learning rate 0.0001208 -> 0.0001188\n",
            "(epoch: 140, iters: 80, time: 0.062, data: 0.000) G_GAN: 4.279 G_L1: 2.621 D_real: 0.000 D_fake: 0.030 \n",
            "(epoch: 140, iters: 180, time: 0.103, data: 0.000) G_GAN: 7.952 G_L1: 8.886 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 140, iters: 280, time: 0.070, data: 0.003) G_GAN: 0.621 G_L1: 0.000 D_real: 0.591 D_fake: 0.813 \n",
            "(epoch: 140, iters: 380, time: 0.108, data: 0.194) G_GAN: 7.485 G_L1: 3.129 D_real: 0.222 D_fake: 0.000 \n",
            "(epoch: 140, iters: 480, time: 0.096, data: 0.000) G_GAN: 7.074 G_L1: 1.212 D_real: 0.301 D_fake: 0.001 \n",
            "(epoch: 140, iters: 580, time: 0.063, data: 0.016) G_GAN: 6.004 G_L1: 1.429 D_real: 0.001 D_fake: 0.004 \n",
            "(epoch: 140, iters: 680, time: 0.079, data: 0.000) G_GAN: 8.144 G_L1: 2.447 D_real: 0.003 D_fake: 0.001 \n",
            "(epoch: 140, iters: 780, time: 0.085, data: 0.001) G_GAN: 0.737 G_L1: 0.001 D_real: 0.779 D_fake: 0.642 \n",
            "(epoch: 140, iters: 880, time: 0.103, data: 0.002) G_GAN: 5.167 G_L1: 1.152 D_real: 0.008 D_fake: 0.009 \n",
            "End of epoch 140 / 200 \t Time Taken: 118 sec\n",
            "learning rate 0.0001188 -> 0.0001168\n",
            "(epoch: 141, iters: 66, time: 0.085, data: 0.000) G_GAN: 2.140 G_L1: 1.921 D_real: 1.096 D_fake: 0.037 \n",
            "(epoch: 141, iters: 166, time: 0.079, data: 0.000) G_GAN: 0.716 G_L1: 0.000 D_real: 0.719 D_fake: 0.687 \n",
            "(epoch: 141, iters: 266, time: 0.105, data: 0.051) G_GAN: 3.029 G_L1: 0.538 D_real: 0.202 D_fake: 0.030 \n",
            "saving the latest model (epoch 141, total_iters 120000)\n",
            "(epoch: 141, iters: 366, time: 0.090, data: 0.004) G_GAN: 10.794 G_L1: 2.965 D_real: 0.003 D_fake: 0.000 \n",
            "(epoch: 141, iters: 466, time: 0.082, data: 0.000) G_GAN: 5.300 G_L1: 6.348 D_real: 0.001 D_fake: 0.014 \n",
            "(epoch: 141, iters: 566, time: 0.094, data: 0.000) G_GAN: 5.805 G_L1: 4.394 D_real: 0.000 D_fake: 0.007 \n",
            "(epoch: 141, iters: 666, time: 0.099, data: 0.000) G_GAN: 7.640 G_L1: 8.353 D_real: 0.010 D_fake: 0.001 \n",
            "(epoch: 141, iters: 766, time: 0.101, data: 0.008) G_GAN: 5.359 G_L1: 15.470 D_real: 0.001 D_fake: 0.013 \n",
            "(epoch: 141, iters: 866, time: 0.080, data: 0.120) G_GAN: 4.783 G_L1: 1.098 D_real: 0.153 D_fake: 0.004 \n",
            "End of epoch 141 / 200 \t Time Taken: 120 sec\n",
            "learning rate 0.0001168 -> 0.0001149\n",
            "(epoch: 142, iters: 52, time: 0.071, data: 0.154) G_GAN: 0.698 G_L1: 0.000 D_real: 0.693 D_fake: 0.698 \n",
            "(epoch: 142, iters: 152, time: 0.102, data: 0.136) G_GAN: 14.343 G_L1: 2.361 D_real: 0.050 D_fake: 0.000 \n",
            "(epoch: 142, iters: 252, time: 0.075, data: 0.000) G_GAN: 9.296 G_L1: 5.060 D_real: 0.025 D_fake: 0.000 \n",
            "(epoch: 142, iters: 352, time: 0.089, data: 0.000) G_GAN: 6.385 G_L1: 2.724 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 142, iters: 452, time: 0.087, data: 0.000) G_GAN: 3.789 G_L1: 0.365 D_real: 0.008 D_fake: 0.251 \n",
            "(epoch: 142, iters: 552, time: 0.086, data: 0.000) G_GAN: 10.870 G_L1: 4.899 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 142, iters: 652, time: 0.081, data: 0.000) G_GAN: 6.566 G_L1: 4.026 D_real: 0.008 D_fake: 0.002 \n",
            "(epoch: 142, iters: 752, time: 0.104, data: 0.000) G_GAN: 11.271 G_L1: 2.877 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 142, iters: 852, time: 0.091, data: 0.000) G_GAN: 6.120 G_L1: 12.356 D_real: 0.003 D_fake: 0.008 \n",
            "End of epoch 142 / 200 \t Time Taken: 119 sec\n",
            "learning rate 0.0001149 -> 0.0001129\n",
            "(epoch: 143, iters: 38, time: 0.087, data: 0.000) G_GAN: 7.164 G_L1: 2.275 D_real: 0.003 D_fake: 0.002 \n",
            "(epoch: 143, iters: 138, time: 0.106, data: 0.000) G_GAN: 1.434 G_L1: 0.536 D_real: 0.459 D_fake: 0.045 \n",
            "(epoch: 143, iters: 238, time: 0.061, data: 0.000) G_GAN: 0.742 G_L1: 0.000 D_real: 0.731 D_fake: 0.660 \n",
            "(epoch: 143, iters: 338, time: 0.070, data: 0.000) G_GAN: 0.560 G_L1: 0.000 D_real: 0.559 D_fake: 0.874 \n",
            "(epoch: 143, iters: 438, time: 0.083, data: 0.000) G_GAN: 0.693 G_L1: 0.000 D_real: 0.690 D_fake: 0.705 \n",
            "(epoch: 143, iters: 538, time: 0.065, data: 0.004) G_GAN: 0.686 G_L1: 0.000 D_real: 0.686 D_fake: 0.711 \n",
            "(epoch: 143, iters: 638, time: 0.077, data: 0.000) G_GAN: 9.391 G_L1: 3.592 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 143, iters: 738, time: 0.104, data: 0.000) G_GAN: 10.343 G_L1: 5.343 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 143, iters: 838, time: 0.089, data: 0.000) G_GAN: 12.310 G_L1: 1.731 D_real: 0.011 D_fake: 0.000 \n",
            "End of epoch 143 / 200 \t Time Taken: 120 sec\n",
            "learning rate 0.0001129 -> 0.0001109\n",
            "(epoch: 144, iters: 24, time: 0.079, data: 0.000) G_GAN: 0.581 G_L1: 0.000 D_real: 0.515 D_fake: 0.914 \n",
            "(epoch: 144, iters: 124, time: 0.102, data: 0.199) G_GAN: 3.486 G_L1: 0.725 D_real: 0.008 D_fake: 0.093 \n",
            "(epoch: 144, iters: 224, time: 0.090, data: 0.126) G_GAN: 3.790 G_L1: 5.450 D_real: 0.001 D_fake: 0.084 \n",
            "(epoch: 144, iters: 324, time: 0.092, data: 0.000) G_GAN: 3.110 G_L1: 0.238 D_real: 0.013 D_fake: 0.468 \n",
            "(epoch: 144, iters: 424, time: 0.079, data: 0.000) G_GAN: 0.669 G_L1: 0.000 D_real: 0.664 D_fake: 0.726 \n",
            "(epoch: 144, iters: 524, time: 0.096, data: 0.002) G_GAN: 7.872 G_L1: 1.764 D_real: 0.096 D_fake: 0.001 \n",
            "(epoch: 144, iters: 624, time: 0.084, data: 0.000) G_GAN: 3.715 G_L1: 3.312 D_real: 0.029 D_fake: 1.329 \n",
            "(epoch: 144, iters: 724, time: 0.098, data: 0.001) G_GAN: 10.641 G_L1: 1.575 D_real: 0.939 D_fake: 0.000 \n",
            "(epoch: 144, iters: 824, time: 0.088, data: 0.013) G_GAN: 4.396 G_L1: 2.616 D_real: 0.300 D_fake: 0.004 \n",
            "End of epoch 144 / 200 \t Time Taken: 119 sec\n",
            "learning rate 0.0001109 -> 0.0001089\n",
            "(epoch: 145, iters: 10, time: 0.078, data: 0.028) G_GAN: 3.803 G_L1: 0.637 D_real: 0.341 D_fake: 0.011 \n",
            "(epoch: 145, iters: 110, time: 0.068, data: 0.000) G_GAN: 5.464 G_L1: 3.549 D_real: 0.003 D_fake: 0.013 \n",
            "(epoch: 145, iters: 210, time: 0.083, data: 0.000) G_GAN: 0.771 G_L1: 0.000 D_real: 0.768 D_fake: 0.629 \n",
            "(epoch: 145, iters: 310, time: 0.092, data: 0.000) G_GAN: 2.980 G_L1: 1.446 D_real: 0.056 D_fake: 0.074 \n",
            "(epoch: 145, iters: 410, time: 0.071, data: 0.000) G_GAN: 2.767 G_L1: 0.505 D_real: 0.206 D_fake: 0.027 \n",
            "(epoch: 145, iters: 510, time: 0.076, data: 0.001) G_GAN: 8.387 G_L1: 4.780 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 145, iters: 610, time: 0.100, data: 0.000) G_GAN: 6.582 G_L1: 3.214 D_real: 0.003 D_fake: 0.003 \n",
            "(epoch: 145, iters: 710, time: 0.092, data: 0.000) G_GAN: 11.483 G_L1: 1.304 D_real: 0.034 D_fake: 0.000 \n",
            "(epoch: 145, iters: 810, time: 0.067, data: 0.007) G_GAN: 10.977 G_L1: 1.637 D_real: 0.017 D_fake: 0.000 \n",
            "(epoch: 145, iters: 910, time: 0.057, data: 0.000) G_GAN: 0.667 G_L1: 0.000 D_real: 0.674 D_fake: 0.720 \n",
            "End of epoch 145 / 200 \t Time Taken: 120 sec\n",
            "learning rate 0.0001089 -> 0.0001069\n",
            "(epoch: 146, iters: 96, time: 0.085, data: 0.000) G_GAN: 9.639 G_L1: 7.120 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 146, iters: 196, time: 0.089, data: 0.143) G_GAN: 9.474 G_L1: 6.190 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 146, iters: 296, time: 0.110, data: 0.000) G_GAN: 8.244 G_L1: 4.896 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 146, iters: 396, time: 0.096, data: 0.000) G_GAN: 6.242 G_L1: 0.977 D_real: 0.002 D_fake: 0.004 \n",
            "(epoch: 146, iters: 496, time: 0.086, data: 0.000) G_GAN: 8.275 G_L1: 4.648 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 146, iters: 596, time: 0.104, data: 0.001) G_GAN: 0.628 G_L1: 0.000 D_real: 0.606 D_fake: 0.795 \n",
            "(epoch: 146, iters: 696, time: 0.066, data: 0.001) G_GAN: 13.377 G_L1: 4.940 D_real: 0.020 D_fake: 0.000 \n",
            "saving the latest model (epoch 146, total_iters 125000)\n",
            "(epoch: 146, iters: 796, time: 0.110, data: 0.000) G_GAN: 0.742 G_L1: 0.000 D_real: 0.742 D_fake: 0.649 \n",
            "(epoch: 146, iters: 896, time: 0.097, data: 0.000) G_GAN: 6.555 G_L1: 0.932 D_real: 0.013 D_fake: 0.002 \n",
            "End of epoch 146 / 200 \t Time Taken: 122 sec\n",
            "learning rate 0.0001069 -> 0.0001050\n",
            "(epoch: 147, iters: 82, time: 0.097, data: 0.000) G_GAN: 10.865 G_L1: 0.613 D_real: 0.022 D_fake: 0.000 \n",
            "(epoch: 147, iters: 182, time: 0.092, data: 0.000) G_GAN: 0.696 G_L1: 0.000 D_real: 0.690 D_fake: 0.699 \n",
            "(epoch: 147, iters: 282, time: 0.081, data: 0.001) G_GAN: 3.094 G_L1: 1.488 D_real: 0.090 D_fake: 0.103 \n",
            "(epoch: 147, iters: 382, time: 0.108, data: 0.000) G_GAN: 9.004 G_L1: 4.590 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 147, iters: 482, time: 0.096, data: 0.000) G_GAN: 10.633 G_L1: 0.929 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 147, iters: 582, time: 0.074, data: 0.000) G_GAN: 9.833 G_L1: 1.975 D_real: 0.003 D_fake: 0.000 \n",
            "(epoch: 147, iters: 682, time: 0.086, data: 0.093) G_GAN: 5.117 G_L1: 1.194 D_real: 0.689 D_fake: 0.003 \n",
            "(epoch: 147, iters: 782, time: 0.090, data: 0.000) G_GAN: 9.624 G_L1: 2.333 D_real: 0.003 D_fake: 0.000 \n",
            "(epoch: 147, iters: 882, time: 0.108, data: 0.005) G_GAN: 6.318 G_L1: 2.610 D_real: 0.001 D_fake: 0.004 \n",
            "End of epoch 147 / 200 \t Time Taken: 122 sec\n",
            "learning rate 0.0001050 -> 0.0001030\n",
            "(epoch: 148, iters: 68, time: 0.093, data: 0.000) G_GAN: 12.975 G_L1: 6.364 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 148, iters: 168, time: 0.095, data: 0.000) G_GAN: 11.185 G_L1: 4.402 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 148, iters: 268, time: 0.091, data: 0.000) G_GAN: 4.356 G_L1: 0.975 D_real: 0.052 D_fake: 0.015 \n",
            "(epoch: 148, iters: 368, time: 0.073, data: 0.000) G_GAN: 6.224 G_L1: 0.462 D_real: 0.052 D_fake: 0.002 \n",
            "(epoch: 148, iters: 468, time: 0.099, data: 0.153) G_GAN: 0.697 G_L1: 0.000 D_real: 0.721 D_fake: 0.673 \n",
            "(epoch: 148, iters: 568, time: 0.081, data: 0.091) G_GAN: 7.759 G_L1: 0.889 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 148, iters: 668, time: 0.085, data: 0.000) G_GAN: 0.706 G_L1: 0.000 D_real: 0.708 D_fake: 0.681 \n",
            "(epoch: 148, iters: 768, time: 0.079, data: 0.000) G_GAN: 0.681 G_L1: 0.000 D_real: 0.677 D_fake: 0.713 \n",
            "(epoch: 148, iters: 868, time: 0.074, data: 0.030) G_GAN: 6.837 G_L1: 1.852 D_real: 0.072 D_fake: 0.002 \n",
            "End of epoch 148 / 200 \t Time Taken: 123 sec\n",
            "learning rate 0.0001030 -> 0.0001010\n",
            "(epoch: 149, iters: 54, time: 0.081, data: 0.000) G_GAN: 8.008 G_L1: 0.216 D_real: 0.052 D_fake: 0.000 \n",
            "(epoch: 149, iters: 154, time: 0.112, data: 0.000) G_GAN: 12.243 G_L1: 0.574 D_real: 0.093 D_fake: 0.000 \n",
            "(epoch: 149, iters: 254, time: 0.104, data: 0.000) G_GAN: 3.107 G_L1: 0.579 D_real: 0.046 D_fake: 0.087 \n",
            "(epoch: 149, iters: 354, time: 0.111, data: 0.000) G_GAN: 0.665 G_L1: 0.000 D_real: 0.672 D_fake: 0.729 \n",
            "(epoch: 149, iters: 454, time: 0.068, data: 0.000) G_GAN: 10.637 G_L1: 3.694 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 149, iters: 554, time: 0.097, data: 0.000) G_GAN: 5.427 G_L1: 2.619 D_real: 0.016 D_fake: 0.007 \n",
            "(epoch: 149, iters: 654, time: 0.078, data: 0.000) G_GAN: 0.781 G_L1: 0.000 D_real: 0.785 D_fake: 0.618 \n",
            "(epoch: 149, iters: 754, time: 0.120, data: 0.002) G_GAN: 9.777 G_L1: 4.366 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 149, iters: 854, time: 0.085, data: 0.000) G_GAN: 8.756 G_L1: 5.886 D_real: 0.000 D_fake: 0.000 \n",
            "End of epoch 149 / 200 \t Time Taken: 120 sec\n",
            "learning rate 0.0001010 -> 0.0000990\n",
            "(epoch: 150, iters: 40, time: 0.115, data: 0.000) G_GAN: 0.851 G_L1: 0.000 D_real: 0.904 D_fake: 0.534 \n",
            "(epoch: 150, iters: 140, time: 0.075, data: 0.013) G_GAN: 0.704 G_L1: 0.000 D_real: 0.710 D_fake: 0.680 \n",
            "(epoch: 150, iters: 240, time: 0.104, data: 0.005) G_GAN: 7.047 G_L1: 5.735 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 150, iters: 340, time: 0.098, data: 0.000) G_GAN: 7.473 G_L1: 2.005 D_real: 0.009 D_fake: 0.001 \n",
            "(epoch: 150, iters: 440, time: 0.081, data: 0.000) G_GAN: 5.328 G_L1: 0.861 D_real: 0.572 D_fake: 0.001 \n",
            "(epoch: 150, iters: 540, time: 0.087, data: 0.000) G_GAN: 7.757 G_L1: 1.094 D_real: 0.005 D_fake: 0.001 \n",
            "(epoch: 150, iters: 640, time: 0.104, data: 0.000) G_GAN: 7.418 G_L1: 3.195 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 150, iters: 740, time: 0.094, data: 0.000) G_GAN: 10.249 G_L1: 8.811 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 150, iters: 840, time: 0.093, data: 0.000) G_GAN: 7.263 G_L1: 0.231 D_real: 0.311 D_fake: 0.000 \n",
            "End of epoch 150 / 200 \t Time Taken: 120 sec\n",
            "learning rate 0.0000990 -> 0.0000970\n",
            "(epoch: 151, iters: 26, time: 0.095, data: 0.000) G_GAN: 3.207 G_L1: 0.863 D_real: 0.240 D_fake: 0.040 \n",
            "(epoch: 151, iters: 126, time: 0.096, data: 0.000) G_GAN: 8.805 G_L1: 12.545 D_real: 0.004 D_fake: 0.000 \n",
            "(epoch: 151, iters: 226, time: 0.101, data: 0.000) G_GAN: 3.075 G_L1: 0.874 D_real: 0.074 D_fake: 0.307 \n",
            "(epoch: 151, iters: 326, time: 0.093, data: 0.000) G_GAN: 8.510 G_L1: 6.405 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 151, iters: 426, time: 0.073, data: 0.000) G_GAN: 8.524 G_L1: 6.088 D_real: 0.003 D_fake: 0.001 \n",
            "(epoch: 151, iters: 526, time: 0.102, data: 0.001) G_GAN: 7.748 G_L1: 1.651 D_real: 0.569 D_fake: 0.000 \n",
            "(epoch: 151, iters: 626, time: 0.066, data: 0.000) G_GAN: 8.714 G_L1: 6.429 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 151, iters: 726, time: 0.086, data: 0.000) G_GAN: 7.376 G_L1: 5.911 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 151, iters: 826, time: 0.077, data: 0.152) G_GAN: 2.297 G_L1: 0.196 D_real: 0.082 D_fake: 1.588 \n",
            "End of epoch 151 / 200 \t Time Taken: 120 sec\n",
            "learning rate 0.0000970 -> 0.0000950\n",
            "(epoch: 152, iters: 12, time: 0.099, data: 0.000) G_GAN: 10.049 G_L1: 2.264 D_real: 0.027 D_fake: 0.000 \n",
            "(epoch: 152, iters: 112, time: 0.095, data: 0.143) G_GAN: 1.347 G_L1: 0.453 D_real: 0.401 D_fake: 0.694 \n",
            "(epoch: 152, iters: 212, time: 0.091, data: 0.141) G_GAN: 8.352 G_L1: 3.003 D_real: 0.138 D_fake: 0.000 \n",
            "saving the latest model (epoch 152, total_iters 130000)\n",
            "(epoch: 152, iters: 312, time: 0.074, data: 0.004) G_GAN: 5.644 G_L1: 0.941 D_real: 0.024 D_fake: 0.005 \n",
            "(epoch: 152, iters: 412, time: 0.095, data: 0.000) G_GAN: 5.345 G_L1: 1.915 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 152, iters: 512, time: 0.079, data: 0.057) G_GAN: 6.071 G_L1: 3.231 D_real: 0.010 D_fake: 0.004 \n",
            "(epoch: 152, iters: 612, time: 0.081, data: 0.035) G_GAN: 0.668 G_L1: 0.000 D_real: 0.667 D_fake: 0.723 \n",
            "(epoch: 152, iters: 712, time: 0.103, data: 0.001) G_GAN: 10.815 G_L1: 3.528 D_real: 0.005 D_fake: 0.000 \n",
            "(epoch: 152, iters: 812, time: 0.077, data: 0.000) G_GAN: 12.641 G_L1: 0.998 D_real: 0.003 D_fake: 0.000 \n",
            "(epoch: 152, iters: 912, time: 0.070, data: 0.141) G_GAN: 0.718 G_L1: 0.000 D_real: 0.724 D_fake: 0.668 \n",
            "End of epoch 152 / 200 \t Time Taken: 121 sec\n",
            "learning rate 0.0000950 -> 0.0000931\n",
            "(epoch: 153, iters: 98, time: 0.100, data: 0.012) G_GAN: 6.549 G_L1: 4.539 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 153, iters: 198, time: 0.124, data: 0.000) G_GAN: 8.666 G_L1: 3.889 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 153, iters: 298, time: 0.085, data: 0.000) G_GAN: 6.688 G_L1: 4.518 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 153, iters: 398, time: 0.090, data: 0.000) G_GAN: 5.602 G_L1: 6.154 D_real: 0.001 D_fake: 0.011 \n",
            "(epoch: 153, iters: 498, time: 0.074, data: 0.000) G_GAN: 0.583 G_L1: 0.000 D_real: 0.611 D_fake: 0.788 \n",
            "(epoch: 153, iters: 598, time: 0.076, data: 0.002) G_GAN: 3.250 G_L1: 0.316 D_real: 0.031 D_fake: 0.528 \n",
            "(epoch: 153, iters: 698, time: 0.111, data: 0.000) G_GAN: 0.771 G_L1: 0.000 D_real: 0.797 D_fake: 0.611 \n",
            "(epoch: 153, iters: 798, time: 0.096, data: 0.000) G_GAN: 7.874 G_L1: 6.110 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 153, iters: 898, time: 0.095, data: 0.000) G_GAN: 3.623 G_L1: 0.875 D_real: 0.067 D_fake: 0.096 \n",
            "End of epoch 153 / 200 \t Time Taken: 120 sec\n",
            "learning rate 0.0000931 -> 0.0000911\n",
            "(epoch: 154, iters: 84, time: 0.098, data: 0.000) G_GAN: 6.469 G_L1: 6.884 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 154, iters: 184, time: 0.074, data: 0.116) G_GAN: 5.221 G_L1: 2.787 D_real: 0.000 D_fake: 0.008 \n",
            "(epoch: 154, iters: 284, time: 0.066, data: 0.003) G_GAN: 0.660 G_L1: 0.000 D_real: 0.661 D_fake: 0.733 \n",
            "(epoch: 154, iters: 384, time: 0.102, data: 0.002) G_GAN: 6.536 G_L1: 2.013 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 154, iters: 484, time: 0.116, data: 0.000) G_GAN: 7.250 G_L1: 2.815 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 154, iters: 584, time: 0.078, data: 0.000) G_GAN: 3.576 G_L1: 1.810 D_real: 0.006 D_fake: 0.055 \n",
            "(epoch: 154, iters: 684, time: 0.101, data: 0.000) G_GAN: 10.132 G_L1: 4.297 D_real: 0.040 D_fake: 0.000 \n",
            "(epoch: 154, iters: 784, time: 0.096, data: 0.004) G_GAN: 7.695 G_L1: 5.325 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 154, iters: 884, time: 0.103, data: 0.024) G_GAN: 10.626 G_L1: 3.558 D_real: 0.000 D_fake: 0.000 \n",
            "End of epoch 154 / 200 \t Time Taken: 119 sec\n",
            "learning rate 0.0000911 -> 0.0000891\n",
            "(epoch: 155, iters: 70, time: 0.090, data: 0.000) G_GAN: 0.686 G_L1: 0.000 D_real: 0.673 D_fake: 0.719 \n",
            "(epoch: 155, iters: 170, time: 0.090, data: 0.000) G_GAN: 0.684 G_L1: 0.000 D_real: 0.685 D_fake: 0.704 \n",
            "(epoch: 155, iters: 270, time: 0.077, data: 0.000) G_GAN: 7.749 G_L1: 4.317 D_real: 0.002 D_fake: 0.001 \n",
            "(epoch: 155, iters: 370, time: 0.105, data: 0.000) G_GAN: 5.946 G_L1: 11.742 D_real: 0.001 D_fake: 0.009 \n",
            "(epoch: 155, iters: 470, time: 0.100, data: 0.000) G_GAN: 4.590 G_L1: 2.814 D_real: 0.009 D_fake: 0.025 \n",
            "(epoch: 155, iters: 570, time: 0.088, data: 0.000) G_GAN: 2.654 G_L1: 0.172 D_real: 0.189 D_fake: 0.047 \n",
            "(epoch: 155, iters: 670, time: 0.092, data: 0.000) G_GAN: 7.007 G_L1: 3.854 D_real: 0.134 D_fake: 0.001 \n",
            "(epoch: 155, iters: 770, time: 0.056, data: 0.000) G_GAN: 0.638 G_L1: 0.000 D_real: 0.626 D_fake: 0.777 \n",
            "(epoch: 155, iters: 870, time: 0.081, data: 0.000) G_GAN: 4.918 G_L1: 1.771 D_real: 2.154 D_fake: 0.000 \n",
            "End of epoch 155 / 200 \t Time Taken: 120 sec\n",
            "learning rate 0.0000891 -> 0.0000871\n",
            "(epoch: 156, iters: 56, time: 0.079, data: 0.000) G_GAN: 7.764 G_L1: 1.370 D_real: 0.015 D_fake: 0.001 \n",
            "(epoch: 156, iters: 156, time: 0.090, data: 0.000) G_GAN: 8.018 G_L1: 3.360 D_real: 0.002 D_fake: 0.001 \n",
            "(epoch: 156, iters: 256, time: 0.100, data: 0.010) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.696 \n",
            "(epoch: 156, iters: 356, time: 0.092, data: 0.000) G_GAN: 8.213 G_L1: 7.142 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 156, iters: 456, time: 0.081, data: 0.001) G_GAN: 6.710 G_L1: 1.290 D_real: 0.003 D_fake: 0.002 \n",
            "(epoch: 156, iters: 556, time: 0.088, data: 0.000) G_GAN: 4.617 G_L1: 1.040 D_real: 0.190 D_fake: 0.006 \n",
            "(epoch: 156, iters: 656, time: 0.081, data: 0.000) G_GAN: 5.642 G_L1: 1.711 D_real: 0.121 D_fake: 0.004 \n",
            "(epoch: 156, iters: 756, time: 0.077, data: 0.000) G_GAN: 3.742 G_L1: 3.050 D_real: 0.001 D_fake: 0.067 \n",
            "(epoch: 156, iters: 856, time: 0.068, data: 0.000) G_GAN: 6.449 G_L1: 1.775 D_real: 0.008 D_fake: 0.002 \n",
            "End of epoch 156 / 200 \t Time Taken: 120 sec\n",
            "learning rate 0.0000871 -> 0.0000851\n",
            "(epoch: 157, iters: 42, time: 0.071, data: 0.001) G_GAN: 9.770 G_L1: 1.381 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 157, iters: 142, time: 0.106, data: 0.000) G_GAN: 3.505 G_L1: 0.800 D_real: 0.257 D_fake: 0.013 \n",
            "(epoch: 157, iters: 242, time: 0.097, data: 0.000) G_GAN: 10.820 G_L1: 4.867 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 157, iters: 342, time: 0.081, data: 0.000) G_GAN: 0.648 G_L1: 0.000 D_real: 0.692 D_fake: 0.699 \n",
            "(epoch: 157, iters: 442, time: 0.088, data: 0.000) G_GAN: 10.768 G_L1: 0.176 D_real: 0.032 D_fake: 0.000 \n",
            "(epoch: 157, iters: 542, time: 0.083, data: 0.000) G_GAN: 12.425 G_L1: 1.558 D_real: 0.194 D_fake: 0.000 \n",
            "(epoch: 157, iters: 642, time: 0.106, data: 0.092) G_GAN: 2.603 G_L1: 0.836 D_real: 0.056 D_fake: 0.381 \n",
            "saving the latest model (epoch 157, total_iters 135000)\n",
            "(epoch: 157, iters: 742, time: 0.091, data: 0.000) G_GAN: 3.246 G_L1: 1.315 D_real: 0.002 D_fake: 0.154 \n",
            "(epoch: 157, iters: 842, time: 0.082, data: 0.000) G_GAN: 4.057 G_L1: 14.895 D_real: 0.000 D_fake: 0.056 \n",
            "End of epoch 157 / 200 \t Time Taken: 122 sec\n",
            "learning rate 0.0000851 -> 0.0000832\n",
            "(epoch: 158, iters: 28, time: 0.100, data: 0.049) G_GAN: 8.565 G_L1: 4.837 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 158, iters: 128, time: 0.074, data: 0.041) G_GAN: 9.691 G_L1: 2.527 D_real: 0.003 D_fake: 0.000 \n",
            "(epoch: 158, iters: 228, time: 0.056, data: 0.000) G_GAN: 8.139 G_L1: 1.193 D_real: 1.854 D_fake: 0.000 \n",
            "(epoch: 158, iters: 328, time: 0.085, data: 0.000) G_GAN: 9.565 G_L1: 2.696 D_real: 0.036 D_fake: 0.000 \n",
            "(epoch: 158, iters: 428, time: 0.074, data: 0.000) G_GAN: 9.228 G_L1: 6.118 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 158, iters: 528, time: 0.105, data: 0.000) G_GAN: 14.389 G_L1: 1.577 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 158, iters: 628, time: 0.097, data: 0.000) G_GAN: 3.326 G_L1: 0.762 D_real: 0.053 D_fake: 0.063 \n",
            "(epoch: 158, iters: 728, time: 0.102, data: 0.000) G_GAN: 0.693 G_L1: 0.000 D_real: 0.692 D_fake: 0.696 \n",
            "(epoch: 158, iters: 828, time: 0.092, data: 0.000) G_GAN: 8.606 G_L1: 5.781 D_real: 0.007 D_fake: 0.000 \n",
            "End of epoch 158 / 200 \t Time Taken: 121 sec\n",
            "learning rate 0.0000832 -> 0.0000812\n",
            "(epoch: 159, iters: 14, time: 0.098, data: 0.000) G_GAN: 0.715 G_L1: 0.000 D_real: 0.705 D_fake: 0.691 \n",
            "(epoch: 159, iters: 114, time: 0.089, data: 0.000) G_GAN: 12.746 G_L1: 1.025 D_real: 0.139 D_fake: 0.000 \n",
            "(epoch: 159, iters: 214, time: 0.092, data: 0.000) G_GAN: 5.261 G_L1: 1.047 D_real: 0.044 D_fake: 0.007 \n",
            "(epoch: 159, iters: 314, time: 0.077, data: 0.159) G_GAN: 6.594 G_L1: 13.550 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 159, iters: 414, time: 0.091, data: 0.044) G_GAN: 0.689 G_L1: 0.000 D_real: 0.675 D_fake: 0.715 \n",
            "(epoch: 159, iters: 514, time: 0.085, data: 0.143) G_GAN: 0.707 G_L1: 0.000 D_real: 0.713 D_fake: 0.676 \n",
            "(epoch: 159, iters: 614, time: 0.108, data: 0.148) G_GAN: 8.629 G_L1: 3.794 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 159, iters: 714, time: 0.102, data: 0.132) G_GAN: 5.104 G_L1: 3.445 D_real: 0.000 D_fake: 0.012 \n",
            "(epoch: 159, iters: 814, time: 0.095, data: 0.000) G_GAN: 9.570 G_L1: 3.299 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 159, iters: 914, time: 0.057, data: 0.000) G_GAN: 4.505 G_L1: 6.435 D_real: 0.037 D_fake: 0.022 \n",
            "End of epoch 159 / 200 \t Time Taken: 119 sec\n",
            "learning rate 0.0000812 -> 0.0000792\n",
            "(epoch: 160, iters: 100, time: 0.072, data: 0.673) G_GAN: 0.760 G_L1: 0.000 D_real: 0.782 D_fake: 0.617 \n",
            "(epoch: 160, iters: 200, time: 0.101, data: 0.000) G_GAN: 0.661 G_L1: 0.000 D_real: 0.662 D_fake: 0.744 \n",
            "(epoch: 160, iters: 300, time: 0.083, data: 0.000) G_GAN: 4.488 G_L1: 0.951 D_real: 0.006 D_fake: 0.015 \n",
            "(epoch: 160, iters: 400, time: 0.070, data: 0.000) G_GAN: 0.708 G_L1: 0.000 D_real: 0.716 D_fake: 0.673 \n",
            "(epoch: 160, iters: 500, time: 0.109, data: 0.000) G_GAN: 2.666 G_L1: 0.767 D_real: 0.047 D_fake: 0.502 \n",
            "(epoch: 160, iters: 600, time: 0.119, data: 0.000) G_GAN: 0.692 G_L1: 0.000 D_real: 0.693 D_fake: 0.696 \n",
            "(epoch: 160, iters: 700, time: 0.072, data: 0.000) G_GAN: 0.724 G_L1: 0.000 D_real: 0.707 D_fake: 0.685 \n",
            "(epoch: 160, iters: 800, time: 0.075, data: 0.000) G_GAN: 12.717 G_L1: 3.670 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 160, iters: 900, time: 0.076, data: 0.000) G_GAN: 0.619 G_L1: 0.000 D_real: 0.600 D_fake: 0.801 \n",
            "End of epoch 160 / 200 \t Time Taken: 123 sec\n",
            "learning rate 0.0000792 -> 0.0000772\n",
            "(epoch: 161, iters: 86, time: 0.087, data: 0.000) G_GAN: 7.031 G_L1: 9.681 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 161, iters: 186, time: 0.105, data: 0.200) G_GAN: 10.857 G_L1: 1.628 D_real: 0.024 D_fake: 0.000 \n",
            "(epoch: 161, iters: 286, time: 0.093, data: 0.173) G_GAN: 8.542 G_L1: 6.582 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 161, iters: 386, time: 0.068, data: 0.125) G_GAN: 7.365 G_L1: 5.926 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 161, iters: 486, time: 0.100, data: 0.001) G_GAN: 6.858 G_L1: 9.385 D_real: 0.033 D_fake: 0.002 \n",
            "(epoch: 161, iters: 586, time: 0.102, data: 0.014) G_GAN: 0.665 G_L1: 0.000 D_real: 0.660 D_fake: 0.729 \n",
            "(epoch: 161, iters: 686, time: 0.090, data: 0.009) G_GAN: 0.720 G_L1: 0.000 D_real: 0.725 D_fake: 0.667 \n",
            "(epoch: 161, iters: 786, time: 0.092, data: 0.000) G_GAN: 0.737 G_L1: 0.000 D_real: 0.718 D_fake: 0.674 \n",
            "(epoch: 161, iters: 886, time: 0.087, data: 0.000) G_GAN: 0.699 G_L1: 0.000 D_real: 0.715 D_fake: 0.678 \n",
            "End of epoch 161 / 200 \t Time Taken: 122 sec\n",
            "learning rate 0.0000772 -> 0.0000752\n",
            "(epoch: 162, iters: 72, time: 0.072, data: 0.006) G_GAN: 2.141 G_L1: 0.842 D_real: 0.926 D_fake: 0.024 \n",
            "(epoch: 162, iters: 172, time: 0.098, data: 0.162) G_GAN: 3.459 G_L1: 0.751 D_real: 0.062 D_fake: 0.038 \n",
            "(epoch: 162, iters: 272, time: 0.071, data: 0.162) G_GAN: 7.276 G_L1: 5.745 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 162, iters: 372, time: 0.095, data: 0.097) G_GAN: 13.648 G_L1: 4.256 D_real: 0.030 D_fake: 0.000 \n",
            "(epoch: 162, iters: 472, time: 0.098, data: 0.148) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.691 \n",
            "(epoch: 162, iters: 572, time: 0.073, data: 0.013) G_GAN: 8.045 G_L1: 2.659 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 162, iters: 672, time: 0.093, data: 0.137) G_GAN: 0.726 G_L1: 0.000 D_real: 0.718 D_fake: 0.673 \n",
            "(epoch: 162, iters: 772, time: 0.103, data: 0.189) G_GAN: 4.426 G_L1: 2.488 D_real: 0.158 D_fake: 0.013 \n",
            "(epoch: 162, iters: 872, time: 0.090, data: 0.134) G_GAN: 12.986 G_L1: 4.429 D_real: 0.897 D_fake: 0.000 \n",
            "End of epoch 162 / 200 \t Time Taken: 119 sec\n",
            "learning rate 0.0000752 -> 0.0000733\n",
            "(epoch: 163, iters: 58, time: 0.072, data: 0.023) G_GAN: 10.065 G_L1: 8.363 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 163, iters: 158, time: 0.108, data: 0.203) G_GAN: 9.580 G_L1: 6.254 D_real: 0.000 D_fake: 0.000 \n",
            "saving the latest model (epoch 163, total_iters 140000)\n",
            "(epoch: 163, iters: 258, time: 0.074, data: 0.005) G_GAN: 9.424 G_L1: 2.673 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 163, iters: 358, time: 0.112, data: 0.005) G_GAN: 3.890 G_L1: 1.388 D_real: 0.012 D_fake: 0.047 \n",
            "(epoch: 163, iters: 458, time: 0.126, data: 0.199) G_GAN: 10.326 G_L1: 4.351 D_real: 0.006 D_fake: 0.000 \n",
            "(epoch: 163, iters: 558, time: 0.077, data: 0.131) G_GAN: 2.101 G_L1: 0.038 D_real: 1.078 D_fake: 0.007 \n",
            "(epoch: 163, iters: 658, time: 0.080, data: 0.272) G_GAN: 11.043 G_L1: 2.866 D_real: 0.003 D_fake: 0.000 \n",
            "(epoch: 163, iters: 758, time: 0.099, data: 0.166) G_GAN: 3.591 G_L1: 2.888 D_real: 0.000 D_fake: 0.074 \n",
            "(epoch: 163, iters: 858, time: 0.076, data: 0.130) G_GAN: 0.722 G_L1: 0.000 D_real: 0.731 D_fake: 0.659 \n",
            "End of epoch 163 / 200 \t Time Taken: 123 sec\n",
            "learning rate 0.0000733 -> 0.0000713\n",
            "(epoch: 164, iters: 44, time: 0.080, data: 0.111) G_GAN: 11.591 G_L1: 4.445 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 164, iters: 144, time: 0.080, data: 0.175) G_GAN: 12.517 G_L1: 3.745 D_real: 0.063 D_fake: 0.000 \n",
            "(epoch: 164, iters: 244, time: 0.104, data: 0.087) G_GAN: 12.586 G_L1: 1.242 D_real: 0.005 D_fake: 0.000 \n",
            "(epoch: 164, iters: 344, time: 0.098, data: 0.000) G_GAN: 2.251 G_L1: 0.715 D_real: 0.212 D_fake: 0.233 \n",
            "(epoch: 164, iters: 444, time: 0.100, data: 0.000) G_GAN: 12.701 G_L1: 1.091 D_real: 0.039 D_fake: 0.000 \n",
            "(epoch: 164, iters: 544, time: 0.099, data: 0.000) G_GAN: 0.674 G_L1: 0.000 D_real: 0.672 D_fake: 0.719 \n",
            "(epoch: 164, iters: 644, time: 0.096, data: 0.001) G_GAN: 0.631 G_L1: 0.000 D_real: 0.611 D_fake: 0.786 \n",
            "(epoch: 164, iters: 744, time: 0.099, data: 0.000) G_GAN: 3.848 G_L1: 2.100 D_real: 0.001 D_fake: 0.048 \n",
            "(epoch: 164, iters: 844, time: 0.076, data: 0.001) G_GAN: 0.682 G_L1: 0.000 D_real: 0.709 D_fake: 0.682 \n",
            "End of epoch 164 / 200 \t Time Taken: 118 sec\n",
            "learning rate 0.0000713 -> 0.0000693\n",
            "(epoch: 165, iters: 30, time: 0.101, data: 0.000) G_GAN: 13.093 G_L1: 3.656 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 165, iters: 130, time: 0.101, data: 0.001) G_GAN: 5.999 G_L1: 3.556 D_real: 0.002 D_fake: 0.006 \n",
            "(epoch: 165, iters: 230, time: 0.106, data: 0.000) G_GAN: 0.688 G_L1: 0.000 D_real: 0.683 D_fake: 0.706 \n",
            "(epoch: 165, iters: 330, time: 0.079, data: 0.000) G_GAN: 13.819 G_L1: 0.809 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 165, iters: 430, time: 0.090, data: 0.000) G_GAN: 7.584 G_L1: 1.014 D_real: 0.004 D_fake: 0.001 \n",
            "(epoch: 165, iters: 530, time: 0.094, data: 0.000) G_GAN: 3.479 G_L1: 0.745 D_real: 0.933 D_fake: 0.011 \n",
            "(epoch: 165, iters: 630, time: 0.107, data: 0.000) G_GAN: 7.334 G_L1: 3.513 D_real: 0.003 D_fake: 0.001 \n",
            "(epoch: 165, iters: 730, time: 0.070, data: 0.000) G_GAN: 6.652 G_L1: 2.927 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 165, iters: 830, time: 0.069, data: 0.000) G_GAN: 9.101 G_L1: 7.974 D_real: 0.004 D_fake: 0.000 \n",
            "End of epoch 165 / 200 \t Time Taken: 120 sec\n",
            "learning rate 0.0000693 -> 0.0000673\n",
            "(epoch: 166, iters: 16, time: 0.113, data: 0.000) G_GAN: 6.355 G_L1: 12.433 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 166, iters: 116, time: 0.108, data: 0.006) G_GAN: 10.539 G_L1: 1.405 D_real: 0.014 D_fake: 0.000 \n",
            "(epoch: 166, iters: 216, time: 0.075, data: 0.000) G_GAN: 0.633 G_L1: 0.000 D_real: 0.616 D_fake: 0.787 \n",
            "(epoch: 166, iters: 316, time: 0.078, data: 0.000) G_GAN: 6.799 G_L1: 9.591 D_real: 0.035 D_fake: 0.002 \n",
            "(epoch: 166, iters: 416, time: 0.102, data: 0.000) G_GAN: 3.355 G_L1: 0.464 D_real: 0.024 D_fake: 0.183 \n",
            "(epoch: 166, iters: 516, time: 0.075, data: 0.007) G_GAN: 9.004 G_L1: 2.963 D_real: 0.048 D_fake: 0.000 \n",
            "(epoch: 166, iters: 616, time: 0.094, data: 0.000) G_GAN: 3.458 G_L1: 0.087 D_real: 0.030 D_fake: 0.590 \n",
            "(epoch: 166, iters: 716, time: 0.082, data: 0.000) G_GAN: 9.733 G_L1: 0.143 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 166, iters: 816, time: 0.064, data: 0.000) G_GAN: 6.252 G_L1: 1.792 D_real: 0.000 D_fake: 0.004 \n",
            "End of epoch 166 / 200 \t Time Taken: 117 sec\n",
            "learning rate 0.0000673 -> 0.0000653\n",
            "(epoch: 167, iters: 2, time: 0.107, data: 0.005) G_GAN: 8.742 G_L1: 6.112 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 167, iters: 102, time: 0.099, data: 0.000) G_GAN: 4.069 G_L1: 1.666 D_real: 0.002 D_fake: 0.040 \n",
            "(epoch: 167, iters: 202, time: 0.085, data: 0.000) G_GAN: 2.419 G_L1: 0.101 D_real: 0.096 D_fake: 0.502 \n",
            "(epoch: 167, iters: 302, time: 0.090, data: 0.000) G_GAN: 8.765 G_L1: 0.872 D_real: 0.038 D_fake: 0.000 \n",
            "(epoch: 167, iters: 402, time: 0.064, data: 0.001) G_GAN: 7.567 G_L1: 5.613 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 167, iters: 502, time: 0.091, data: 0.000) G_GAN: 10.667 G_L1: 0.598 D_real: 0.034 D_fake: 0.000 \n",
            "(epoch: 167, iters: 602, time: 0.074, data: 0.000) G_GAN: 0.717 G_L1: 0.000 D_real: 0.724 D_fake: 0.666 \n",
            "(epoch: 167, iters: 702, time: 0.075, data: 0.000) G_GAN: 5.782 G_L1: 1.543 D_real: 0.010 D_fake: 0.004 \n",
            "(epoch: 167, iters: 802, time: 0.073, data: 0.000) G_GAN: 9.959 G_L1: 0.135 D_real: 0.012 D_fake: 0.000 \n",
            "(epoch: 167, iters: 902, time: 0.100, data: 0.001) G_GAN: 0.813 G_L1: 0.000 D_real: 0.858 D_fake: 0.566 \n",
            "End of epoch 167 / 200 \t Time Taken: 118 sec\n",
            "learning rate 0.0000653 -> 0.0000634\n",
            "(epoch: 168, iters: 88, time: 0.081, data: 0.000) G_GAN: 6.560 G_L1: 3.204 D_real: 0.001 D_fake: 0.004 \n",
            "(epoch: 168, iters: 188, time: 0.093, data: 0.200) G_GAN: 8.304 G_L1: 0.782 D_real: 0.008 D_fake: 0.000 \n",
            "(epoch: 168, iters: 288, time: 0.106, data: 0.002) G_GAN: 3.650 G_L1: 3.100 D_real: 0.000 D_fake: 0.039 \n",
            "(epoch: 168, iters: 388, time: 0.084, data: 0.000) G_GAN: 5.838 G_L1: 0.421 D_real: 0.020 D_fake: 0.004 \n",
            "(epoch: 168, iters: 488, time: 0.075, data: 0.000) G_GAN: 7.689 G_L1: 3.510 D_real: 0.008 D_fake: 0.001 \n",
            "(epoch: 168, iters: 588, time: 0.087, data: 0.000) G_GAN: 9.543 G_L1: 7.633 D_real: 0.026 D_fake: 0.000 \n",
            "saving the latest model (epoch 168, total_iters 145000)\n",
            "(epoch: 168, iters: 688, time: 0.121, data: 0.000) G_GAN: 0.597 G_L1: 0.000 D_real: 0.585 D_fake: 0.821 \n",
            "(epoch: 168, iters: 788, time: 0.108, data: 0.185) G_GAN: 0.724 G_L1: 0.000 D_real: 0.728 D_fake: 0.663 \n",
            "(epoch: 168, iters: 888, time: 0.080, data: 0.091) G_GAN: 10.666 G_L1: 5.497 D_real: 0.000 D_fake: 0.000 \n",
            "End of epoch 168 / 200 \t Time Taken: 121 sec\n",
            "learning rate 0.0000634 -> 0.0000614\n",
            "(epoch: 169, iters: 74, time: 0.087, data: 0.000) G_GAN: 9.444 G_L1: 2.753 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 169, iters: 174, time: 0.069, data: 0.001) G_GAN: 0.648 G_L1: 0.000 D_real: 0.637 D_fake: 0.756 \n",
            "(epoch: 169, iters: 274, time: 0.082, data: 0.000) G_GAN: 0.706 G_L1: 0.000 D_real: 0.709 D_fake: 0.679 \n",
            "(epoch: 169, iters: 374, time: 0.080, data: 0.000) G_GAN: 5.508 G_L1: 10.618 D_real: 0.015 D_fake: 0.010 \n",
            "(epoch: 169, iters: 474, time: 0.088, data: 0.000) G_GAN: 4.502 G_L1: 1.231 D_real: 0.002 D_fake: 0.015 \n",
            "(epoch: 169, iters: 574, time: 0.102, data: 0.000) G_GAN: 7.752 G_L1: 5.417 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 169, iters: 674, time: 0.100, data: 0.000) G_GAN: 0.666 G_L1: 0.000 D_real: 0.660 D_fake: 0.731 \n",
            "(epoch: 169, iters: 774, time: 0.109, data: 0.000) G_GAN: 4.607 G_L1: 1.463 D_real: 0.037 D_fake: 0.017 \n",
            "(epoch: 169, iters: 874, time: 0.072, data: 0.001) G_GAN: 7.870 G_L1: 1.307 D_real: 0.028 D_fake: 0.001 \n",
            "End of epoch 169 / 200 \t Time Taken: 118 sec\n",
            "learning rate 0.0000614 -> 0.0000594\n",
            "(epoch: 170, iters: 60, time: 0.082, data: 0.000) G_GAN: 12.242 G_L1: 2.212 D_real: 0.008 D_fake: 0.000 \n",
            "(epoch: 170, iters: 160, time: 0.098, data: 0.206) G_GAN: 4.334 G_L1: 1.293 D_real: 0.028 D_fake: 0.024 \n",
            "(epoch: 170, iters: 260, time: 0.103, data: 0.059) G_GAN: 10.760 G_L1: 1.290 D_real: 0.011 D_fake: 0.000 \n",
            "(epoch: 170, iters: 360, time: 0.103, data: 0.217) G_GAN: 11.946 G_L1: 2.216 D_real: 0.005 D_fake: 0.000 \n",
            "(epoch: 170, iters: 460, time: 0.090, data: 0.097) G_GAN: 0.708 G_L1: 0.000 D_real: 0.714 D_fake: 0.675 \n",
            "(epoch: 170, iters: 560, time: 0.103, data: 0.035) G_GAN: 7.834 G_L1: 8.935 D_real: 0.002 D_fake: 0.001 \n",
            "(epoch: 170, iters: 660, time: 0.106, data: 0.001) G_GAN: 3.048 G_L1: 3.168 D_real: 0.000 D_fake: 0.279 \n",
            "(epoch: 170, iters: 760, time: 0.094, data: 0.000) G_GAN: 0.672 G_L1: 0.001 D_real: 0.672 D_fake: 0.721 \n",
            "(epoch: 170, iters: 860, time: 0.082, data: 0.000) G_GAN: 3.334 G_L1: 0.064 D_real: 0.029 D_fake: 0.057 \n",
            "End of epoch 170 / 200 \t Time Taken: 117 sec\n",
            "learning rate 0.0000594 -> 0.0000574\n",
            "(epoch: 171, iters: 46, time: 0.102, data: 0.000) G_GAN: 10.276 G_L1: 2.414 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 171, iters: 146, time: 0.079, data: 0.000) G_GAN: 0.593 G_L1: 0.000 D_real: 0.571 D_fake: 0.840 \n",
            "(epoch: 171, iters: 246, time: 0.078, data: 0.000) G_GAN: 10.140 G_L1: 3.144 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 171, iters: 346, time: 0.073, data: 0.001) G_GAN: 9.314 G_L1: 3.693 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 171, iters: 446, time: 0.079, data: 0.000) G_GAN: 4.082 G_L1: 0.385 D_real: 0.234 D_fake: 0.009 \n",
            "(epoch: 171, iters: 546, time: 0.077, data: 0.000) G_GAN: 2.444 G_L1: 1.268 D_real: 0.134 D_fake: 0.111 \n",
            "(epoch: 171, iters: 646, time: 0.075, data: 0.000) G_GAN: 13.366 G_L1: 0.636 D_real: 0.010 D_fake: 0.000 \n",
            "(epoch: 171, iters: 746, time: 0.083, data: 0.000) G_GAN: 13.653 G_L1: 3.015 D_real: 0.007 D_fake: 0.000 \n",
            "(epoch: 171, iters: 846, time: 0.056, data: 0.000) G_GAN: 5.022 G_L1: 0.254 D_real: 0.094 D_fake: 0.010 \n",
            "End of epoch 171 / 200 \t Time Taken: 116 sec\n",
            "learning rate 0.0000574 -> 0.0000554\n",
            "(epoch: 172, iters: 32, time: 0.065, data: 0.001) G_GAN: 2.261 G_L1: 0.227 D_real: 0.094 D_fake: 0.373 \n",
            "(epoch: 172, iters: 132, time: 0.086, data: 0.080) G_GAN: 0.689 G_L1: 0.000 D_real: 0.688 D_fake: 0.701 \n",
            "(epoch: 172, iters: 232, time: 0.073, data: 0.005) G_GAN: 10.610 G_L1: 0.770 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 172, iters: 332, time: 0.083, data: 0.000) G_GAN: 9.538 G_L1: 8.399 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 172, iters: 432, time: 0.069, data: 0.004) G_GAN: 2.137 G_L1: 0.764 D_real: 0.170 D_fake: 0.608 \n",
            "(epoch: 172, iters: 532, time: 0.098, data: 0.000) G_GAN: 6.202 G_L1: 4.320 D_real: 0.000 D_fake: 0.007 \n",
            "(epoch: 172, iters: 632, time: 0.069, data: 0.000) G_GAN: 8.423 G_L1: 2.073 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 172, iters: 732, time: 0.086, data: 0.000) G_GAN: 3.440 G_L1: 1.852 D_real: 0.003 D_fake: 0.084 \n",
            "(epoch: 172, iters: 832, time: 0.098, data: 0.000) G_GAN: 0.676 G_L1: 0.000 D_real: 0.678 D_fake: 0.721 \n",
            "End of epoch 172 / 200 \t Time Taken: 111 sec\n",
            "learning rate 0.0000554 -> 0.0000535\n",
            "(epoch: 173, iters: 18, time: 0.081, data: 0.000) G_GAN: 8.929 G_L1: 5.850 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 173, iters: 118, time: 0.088, data: 0.000) G_GAN: 9.384 G_L1: 3.073 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 173, iters: 218, time: 0.076, data: 0.000) G_GAN: 0.689 G_L1: 0.000 D_real: 0.686 D_fake: 0.702 \n",
            "(epoch: 173, iters: 318, time: 0.086, data: 0.000) G_GAN: 5.826 G_L1: 1.635 D_real: 0.003 D_fake: 0.005 \n",
            "(epoch: 173, iters: 418, time: 0.106, data: 0.000) G_GAN: 7.629 G_L1: 5.209 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 173, iters: 518, time: 0.072, data: 0.000) G_GAN: 7.869 G_L1: 1.712 D_real: 0.007 D_fake: 0.001 \n",
            "(epoch: 173, iters: 618, time: 0.093, data: 0.000) G_GAN: 0.732 G_L1: 0.000 D_real: 0.743 D_fake: 0.650 \n",
            "(epoch: 173, iters: 718, time: 0.059, data: 0.000) G_GAN: 6.911 G_L1: 3.187 D_real: 0.013 D_fake: 0.002 \n",
            "(epoch: 173, iters: 818, time: 0.071, data: 0.000) G_GAN: 8.163 G_L1: 10.120 D_real: 0.004 D_fake: 0.001 \n",
            "End of epoch 173 / 200 \t Time Taken: 106 sec\n",
            "learning rate 0.0000535 -> 0.0000515\n",
            "(epoch: 174, iters: 4, time: 0.104, data: 0.000) G_GAN: 8.257 G_L1: 3.908 D_real: 0.023 D_fake: 0.000 \n",
            "(epoch: 174, iters: 104, time: 0.061, data: 0.045) G_GAN: 11.854 G_L1: 0.574 D_real: 0.127 D_fake: 0.000 \n",
            "saving the latest model (epoch 174, total_iters 150000)\n",
            "(epoch: 174, iters: 204, time: 0.093, data: 0.002) G_GAN: 10.901 G_L1: 1.916 D_real: 0.029 D_fake: 0.000 \n",
            "(epoch: 174, iters: 304, time: 0.069, data: 0.000) G_GAN: 9.424 G_L1: 5.259 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 174, iters: 404, time: 0.095, data: 0.004) G_GAN: 8.917 G_L1: 4.729 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 174, iters: 504, time: 0.084, data: 0.000) G_GAN: 9.706 G_L1: 2.818 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 174, iters: 604, time: 0.072, data: 0.000) G_GAN: 2.735 G_L1: 1.176 D_real: 0.012 D_fake: 0.239 \n",
            "(epoch: 174, iters: 704, time: 0.078, data: 0.002) G_GAN: 12.179 G_L1: 1.611 D_real: 0.010 D_fake: 0.000 \n",
            "(epoch: 174, iters: 804, time: 0.098, data: 0.001) G_GAN: 9.433 G_L1: 7.316 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 174, iters: 904, time: 0.100, data: 0.000) G_GAN: 0.684 G_L1: 0.000 D_real: 0.684 D_fake: 0.707 \n",
            "End of epoch 174 / 200 \t Time Taken: 108 sec\n",
            "learning rate 0.0000515 -> 0.0000495\n",
            "(epoch: 175, iters: 90, time: 0.088, data: 0.000) G_GAN: 10.091 G_L1: 5.372 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 175, iters: 190, time: 0.098, data: 0.000) G_GAN: 6.488 G_L1: 5.391 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 175, iters: 290, time: 0.086, data: 0.005) G_GAN: 5.376 G_L1: 3.078 D_real: 0.003 D_fake: 0.009 \n",
            "(epoch: 175, iters: 390, time: 0.094, data: 0.000) G_GAN: 3.877 G_L1: 2.553 D_real: 0.001 D_fake: 0.073 \n",
            "(epoch: 175, iters: 490, time: 0.068, data: 0.004) G_GAN: 0.743 G_L1: 0.000 D_real: 0.751 D_fake: 0.644 \n",
            "(epoch: 175, iters: 590, time: 0.071, data: 0.012) G_GAN: 12.606 G_L1: 7.214 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 175, iters: 690, time: 0.086, data: 0.000) G_GAN: 3.259 G_L1: 0.913 D_real: 0.056 D_fake: 0.052 \n",
            "(epoch: 175, iters: 790, time: 0.081, data: 0.108) G_GAN: 6.421 G_L1: 3.125 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 175, iters: 890, time: 0.080, data: 0.145) G_GAN: 12.395 G_L1: 6.600 D_real: 0.000 D_fake: 0.000 \n",
            "End of epoch 175 / 200 \t Time Taken: 104 sec\n",
            "learning rate 0.0000495 -> 0.0000475\n",
            "(epoch: 176, iters: 76, time: 0.095, data: 0.168) G_GAN: 6.612 G_L1: 2.797 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 176, iters: 176, time: 0.089, data: 0.108) G_GAN: 0.695 G_L1: 0.000 D_real: 0.686 D_fake: 0.708 \n",
            "(epoch: 176, iters: 276, time: 0.087, data: 0.071) G_GAN: 2.417 G_L1: 1.563 D_real: 0.026 D_fake: 0.445 \n",
            "(epoch: 176, iters: 376, time: 0.078, data: 0.000) G_GAN: 7.262 G_L1: 1.723 D_real: 0.013 D_fake: 0.001 \n",
            "(epoch: 176, iters: 476, time: 0.066, data: 0.193) G_GAN: 7.306 G_L1: 1.922 D_real: 0.003 D_fake: 0.001 \n",
            "(epoch: 176, iters: 576, time: 0.071, data: 0.124) G_GAN: 6.877 G_L1: 0.713 D_real: 0.026 D_fake: 0.001 \n",
            "(epoch: 176, iters: 676, time: 0.071, data: 0.084) G_GAN: 8.181 G_L1: 2.619 D_real: 0.004 D_fake: 0.001 \n",
            "(epoch: 176, iters: 776, time: 0.070, data: 0.134) G_GAN: 9.495 G_L1: 4.452 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 176, iters: 876, time: 0.091, data: 0.143) G_GAN: 0.703 G_L1: 0.000 D_real: 0.709 D_fake: 0.682 \n",
            "End of epoch 176 / 200 \t Time Taken: 104 sec\n",
            "learning rate 0.0000475 -> 0.0000455\n",
            "(epoch: 177, iters: 62, time: 0.076, data: 0.000) G_GAN: 4.689 G_L1: 1.442 D_real: 0.136 D_fake: 0.009 \n",
            "(epoch: 177, iters: 162, time: 0.103, data: 0.152) G_GAN: 4.539 G_L1: 2.068 D_real: 0.495 D_fake: 0.004 \n",
            "(epoch: 177, iters: 262, time: 0.083, data: 0.000) G_GAN: 8.857 G_L1: 0.957 D_real: 0.008 D_fake: 0.000 \n",
            "(epoch: 177, iters: 362, time: 0.070, data: 0.000) G_GAN: 6.950 G_L1: 6.822 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 177, iters: 462, time: 0.082, data: 0.000) G_GAN: 0.687 G_L1: 0.000 D_real: 0.684 D_fake: 0.704 \n",
            "(epoch: 177, iters: 562, time: 0.076, data: 0.000) G_GAN: 12.314 G_L1: 1.936 D_real: 0.036 D_fake: 0.000 \n",
            "(epoch: 177, iters: 662, time: 0.073, data: 0.000) G_GAN: 7.606 G_L1: 0.615 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 177, iters: 762, time: 0.088, data: 0.000) G_GAN: 3.125 G_L1: 1.752 D_real: 0.009 D_fake: 0.122 \n",
            "(epoch: 177, iters: 862, time: 0.058, data: 0.000) G_GAN: 0.789 G_L1: 0.000 D_real: 0.784 D_fake: 0.614 \n",
            "End of epoch 177 / 200 \t Time Taken: 106 sec\n",
            "learning rate 0.0000455 -> 0.0000436\n",
            "(epoch: 178, iters: 48, time: 0.086, data: 0.000) G_GAN: 0.652 G_L1: 0.000 D_real: 0.648 D_fake: 0.743 \n",
            "(epoch: 178, iters: 148, time: 0.107, data: 0.159) G_GAN: 13.404 G_L1: 1.910 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 178, iters: 248, time: 0.106, data: 0.043) G_GAN: 4.511 G_L1: 1.068 D_real: 0.007 D_fake: 0.015 \n",
            "(epoch: 178, iters: 348, time: 0.071, data: 0.111) G_GAN: 0.704 G_L1: 0.000 D_real: 0.705 D_fake: 0.683 \n",
            "(epoch: 178, iters: 448, time: 0.083, data: 0.137) G_GAN: 8.947 G_L1: 0.892 D_real: 0.032 D_fake: 0.000 \n",
            "(epoch: 178, iters: 548, time: 0.085, data: 0.222) G_GAN: 0.663 G_L1: 0.000 D_real: 0.656 D_fake: 0.733 \n",
            "(epoch: 178, iters: 648, time: 0.111, data: 0.178) G_GAN: 10.311 G_L1: 9.135 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 178, iters: 748, time: 0.093, data: 0.003) G_GAN: 3.591 G_L1: 1.668 D_real: 0.078 D_fake: 0.045 \n",
            "(epoch: 178, iters: 848, time: 0.093, data: 0.015) G_GAN: 2.501 G_L1: 0.738 D_real: 0.035 D_fake: 0.524 \n",
            "End of epoch 178 / 200 \t Time Taken: 105 sec\n",
            "learning rate 0.0000436 -> 0.0000416\n",
            "(epoch: 179, iters: 34, time: 0.089, data: 0.197) G_GAN: 9.733 G_L1: 3.214 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 179, iters: 134, time: 0.065, data: 0.000) G_GAN: 8.320 G_L1: 6.717 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 179, iters: 234, time: 0.069, data: 0.000) G_GAN: 5.335 G_L1: 4.456 D_real: 0.000 D_fake: 0.011 \n",
            "(epoch: 179, iters: 334, time: 0.084, data: 0.000) G_GAN: 2.021 G_L1: 0.234 D_real: 0.133 D_fake: 0.592 \n",
            "(epoch: 179, iters: 434, time: 0.068, data: 0.000) G_GAN: 9.253 G_L1: 3.474 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 179, iters: 534, time: 0.061, data: 0.000) G_GAN: 0.735 G_L1: 0.000 D_real: 0.731 D_fake: 0.661 \n",
            "saving the latest model (epoch 179, total_iters 155000)\n",
            "(epoch: 179, iters: 634, time: 0.082, data: 0.000) G_GAN: 0.765 G_L1: 0.000 D_real: 0.762 D_fake: 0.631 \n",
            "(epoch: 179, iters: 734, time: 0.068, data: 0.000) G_GAN: 7.563 G_L1: 1.906 D_real: 0.013 D_fake: 0.001 \n",
            "(epoch: 179, iters: 834, time: 0.052, data: 0.000) G_GAN: 0.682 G_L1: 0.000 D_real: 0.681 D_fake: 0.708 \n",
            "End of epoch 179 / 200 \t Time Taken: 106 sec\n",
            "learning rate 0.0000416 -> 0.0000396\n",
            "(epoch: 180, iters: 20, time: 0.099, data: 0.000) G_GAN: 0.701 G_L1: 0.000 D_real: 0.691 D_fake: 0.698 \n",
            "(epoch: 180, iters: 120, time: 0.072, data: 0.002) G_GAN: 3.876 G_L1: 0.837 D_real: 0.004 D_fake: 0.021 \n",
            "(epoch: 180, iters: 220, time: 0.061, data: 0.000) G_GAN: 13.825 G_L1: 4.587 D_real: 0.019 D_fake: 0.000 \n",
            "(epoch: 180, iters: 320, time: 0.095, data: 0.000) G_GAN: 0.708 G_L1: 0.000 D_real: 0.712 D_fake: 0.677 \n",
            "(epoch: 180, iters: 420, time: 0.104, data: 0.000) G_GAN: 9.053 G_L1: 1.143 D_real: 0.003 D_fake: 0.000 \n",
            "(epoch: 180, iters: 520, time: 0.072, data: 0.000) G_GAN: 10.453 G_L1: 9.401 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 180, iters: 620, time: 0.097, data: 0.000) G_GAN: 5.965 G_L1: 1.062 D_real: 0.001 D_fake: 0.004 \n",
            "(epoch: 180, iters: 720, time: 0.083, data: 0.000) G_GAN: 3.211 G_L1: 1.202 D_real: 0.002 D_fake: 0.093 \n",
            "(epoch: 180, iters: 820, time: 0.095, data: 0.006) G_GAN: 5.070 G_L1: 7.510 D_real: 0.000 D_fake: 0.018 \n",
            "End of epoch 180 / 200 \t Time Taken: 105 sec\n",
            "learning rate 0.0000396 -> 0.0000376\n",
            "(epoch: 181, iters: 6, time: 0.068, data: 0.000) G_GAN: 6.269 G_L1: 1.338 D_real: 0.049 D_fake: 0.003 \n",
            "(epoch: 181, iters: 106, time: 0.063, data: 0.000) G_GAN: 8.470 G_L1: 0.764 D_real: 0.039 D_fake: 0.000 \n",
            "(epoch: 181, iters: 206, time: 0.083, data: 0.047) G_GAN: 9.768 G_L1: 1.893 D_real: 0.028 D_fake: 0.000 \n",
            "(epoch: 181, iters: 306, time: 0.057, data: 0.000) G_GAN: 9.509 G_L1: 1.094 D_real: 0.008 D_fake: 0.000 \n",
            "(epoch: 181, iters: 406, time: 0.088, data: 0.000) G_GAN: 2.835 G_L1: 0.303 D_real: 0.009 D_fake: 0.275 \n",
            "(epoch: 181, iters: 506, time: 0.077, data: 0.002) G_GAN: 9.451 G_L1: 3.650 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 181, iters: 606, time: 0.079, data: 0.006) G_GAN: 4.492 G_L1: 3.474 D_real: 0.077 D_fake: 0.019 \n",
            "(epoch: 181, iters: 706, time: 0.083, data: 0.000) G_GAN: 0.701 G_L1: 0.000 D_real: 0.699 D_fake: 0.689 \n",
            "(epoch: 181, iters: 806, time: 0.078, data: 0.000) G_GAN: 11.707 G_L1: 5.643 D_real: 0.007 D_fake: 0.000 \n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 49, in <module>\n",
            "    model.set_input(data)         # unpack data from dataset and apply preprocessing\n",
            "  File \"/gdrive/My Drive/Colab Notebooks/pytorch-CycleGAN-and-pix2pix/models/pix2pix_model.py\", line 85, in set_input\n",
            "    self.real_A = input['A'].to(self.device)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UkcaFZiyASl"
      },
      "source": [
        "# Testing\n",
        "\n",
        "-   `python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_pix2pix`\n",
        "\n",
        "Change the `--dataroot`, `--name`, and `--direction` to be consistent with your trained model's configuration and how you want to transform images.\n",
        "\n",
        "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mey7o6j-0368",
        "outputId": "6c9c7e61-1e34-44d2-9887-02045b69192e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls checkpoints/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "maps_pix2pix  pix2pix\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCsKkEq0yGh0",
        "outputId": "639c4ddf-4cb4-4b20-8682-f3faaf71b0ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python test.py --dataroot ./mydataset --model pix2pix --name maps_pix2pix --preprocess resize_crop_noise"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./mydataset                   \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                    epoch: latest                        \n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \n",
            "               n_layers_D: 3                             \n",
            "                     name: maps_pix2pix                  \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: unet_256                      \n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                    noise: 0                             \n",
            "                     norm: batch                         \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 1                             \n",
            "                    phase: test                          \n",
            "               preprocess: resize_crop_noise             \t[default: resize_crop]\n",
            "              results_dir: ./results/                    \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "dataset\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "model\n",
            "loading the model from ./checkpoints/maps_pix2pix/latest_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 54.410 M\n",
            "-----------------------------------------------\n",
            "model setup\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqUZDYB1Bzul",
        "outputId": "80ef0780-9958-441c-856d-3522eaa39663",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python test.py --dataroot ./mydataset --model pix2pix --name maps_pix2pix --phase val"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./mydataset                   \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                    epoch: latest                        \n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \n",
            "               n_layers_D: 3                             \n",
            "                     name: maps_pix2pix                  \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: unet_256                      \n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                    noise: 0                             \n",
            "                     norm: batch                         \n",
            "                 num_test: 1000                          \n",
            "              num_threads: 4                             \n",
            "                output_nc: 1                             \n",
            "                    phase: val                           \t[default: test]\n",
            "               preprocess: resize_crop                   \n",
            "              results_dir: ./results/                    \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "latest\n",
            "loading the model from ./checkpoints/maps_pix2pix/latest_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 54.410 M\n",
            "-----------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MMLPix2Pix",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wNjDKdQy35h"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHZ8tEJuCEVC",
        "outputId": "d0208c3b-279c-419a-e422-244f93a5db21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/My\\ Drive/Colab Notebooks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRm-USlsHgEV",
        "outputId": "8c5271a0-a031-4103-a77e-e00abbead977",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/loerssoni/pytorch-CycleGAN-and-pix2pix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'pytorch-CycleGAN-and-pix2pix' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt3igws3eiVp"
      },
      "source": [
        "import os\n",
        "os.chdir('pytorch-CycleGAN-and-pix2pix/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1EySlOXwwoa",
        "outputId": "f22d3f2a-4476-49b0-baca-cb0f76c99337",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.7.0+cu101)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.8.1+cu101)\n",
            "Collecting dominate>=2.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/a8/4354f8122c39e35516a2708746d89db5e339c867abbd8e0179bccee4b7f9/dominate-2.6.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (7.0.0)\n",
            "Installing collected packages: dominate\n",
            "Successfully installed dominate-2.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeN2NsowL4Nq",
        "outputId": "e6e37f64-c957-48f4-afbd-0b38e80d079c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/gdrive/My Drive/Colab Notebooks/pytorch-CycleGAN-and-pix2pix'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFw1kDQBx3LN"
      },
      "source": [
        "# Training\n",
        "\n",
        "-   `python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA`\n",
        "\n",
        "Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. Add `--direction BtoA` if you want to train a model to transfrom from class B to A."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWLT3r3EE1cZ",
        "outputId": "f3dedaf1-520a-4aa7-ad7d-0ee3397a732f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python datasets/datagen.py --directory ./mydataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "split = train, create 900 images\n",
            "split = train, number of images = 900\n",
            "split = test, create 100 images\n",
            "split = test, number of images = 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sp7TCT2x9dB",
        "outputId": "8fcce0e7-fc53-4d88-90c7-e844bf1ab513",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python train.py --dataroot ./mydataset --name maps_pix2pix --model pix2pix  --epoch_count 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./mydataset                   \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 10                            \t[default: 1]\n",
            "                 gan_mode: vanilla                       \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                lambda_L1: 100.0                         \n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                 log_name: loss_log.txt                  \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \n",
            "                 n_epochs: 100                           \n",
            "           n_epochs_decay: 100                           \n",
            "               n_layers_D: 3                             \n",
            "                     name: maps_pix2pix                  \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: unet_256                      \n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "              num_threads: 4                             \n",
            "                output_nc: 1                             \n",
            "                    phase: train                         \n",
            "                pool_size: 0                             \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "The number of training images = 914\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 54.410 M\n",
            "[Network D] Total number of parameters : 2.767 M\n",
            "-----------------------------------------------\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 10, iters: 100, time: 0.068, data: 0.163) G_GAN: 0.741 G_L1: 2.636 D_real: 0.751 D_fake: 0.614 \n",
            "(epoch: 10, iters: 200, time: 0.065, data: 0.002) G_GAN: 0.955 G_L1: 5.431 D_real: 0.502 D_fake: 0.732 \n",
            "(epoch: 10, iters: 300, time: 0.068, data: 0.000) G_GAN: 0.687 G_L1: 7.091 D_real: 0.963 D_fake: 0.492 \n",
            "(epoch: 10, iters: 400, time: 0.060, data: 0.063) G_GAN: 0.840 G_L1: 0.292 D_real: 0.911 D_fake: 0.515 \n",
            "(epoch: 10, iters: 500, time: 0.065, data: 0.003) G_GAN: 0.682 G_L1: 0.183 D_real: 0.627 D_fake: 0.769 \n",
            "(epoch: 10, iters: 600, time: 0.069, data: 0.000) G_GAN: 0.660 G_L1: 2.232 D_real: 0.997 D_fake: 0.531 \n",
            "(epoch: 10, iters: 700, time: 0.068, data: 0.000) G_GAN: 0.725 G_L1: 0.736 D_real: 0.573 D_fake: 0.801 \n",
            "(epoch: 10, iters: 800, time: 0.059, data: 0.000) G_GAN: 0.664 G_L1: 0.767 D_real: 0.616 D_fake: 0.791 \n",
            "(epoch: 10, iters: 900, time: 0.063, data: 0.000) G_GAN: 0.709 G_L1: 3.005 D_real: 0.611 D_fake: 0.725 \n",
            "saving the model at the end of epoch 10, iters 914\n",
            "End of epoch 10 / 200 \t Time Taken: 84 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 11, iters: 86, time: 0.063, data: 0.001) G_GAN: 0.641 G_L1: 2.027 D_real: 0.817 D_fake: 0.599 \n",
            "(epoch: 11, iters: 186, time: 0.060, data: 0.002) G_GAN: 0.854 G_L1: 2.437 D_real: 0.793 D_fake: 0.616 \n",
            "(epoch: 11, iters: 286, time: 0.066, data: 0.001) G_GAN: 0.853 G_L1: 3.971 D_real: 0.443 D_fake: 1.015 \n",
            "(epoch: 11, iters: 386, time: 0.067, data: 0.002) G_GAN: 0.747 G_L1: 0.917 D_real: 0.793 D_fake: 0.610 \n",
            "(epoch: 11, iters: 486, time: 0.067, data: 0.002) G_GAN: 0.886 G_L1: 4.548 D_real: 0.962 D_fake: 0.475 \n",
            "(epoch: 11, iters: 586, time: 0.068, data: 0.002) G_GAN: 0.716 G_L1: 0.499 D_real: 0.681 D_fake: 0.709 \n",
            "(epoch: 11, iters: 686, time: 0.068, data: 0.002) G_GAN: 0.707 G_L1: 3.202 D_real: 0.766 D_fake: 0.614 \n",
            "(epoch: 11, iters: 786, time: 0.062, data: 0.002) G_GAN: 0.738 G_L1: 1.488 D_real: 0.646 D_fake: 0.626 \n",
            "(epoch: 11, iters: 886, time: 0.068, data: 0.002) G_GAN: 0.683 G_L1: 0.023 D_real: 0.688 D_fake: 0.699 \n",
            "End of epoch 11 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 12, iters: 72, time: 0.067, data: 0.183) G_GAN: 0.865 G_L1: 1.576 D_real: 0.676 D_fake: 0.792 \n",
            "(epoch: 12, iters: 172, time: 0.068, data: 0.002) G_GAN: 0.704 G_L1: 0.603 D_real: 0.547 D_fake: 0.866 \n",
            "(epoch: 12, iters: 272, time: 0.068, data: 0.001) G_GAN: 0.722 G_L1: 2.900 D_real: 0.845 D_fake: 0.563 \n",
            "(epoch: 12, iters: 372, time: 0.067, data: 0.002) G_GAN: 0.682 G_L1: 0.693 D_real: 0.492 D_fake: 0.772 \n",
            "(epoch: 12, iters: 472, time: 0.068, data: 0.002) G_GAN: 0.623 G_L1: 0.020 D_real: 0.609 D_fake: 0.786 \n",
            "(epoch: 12, iters: 572, time: 0.068, data: 0.002) G_GAN: 0.683 G_L1: 1.393 D_real: 0.819 D_fake: 0.603 \n",
            "(epoch: 12, iters: 672, time: 0.068, data: 0.002) G_GAN: 0.758 G_L1: 1.704 D_real: 0.570 D_fake: 0.778 \n",
            "(epoch: 12, iters: 772, time: 0.067, data: 0.002) G_GAN: 0.695 G_L1: 0.017 D_real: 0.710 D_fake: 0.678 \n",
            "(epoch: 12, iters: 872, time: 0.068, data: 0.002) G_GAN: 0.676 G_L1: 2.585 D_real: 0.713 D_fake: 0.634 \n",
            "End of epoch 12 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 13, iters: 58, time: 0.069, data: 0.002) G_GAN: 0.759 G_L1: 1.597 D_real: 0.790 D_fake: 0.605 \n",
            "(epoch: 13, iters: 158, time: 0.068, data: 0.002) G_GAN: 0.795 G_L1: 1.426 D_real: 0.751 D_fake: 0.611 \n",
            "(epoch: 13, iters: 258, time: 0.068, data: 0.002) G_GAN: 0.704 G_L1: 1.726 D_real: 0.746 D_fake: 0.646 \n",
            "(epoch: 13, iters: 358, time: 0.068, data: 0.002) G_GAN: 0.748 G_L1: 3.801 D_real: 0.695 D_fake: 0.681 \n",
            "(epoch: 13, iters: 458, time: 0.067, data: 0.002) G_GAN: 0.717 G_L1: 0.879 D_real: 0.754 D_fake: 0.634 \n",
            "(epoch: 13, iters: 558, time: 0.068, data: 0.002) G_GAN: 0.652 G_L1: 0.013 D_real: 0.582 D_fake: 0.828 \n",
            "(epoch: 13, iters: 658, time: 0.068, data: 0.002) G_GAN: 0.733 G_L1: 1.193 D_real: 0.762 D_fake: 0.622 \n",
            "(epoch: 13, iters: 758, time: 0.068, data: 0.002) G_GAN: 0.657 G_L1: 0.009 D_real: 0.602 D_fake: 0.795 \n",
            "(epoch: 13, iters: 858, time: 0.067, data: 0.002) G_GAN: 1.063 G_L1: 1.547 D_real: 0.427 D_fake: 0.522 \n",
            "End of epoch 13 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 14, iters: 44, time: 0.068, data: 0.002) G_GAN: 0.791 G_L1: 0.009 D_real: 0.760 D_fake: 0.639 \n",
            "(epoch: 14, iters: 144, time: 0.068, data: 0.002) G_GAN: 0.700 G_L1: 0.010 D_real: 0.702 D_fake: 0.685 \n",
            "(epoch: 14, iters: 244, time: 0.068, data: 0.002) G_GAN: 0.730 G_L1: 0.007 D_real: 0.735 D_fake: 0.655 \n",
            "(epoch: 14, iters: 344, time: 0.068, data: 0.002) G_GAN: 0.786 G_L1: 0.007 D_real: 0.852 D_fake: 0.557 \n",
            "(epoch: 14, iters: 444, time: 0.068, data: 0.002) G_GAN: 0.673 G_L1: 0.008 D_real: 0.653 D_fake: 0.736 \n",
            "(epoch: 14, iters: 544, time: 0.068, data: 0.002) G_GAN: 0.796 G_L1: 1.069 D_real: 0.460 D_fake: 0.830 \n",
            "(epoch: 14, iters: 644, time: 0.069, data: 0.002) G_GAN: 0.876 G_L1: 1.367 D_real: 0.446 D_fake: 0.708 \n",
            "(epoch: 14, iters: 744, time: 0.069, data: 0.002) G_GAN: 0.528 G_L1: 1.455 D_real: 0.698 D_fake: 0.707 \n",
            "(epoch: 14, iters: 844, time: 0.068, data: 0.002) G_GAN: 0.663 G_L1: 1.689 D_real: 0.709 D_fake: 0.595 \n",
            "End of epoch 14 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 15, iters: 30, time: 0.068, data: 0.001) G_GAN: 0.736 G_L1: 2.717 D_real: 0.644 D_fake: 0.609 \n",
            "(epoch: 15, iters: 130, time: 0.068, data: 0.002) G_GAN: 0.863 G_L1: 1.783 D_real: 0.426 D_fake: 0.978 \n",
            "(epoch: 15, iters: 230, time: 0.066, data: 0.002) G_GAN: 0.732 G_L1: 0.404 D_real: 0.698 D_fake: 0.671 \n",
            "(epoch: 15, iters: 330, time: 0.068, data: 0.002) G_GAN: 0.784 G_L1: 1.088 D_real: 0.472 D_fake: 0.906 \n",
            "(epoch: 15, iters: 430, time: 0.067, data: 0.002) G_GAN: 0.656 G_L1: 0.579 D_real: 0.692 D_fake: 0.679 \n",
            "saving the latest model (epoch 15, total_iters 5000)\n",
            "(epoch: 15, iters: 530, time: 0.064, data: 0.002) G_GAN: 0.691 G_L1: 0.580 D_real: 0.714 D_fake: 0.633 \n",
            "(epoch: 15, iters: 630, time: 0.065, data: 0.002) G_GAN: 0.748 G_L1: 0.777 D_real: 0.653 D_fake: 0.661 \n",
            "(epoch: 15, iters: 730, time: 0.069, data: 0.002) G_GAN: 0.741 G_L1: 0.004 D_real: 0.782 D_fake: 0.612 \n",
            "(epoch: 15, iters: 830, time: 0.067, data: 0.002) G_GAN: 0.911 G_L1: 4.141 D_real: 0.530 D_fake: 0.857 \n",
            "saving the model at the end of epoch 15, iters 5484\n",
            "End of epoch 15 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 16, iters: 16, time: 0.068, data: 0.002) G_GAN: 0.712 G_L1: 0.003 D_real: 0.732 D_fake: 0.658 \n",
            "(epoch: 16, iters: 116, time: 0.067, data: 0.002) G_GAN: 0.845 G_L1: 1.171 D_real: 0.825 D_fake: 0.487 \n",
            "(epoch: 16, iters: 216, time: 0.061, data: 0.002) G_GAN: 0.596 G_L1: 0.704 D_real: 0.589 D_fake: 0.807 \n",
            "(epoch: 16, iters: 316, time: 0.067, data: 0.002) G_GAN: 0.597 G_L1: 1.869 D_real: 0.915 D_fake: 1.259 \n",
            "(epoch: 16, iters: 416, time: 0.065, data: 0.002) G_GAN: 0.700 G_L1: 1.366 D_real: 0.732 D_fake: 0.654 \n",
            "(epoch: 16, iters: 516, time: 0.068, data: 0.002) G_GAN: 0.716 G_L1: 1.179 D_real: 0.762 D_fake: 0.615 \n",
            "(epoch: 16, iters: 616, time: 0.067, data: 0.001) G_GAN: 0.837 G_L1: 0.832 D_real: 0.962 D_fake: 0.481 \n",
            "(epoch: 16, iters: 716, time: 0.068, data: 0.002) G_GAN: 0.790 G_L1: 2.164 D_real: 0.579 D_fake: 0.742 \n",
            "(epoch: 16, iters: 816, time: 0.067, data: 0.002) G_GAN: 0.710 G_L1: 0.062 D_real: 0.703 D_fake: 0.683 \n",
            "End of epoch 16 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 17, iters: 2, time: 0.057, data: 0.001) G_GAN: 0.751 G_L1: 2.864 D_real: 0.597 D_fake: 0.801 \n",
            "(epoch: 17, iters: 102, time: 0.069, data: 0.000) G_GAN: 1.079 G_L1: 1.352 D_real: 1.336 D_fake: 0.256 \n",
            "(epoch: 17, iters: 202, time: 0.063, data: 0.002) G_GAN: 1.187 G_L1: 4.858 D_real: 0.355 D_fake: 0.822 \n",
            "(epoch: 17, iters: 302, time: 0.068, data: 0.002) G_GAN: 0.676 G_L1: 0.129 D_real: 0.656 D_fake: 0.738 \n",
            "(epoch: 17, iters: 402, time: 0.062, data: 0.002) G_GAN: 0.748 G_L1: 0.002 D_real: 0.716 D_fake: 0.674 \n",
            "(epoch: 17, iters: 502, time: 0.067, data: 0.002) G_GAN: 0.615 G_L1: 0.707 D_real: 0.636 D_fake: 0.766 \n",
            "(epoch: 17, iters: 602, time: 0.068, data: 0.002) G_GAN: 0.698 G_L1: 0.001 D_real: 0.653 D_fake: 0.736 \n",
            "(epoch: 17, iters: 702, time: 0.068, data: 0.002) G_GAN: 0.880 G_L1: 0.900 D_real: 0.386 D_fake: 0.702 \n",
            "(epoch: 17, iters: 802, time: 0.066, data: 0.002) G_GAN: 0.750 G_L1: 1.880 D_real: 0.853 D_fake: 0.529 \n",
            "(epoch: 17, iters: 902, time: 0.068, data: 0.002) G_GAN: 0.655 G_L1: 0.583 D_real: 0.606 D_fake: 0.749 \n",
            "End of epoch 17 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 18, iters: 88, time: 0.068, data: 0.002) G_GAN: 0.780 G_L1: 1.275 D_real: 0.538 D_fake: 0.881 \n",
            "(epoch: 18, iters: 188, time: 0.068, data: 0.002) G_GAN: 0.625 G_L1: 0.672 D_real: 0.661 D_fake: 0.731 \n",
            "(epoch: 18, iters: 288, time: 0.067, data: 0.002) G_GAN: 0.657 G_L1: 1.487 D_real: 0.574 D_fake: 0.670 \n",
            "(epoch: 18, iters: 388, time: 0.068, data: 0.002) G_GAN: 0.845 G_L1: 0.395 D_real: 0.725 D_fake: 0.691 \n",
            "(epoch: 18, iters: 488, time: 0.068, data: 0.002) G_GAN: 0.653 G_L1: 0.001 D_real: 0.627 D_fake: 0.764 \n",
            "(epoch: 18, iters: 588, time: 0.069, data: 0.002) G_GAN: 0.624 G_L1: 0.397 D_real: 0.616 D_fake: 0.779 \n",
            "(epoch: 18, iters: 688, time: 0.068, data: 0.002) G_GAN: 1.165 G_L1: 1.606 D_real: 0.236 D_fake: 0.735 \n",
            "(epoch: 18, iters: 788, time: 0.068, data: 0.002) G_GAN: 0.613 G_L1: 1.168 D_real: 0.794 D_fake: 0.618 \n",
            "(epoch: 18, iters: 888, time: 0.068, data: 0.002) G_GAN: 0.671 G_L1: 0.001 D_real: 0.686 D_fake: 0.702 \n",
            "End of epoch 18 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 19, iters: 74, time: 0.068, data: 0.002) G_GAN: 0.784 G_L1: 0.818 D_real: 1.142 D_fake: 0.466 \n",
            "(epoch: 19, iters: 174, time: 0.068, data: 0.002) G_GAN: 0.688 G_L1: 0.001 D_real: 0.689 D_fake: 0.698 \n",
            "(epoch: 19, iters: 274, time: 0.068, data: 0.002) G_GAN: 0.831 G_L1: 0.828 D_real: 0.683 D_fake: 0.535 \n",
            "(epoch: 19, iters: 374, time: 0.069, data: 0.002) G_GAN: 0.690 G_L1: 1.383 D_real: 0.523 D_fake: 0.865 \n",
            "(epoch: 19, iters: 474, time: 0.067, data: 0.002) G_GAN: 0.686 G_L1: 1.087 D_real: 0.702 D_fake: 0.687 \n",
            "(epoch: 19, iters: 574, time: 0.067, data: 0.001) G_GAN: 0.761 G_L1: 0.501 D_real: 0.835 D_fake: 0.572 \n",
            "(epoch: 19, iters: 674, time: 0.063, data: 0.002) G_GAN: 0.680 G_L1: 0.017 D_real: 0.663 D_fake: 0.724 \n",
            "(epoch: 19, iters: 774, time: 0.069, data: 0.002) G_GAN: 0.724 G_L1: 0.148 D_real: 0.723 D_fake: 0.668 \n",
            "(epoch: 19, iters: 874, time: 0.066, data: 0.002) G_GAN: 0.739 G_L1: 2.188 D_real: 0.901 D_fake: 0.492 \n",
            "End of epoch 19 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 20, iters: 60, time: 0.065, data: 0.002) G_GAN: 0.690 G_L1: 1.068 D_real: 0.911 D_fake: 0.515 \n",
            "(epoch: 20, iters: 160, time: 0.067, data: 0.002) G_GAN: 1.209 G_L1: 0.343 D_real: 0.309 D_fake: 0.740 \n",
            "(epoch: 20, iters: 260, time: 0.067, data: 0.002) G_GAN: 0.730 G_L1: 0.615 D_real: 0.787 D_fake: 0.607 \n",
            "(epoch: 20, iters: 360, time: 0.069, data: 0.002) G_GAN: 0.804 G_L1: 1.711 D_real: 0.686 D_fake: 0.666 \n",
            "(epoch: 20, iters: 460, time: 0.069, data: 0.001) G_GAN: 0.737 G_L1: 1.226 D_real: 0.651 D_fake: 0.673 \n",
            "(epoch: 20, iters: 560, time: 0.068, data: 0.002) G_GAN: 0.793 G_L1: 1.220 D_real: 0.727 D_fake: 0.701 \n",
            "(epoch: 20, iters: 660, time: 0.068, data: 0.002) G_GAN: 0.757 G_L1: 1.888 D_real: 0.827 D_fake: 0.563 \n",
            "(epoch: 20, iters: 760, time: 0.068, data: 0.002) G_GAN: 0.714 G_L1: 1.073 D_real: 0.714 D_fake: 0.654 \n",
            "(epoch: 20, iters: 860, time: 0.067, data: 0.002) G_GAN: 0.701 G_L1: 0.021 D_real: 0.708 D_fake: 0.679 \n",
            "saving the latest model (epoch 20, total_iters 10000)\n",
            "saving the model at the end of epoch 20, iters 10054\n",
            "End of epoch 20 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 21, iters: 46, time: 0.068, data: 0.002) G_GAN: 0.802 G_L1: 1.797 D_real: 0.612 D_fake: 0.664 \n",
            "(epoch: 21, iters: 146, time: 0.066, data: 0.002) G_GAN: 0.677 G_L1: 0.791 D_real: 0.564 D_fake: 0.794 \n",
            "(epoch: 21, iters: 246, time: 0.068, data: 0.002) G_GAN: 0.695 G_L1: 0.518 D_real: 0.585 D_fake: 0.652 \n",
            "(epoch: 21, iters: 346, time: 0.068, data: 0.002) G_GAN: 0.893 G_L1: 3.066 D_real: 0.329 D_fake: 1.009 \n",
            "(epoch: 21, iters: 446, time: 0.069, data: 0.002) G_GAN: 0.706 G_L1: 0.541 D_real: 0.693 D_fake: 0.699 \n",
            "(epoch: 21, iters: 546, time: 0.068, data: 0.002) G_GAN: 0.670 G_L1: 0.603 D_real: 0.566 D_fake: 0.822 \n",
            "(epoch: 21, iters: 646, time: 0.067, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.704 D_fake: 0.682 \n",
            "(epoch: 21, iters: 746, time: 0.068, data: 0.002) G_GAN: 0.686 G_L1: 0.242 D_real: 0.670 D_fake: 0.708 \n",
            "(epoch: 21, iters: 846, time: 0.068, data: 0.002) G_GAN: 1.340 G_L1: 2.774 D_real: 0.979 D_fake: 1.140 \n",
            "End of epoch 21 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 22, iters: 32, time: 0.068, data: 0.002) G_GAN: 0.653 G_L1: 0.000 D_real: 0.637 D_fake: 0.754 \n",
            "(epoch: 22, iters: 132, time: 0.069, data: 0.002) G_GAN: 0.677 G_L1: 0.000 D_real: 0.637 D_fake: 0.754 \n",
            "(epoch: 22, iters: 232, time: 0.068, data: 0.002) G_GAN: 0.720 G_L1: 0.433 D_real: 0.613 D_fake: 0.751 \n",
            "(epoch: 22, iters: 332, time: 0.068, data: 0.002) G_GAN: 0.663 G_L1: 0.000 D_real: 0.673 D_fake: 0.715 \n",
            "(epoch: 22, iters: 432, time: 0.063, data: 0.002) G_GAN: 0.738 G_L1: 0.143 D_real: 0.737 D_fake: 0.653 \n",
            "(epoch: 22, iters: 532, time: 0.068, data: 0.002) G_GAN: 0.683 G_L1: 0.000 D_real: 0.667 D_fake: 0.720 \n",
            "(epoch: 22, iters: 632, time: 0.068, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
            "(epoch: 22, iters: 732, time: 0.068, data: 0.002) G_GAN: 0.671 G_L1: 0.000 D_real: 0.669 D_fake: 0.718 \n",
            "(epoch: 22, iters: 832, time: 0.068, data: 0.002) G_GAN: 0.841 G_L1: 0.000 D_real: 0.844 D_fake: 0.569 \n",
            "End of epoch 22 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 23, iters: 18, time: 0.067, data: 0.002) G_GAN: 0.682 G_L1: 0.000 D_real: 0.683 D_fake: 0.705 \n",
            "(epoch: 23, iters: 118, time: 0.065, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.702 D_fake: 0.684 \n",
            "(epoch: 23, iters: 218, time: 0.068, data: 0.002) G_GAN: 0.663 G_L1: 0.358 D_real: 0.670 D_fake: 0.706 \n",
            "(epoch: 23, iters: 318, time: 0.067, data: 0.002) G_GAN: 0.683 G_L1: 0.063 D_real: 0.694 D_fake: 0.692 \n",
            "(epoch: 23, iters: 418, time: 0.069, data: 0.002) G_GAN: 0.663 G_L1: 0.000 D_real: 0.661 D_fake: 0.729 \n",
            "(epoch: 23, iters: 518, time: 0.069, data: 0.001) G_GAN: 0.763 G_L1: 0.654 D_real: 0.754 D_fake: 0.644 \n",
            "(epoch: 23, iters: 618, time: 0.068, data: 0.002) G_GAN: 0.602 G_L1: 0.503 D_real: 0.460 D_fake: 0.993 \n",
            "(epoch: 23, iters: 718, time: 0.069, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
            "(epoch: 23, iters: 818, time: 0.066, data: 0.002) G_GAN: 0.679 G_L1: 0.329 D_real: 0.652 D_fake: 0.740 \n",
            "End of epoch 23 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 24, iters: 4, time: 0.067, data: 0.002) G_GAN: 0.674 G_L1: 0.000 D_real: 0.668 D_fake: 0.719 \n",
            "(epoch: 24, iters: 104, time: 0.067, data: 0.004) G_GAN: 1.114 G_L1: 2.480 D_real: 0.341 D_fake: 0.564 \n",
            "(epoch: 24, iters: 204, time: 0.069, data: 0.002) G_GAN: 0.709 G_L1: 0.395 D_real: 0.715 D_fake: 0.668 \n",
            "(epoch: 24, iters: 304, time: 0.067, data: 0.002) G_GAN: 0.675 G_L1: 0.264 D_real: 0.545 D_fake: 0.933 \n",
            "(epoch: 24, iters: 404, time: 0.068, data: 0.002) G_GAN: 0.681 G_L1: 0.000 D_real: 0.676 D_fake: 0.712 \n",
            "(epoch: 24, iters: 504, time: 0.069, data: 0.002) G_GAN: 0.771 G_L1: 0.304 D_real: 0.761 D_fake: 0.636 \n",
            "(epoch: 24, iters: 604, time: 0.068, data: 0.002) G_GAN: 0.728 G_L1: 0.001 D_real: 0.755 D_fake: 0.635 \n",
            "(epoch: 24, iters: 704, time: 0.068, data: 0.002) G_GAN: 0.713 G_L1: 0.593 D_real: 0.622 D_fake: 0.706 \n",
            "(epoch: 24, iters: 804, time: 0.068, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.723 D_fake: 0.666 \n",
            "(epoch: 24, iters: 904, time: 0.068, data: 0.002) G_GAN: 0.673 G_L1: 0.334 D_real: 0.642 D_fake: 0.750 \n",
            "End of epoch 24 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 25, iters: 90, time: 0.068, data: 0.002) G_GAN: 0.754 G_L1: 0.161 D_real: 0.821 D_fake: 0.578 \n",
            "(epoch: 25, iters: 190, time: 0.068, data: 0.002) G_GAN: 0.700 G_L1: 0.649 D_real: 0.699 D_fake: 0.687 \n",
            "(epoch: 25, iters: 290, time: 0.068, data: 0.002) G_GAN: 0.702 G_L1: 0.760 D_real: 0.684 D_fake: 0.694 \n",
            "(epoch: 25, iters: 390, time: 0.067, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.766 D_fake: 0.625 \n",
            "(epoch: 25, iters: 490, time: 0.068, data: 0.002) G_GAN: 0.729 G_L1: 1.080 D_real: 0.737 D_fake: 0.635 \n",
            "(epoch: 25, iters: 590, time: 0.069, data: 0.002) G_GAN: 0.767 G_L1: 0.552 D_real: 0.818 D_fake: 0.568 \n",
            "(epoch: 25, iters: 690, time: 0.064, data: 0.002) G_GAN: 0.768 G_L1: 0.372 D_real: 0.771 D_fake: 0.626 \n",
            "(epoch: 25, iters: 790, time: 0.069, data: 0.002) G_GAN: 0.715 G_L1: 0.284 D_real: 0.705 D_fake: 0.681 \n",
            "(epoch: 25, iters: 890, time: 0.067, data: 0.002) G_GAN: 0.679 G_L1: 0.098 D_real: 0.666 D_fake: 0.723 \n",
            "saving the model at the end of epoch 25, iters 14624\n",
            "End of epoch 25 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 26, iters: 76, time: 0.068, data: 0.002) G_GAN: 0.733 G_L1: 0.042 D_real: 0.727 D_fake: 0.663 \n",
            "(epoch: 26, iters: 176, time: 0.057, data: 0.002) G_GAN: 0.669 G_L1: 1.469 D_real: 0.657 D_fake: 0.749 \n",
            "(epoch: 26, iters: 276, time: 0.068, data: 0.002) G_GAN: 0.622 G_L1: 0.139 D_real: 0.686 D_fake: 0.708 \n",
            "(epoch: 26, iters: 376, time: 0.069, data: 0.001) G_GAN: 0.703 G_L1: 0.537 D_real: 0.748 D_fake: 0.642 \n",
            "saving the latest model (epoch 26, total_iters 15000)\n",
            "(epoch: 26, iters: 476, time: 0.068, data: 0.002) G_GAN: 0.839 G_L1: 1.252 D_real: 0.597 D_fake: 0.596 \n",
            "(epoch: 26, iters: 576, time: 0.067, data: 0.003) G_GAN: 0.672 G_L1: 0.002 D_real: 0.678 D_fake: 0.711 \n",
            "(epoch: 26, iters: 676, time: 0.068, data: 0.002) G_GAN: 0.750 G_L1: 0.613 D_real: 0.540 D_fake: 0.799 \n",
            "(epoch: 26, iters: 776, time: 0.063, data: 0.002) G_GAN: 0.705 G_L1: 0.216 D_real: 0.701 D_fake: 0.689 \n",
            "(epoch: 26, iters: 876, time: 0.068, data: 0.002) G_GAN: 0.678 G_L1: 0.045 D_real: 0.658 D_fake: 0.733 \n",
            "End of epoch 26 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 27, iters: 62, time: 0.068, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.735 D_fake: 0.653 \n",
            "(epoch: 27, iters: 162, time: 0.068, data: 0.002) G_GAN: 0.774 G_L1: 0.000 D_real: 0.822 D_fake: 0.581 \n",
            "(epoch: 27, iters: 262, time: 0.068, data: 0.002) G_GAN: 0.779 G_L1: 1.905 D_real: 0.705 D_fake: 0.515 \n",
            "(epoch: 27, iters: 362, time: 0.068, data: 0.002) G_GAN: 1.127 G_L1: 2.418 D_real: 0.884 D_fake: 1.364 \n",
            "(epoch: 27, iters: 462, time: 0.068, data: 0.002) G_GAN: 0.698 G_L1: 0.336 D_real: 0.697 D_fake: 0.692 \n",
            "(epoch: 27, iters: 562, time: 0.067, data: 0.002) G_GAN: 0.769 G_L1: 0.283 D_real: 0.317 D_fake: 0.808 \n",
            "(epoch: 27, iters: 662, time: 0.068, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
            "(epoch: 27, iters: 762, time: 0.068, data: 0.002) G_GAN: 0.764 G_L1: 0.352 D_real: 0.771 D_fake: 0.620 \n",
            "(epoch: 27, iters: 862, time: 0.068, data: 0.002) G_GAN: 0.714 G_L1: 1.184 D_real: 0.642 D_fake: 0.669 \n",
            "End of epoch 27 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 28, iters: 48, time: 0.068, data: 0.002) G_GAN: 0.690 G_L1: 0.586 D_real: 0.691 D_fake: 0.700 \n",
            "(epoch: 28, iters: 148, time: 0.068, data: 0.002) G_GAN: 0.665 G_L1: 0.000 D_real: 0.652 D_fake: 0.736 \n",
            "(epoch: 28, iters: 248, time: 0.069, data: 0.002) G_GAN: 0.697 G_L1: 0.001 D_real: 0.684 D_fake: 0.703 \n",
            "(epoch: 28, iters: 348, time: 0.067, data: 0.002) G_GAN: 0.701 G_L1: 0.336 D_real: 0.636 D_fake: 0.714 \n",
            "(epoch: 28, iters: 448, time: 0.066, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.711 D_fake: 0.676 \n",
            "(epoch: 28, iters: 548, time: 0.067, data: 0.002) G_GAN: 0.945 G_L1: 1.147 D_real: 0.448 D_fake: 0.753 \n",
            "(epoch: 28, iters: 648, time: 0.067, data: 0.002) G_GAN: 0.673 G_L1: 0.213 D_real: 0.611 D_fake: 0.736 \n",
            "(epoch: 28, iters: 748, time: 0.068, data: 0.002) G_GAN: 0.958 G_L1: 0.425 D_real: 1.038 D_fake: 0.443 \n",
            "(epoch: 28, iters: 848, time: 0.069, data: 0.002) G_GAN: 0.710 G_L1: 1.154 D_real: 0.872 D_fake: 0.530 \n",
            "End of epoch 28 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 29, iters: 34, time: 0.068, data: 0.002) G_GAN: 0.833 G_L1: 0.000 D_real: 0.859 D_fake: 0.552 \n",
            "(epoch: 29, iters: 134, time: 0.066, data: 0.001) G_GAN: 0.690 G_L1: 0.014 D_real: 0.708 D_fake: 0.680 \n",
            "(epoch: 29, iters: 234, time: 0.067, data: 0.002) G_GAN: 0.695 G_L1: 0.763 D_real: 0.891 D_fake: 0.513 \n",
            "(epoch: 29, iters: 334, time: 0.067, data: 0.002) G_GAN: 0.663 G_L1: 1.233 D_real: 0.606 D_fake: 0.772 \n",
            "(epoch: 29, iters: 434, time: 0.068, data: 0.002) G_GAN: 0.635 G_L1: 0.000 D_real: 0.652 D_fake: 0.739 \n",
            "(epoch: 29, iters: 534, time: 0.068, data: 0.002) G_GAN: 0.854 G_L1: 0.755 D_real: 0.675 D_fake: 0.511 \n",
            "(epoch: 29, iters: 634, time: 0.068, data: 0.003) G_GAN: 0.768 G_L1: 1.509 D_real: 0.857 D_fake: 0.528 \n",
            "(epoch: 29, iters: 734, time: 0.068, data: 0.002) G_GAN: 0.749 G_L1: 0.496 D_real: 1.050 D_fake: 0.481 \n",
            "(epoch: 29, iters: 834, time: 0.067, data: 0.002) G_GAN: 1.018 G_L1: 0.666 D_real: 0.393 D_fake: 0.997 \n",
            "End of epoch 29 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 30, iters: 20, time: 0.068, data: 0.002) G_GAN: 0.993 G_L1: 0.956 D_real: 0.386 D_fake: 0.760 \n",
            "(epoch: 30, iters: 120, time: 0.069, data: 0.002) G_GAN: 0.616 G_L1: 0.172 D_real: 0.609 D_fake: 0.784 \n",
            "(epoch: 30, iters: 220, time: 0.068, data: 0.002) G_GAN: 0.717 G_L1: 0.543 D_real: 0.737 D_fake: 0.645 \n",
            "(epoch: 30, iters: 320, time: 0.063, data: 0.002) G_GAN: 0.739 G_L1: 0.222 D_real: 0.749 D_fake: 0.632 \n",
            "(epoch: 30, iters: 420, time: 0.068, data: 0.002) G_GAN: 0.660 G_L1: 0.000 D_real: 0.648 D_fake: 0.741 \n",
            "(epoch: 30, iters: 520, time: 0.068, data: 0.002) G_GAN: 0.764 G_L1: 0.501 D_real: 0.732 D_fake: 0.627 \n",
            "(epoch: 30, iters: 620, time: 0.069, data: 0.002) G_GAN: 0.604 G_L1: 0.631 D_real: 0.527 D_fake: 0.914 \n",
            "(epoch: 30, iters: 720, time: 0.068, data: 0.002) G_GAN: 0.672 G_L1: 0.151 D_real: 0.606 D_fake: 0.752 \n",
            "(epoch: 30, iters: 820, time: 0.069, data: 0.002) G_GAN: 0.662 G_L1: 0.365 D_real: 0.659 D_fake: 0.728 \n",
            "saving the model at the end of epoch 30, iters 19194\n",
            "End of epoch 30 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 31, iters: 6, time: 0.071, data: 0.001) G_GAN: 0.695 G_L1: 0.893 D_real: 0.724 D_fake: 0.675 \n",
            "(epoch: 31, iters: 106, time: 0.067, data: 0.001) G_GAN: 0.703 G_L1: 0.080 D_real: 0.699 D_fake: 0.694 \n",
            "(epoch: 31, iters: 206, time: 0.067, data: 0.003) G_GAN: 0.727 G_L1: 1.285 D_real: 0.760 D_fake: 0.624 \n",
            "(epoch: 31, iters: 306, time: 0.064, data: 0.002) G_GAN: 0.857 G_L1: 0.577 D_real: 0.677 D_fake: 0.737 \n",
            "(epoch: 31, iters: 406, time: 0.068, data: 0.002) G_GAN: 0.709 G_L1: 0.226 D_real: 0.714 D_fake: 0.676 \n",
            "(epoch: 31, iters: 506, time: 0.068, data: 0.002) G_GAN: 0.847 G_L1: 0.728 D_real: 0.851 D_fake: 0.476 \n",
            "(epoch: 31, iters: 606, time: 0.068, data: 0.001) G_GAN: 0.683 G_L1: 0.139 D_real: 0.680 D_fake: 0.707 \n",
            "(epoch: 31, iters: 706, time: 0.068, data: 0.001) G_GAN: 0.665 G_L1: 0.057 D_real: 0.663 D_fake: 0.724 \n",
            "(epoch: 31, iters: 806, time: 0.068, data: 0.001) G_GAN: 0.819 G_L1: 1.290 D_real: 0.996 D_fake: 0.341 \n",
            "saving the latest model (epoch 31, total_iters 20000)\n",
            "(epoch: 31, iters: 906, time: 0.066, data: 0.001) G_GAN: 0.699 G_L1: 0.000 D_real: 0.691 D_fake: 0.696 \n",
            "End of epoch 31 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 32, iters: 92, time: 0.060, data: 0.002) G_GAN: 0.702 G_L1: 0.353 D_real: 0.652 D_fake: 0.671 \n",
            "(epoch: 32, iters: 192, time: 0.068, data: 0.002) G_GAN: 0.778 G_L1: 0.335 D_real: 0.834 D_fake: 0.575 \n",
            "(epoch: 32, iters: 292, time: 0.064, data: 0.002) G_GAN: 0.695 G_L1: 0.242 D_real: 0.679 D_fake: 0.709 \n",
            "(epoch: 32, iters: 392, time: 0.068, data: 0.002) G_GAN: 0.701 G_L1: 0.916 D_real: 0.693 D_fake: 0.688 \n",
            "(epoch: 32, iters: 492, time: 0.069, data: 0.002) G_GAN: 0.759 G_L1: 0.464 D_real: 0.712 D_fake: 0.680 \n",
            "(epoch: 32, iters: 592, time: 0.068, data: 0.002) G_GAN: 0.760 G_L1: 0.083 D_real: 0.799 D_fake: 0.596 \n",
            "(epoch: 32, iters: 692, time: 0.069, data: 0.002) G_GAN: 0.761 G_L1: 0.430 D_real: 0.548 D_fake: 0.793 \n",
            "(epoch: 32, iters: 792, time: 0.068, data: 0.002) G_GAN: 0.807 G_L1: 0.801 D_real: 0.520 D_fake: 0.585 \n",
            "(epoch: 32, iters: 892, time: 0.068, data: 0.002) G_GAN: 0.579 G_L1: 0.724 D_real: 1.129 D_fake: 0.335 \n",
            "End of epoch 32 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 33, iters: 78, time: 0.068, data: 0.002) G_GAN: 0.727 G_L1: 0.441 D_real: 0.554 D_fake: 0.759 \n",
            "(epoch: 33, iters: 178, time: 0.068, data: 0.002) G_GAN: 0.750 G_L1: 0.319 D_real: 0.704 D_fake: 0.607 \n",
            "(epoch: 33, iters: 278, time: 0.068, data: 0.002) G_GAN: 0.753 G_L1: 0.293 D_real: 0.691 D_fake: 0.678 \n",
            "(epoch: 33, iters: 378, time: 0.068, data: 0.002) G_GAN: 0.668 G_L1: 0.085 D_real: 0.648 D_fake: 0.742 \n",
            "(epoch: 33, iters: 478, time: 0.063, data: 0.002) G_GAN: 0.697 G_L1: 0.667 D_real: 0.563 D_fake: 0.754 \n",
            "(epoch: 33, iters: 578, time: 0.068, data: 0.002) G_GAN: 0.784 G_L1: 0.513 D_real: 0.981 D_fake: 0.387 \n",
            "(epoch: 33, iters: 678, time: 0.068, data: 0.002) G_GAN: 0.718 G_L1: 0.056 D_real: 0.719 D_fake: 0.669 \n",
            "(epoch: 33, iters: 778, time: 0.069, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.712 D_fake: 0.677 \n",
            "(epoch: 33, iters: 878, time: 0.068, data: 0.002) G_GAN: 1.062 G_L1: 1.147 D_real: 0.312 D_fake: 1.037 \n",
            "End of epoch 33 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 34, iters: 64, time: 0.068, data: 0.002) G_GAN: 0.779 G_L1: 0.503 D_real: 0.840 D_fake: 0.562 \n",
            "(epoch: 34, iters: 164, time: 0.068, data: 0.002) G_GAN: 0.784 G_L1: 0.000 D_real: 0.830 D_fake: 0.575 \n",
            "(epoch: 34, iters: 264, time: 0.067, data: 0.002) G_GAN: 0.661 G_L1: 0.000 D_real: 0.678 D_fake: 0.709 \n",
            "(epoch: 34, iters: 364, time: 0.069, data: 0.002) G_GAN: 0.680 G_L1: 0.000 D_real: 0.681 D_fake: 0.706 \n",
            "(epoch: 34, iters: 464, time: 0.068, data: 0.002) G_GAN: 0.828 G_L1: 0.564 D_real: 0.909 D_fake: 0.524 \n",
            "(epoch: 34, iters: 564, time: 0.066, data: 0.002) G_GAN: 0.682 G_L1: 0.000 D_real: 0.650 D_fake: 0.739 \n",
            "(epoch: 34, iters: 664, time: 0.065, data: 0.002) G_GAN: 0.705 G_L1: 0.273 D_real: 0.668 D_fake: 0.724 \n",
            "(epoch: 34, iters: 764, time: 0.068, data: 0.002) G_GAN: 0.778 G_L1: 1.127 D_real: 0.597 D_fake: 0.644 \n",
            "(epoch: 34, iters: 864, time: 0.063, data: 0.002) G_GAN: 0.672 G_L1: 0.000 D_real: 0.655 D_fake: 0.736 \n",
            "End of epoch 34 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 35, iters: 50, time: 0.069, data: 0.002) G_GAN: 0.838 G_L1: 2.476 D_real: 0.441 D_fake: 0.843 \n",
            "(epoch: 35, iters: 150, time: 0.062, data: 0.002) G_GAN: 0.705 G_L1: 0.008 D_real: 0.714 D_fake: 0.673 \n",
            "(epoch: 35, iters: 250, time: 0.068, data: 0.002) G_GAN: 0.626 G_L1: 0.129 D_real: 0.641 D_fake: 0.755 \n",
            "(epoch: 35, iters: 350, time: 0.068, data: 0.002) G_GAN: 0.689 G_L1: 0.205 D_real: 0.655 D_fake: 0.714 \n",
            "(epoch: 35, iters: 450, time: 0.068, data: 0.002) G_GAN: 0.674 G_L1: 0.166 D_real: 0.677 D_fake: 0.714 \n",
            "(epoch: 35, iters: 550, time: 0.067, data: 0.002) G_GAN: 0.758 G_L1: 0.307 D_real: 0.801 D_fake: 0.599 \n",
            "(epoch: 35, iters: 650, time: 0.068, data: 0.002) G_GAN: 0.646 G_L1: 0.437 D_real: 0.935 D_fake: 0.511 \n",
            "(epoch: 35, iters: 750, time: 0.068, data: 0.002) G_GAN: 0.760 G_L1: 0.210 D_real: 0.794 D_fake: 0.591 \n",
            "(epoch: 35, iters: 850, time: 0.064, data: 0.002) G_GAN: 0.927 G_L1: 0.914 D_real: 1.064 D_fake: 0.397 \n",
            "saving the model at the end of epoch 35, iters 23764\n",
            "End of epoch 35 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 36, iters: 36, time: 0.065, data: 0.002) G_GAN: 0.857 G_L1: 0.841 D_real: 0.420 D_fake: 0.624 \n",
            "(epoch: 36, iters: 136, time: 0.059, data: 0.002) G_GAN: 0.974 G_L1: 0.265 D_real: 0.789 D_fake: 0.499 \n",
            "(epoch: 36, iters: 236, time: 0.061, data: 0.002) G_GAN: 0.732 G_L1: 0.809 D_real: 0.771 D_fake: 0.394 \n",
            "(epoch: 36, iters: 336, time: 0.060, data: 0.002) G_GAN: 0.897 G_L1: 0.982 D_real: 0.471 D_fake: 0.526 \n",
            "(epoch: 36, iters: 436, time: 0.068, data: 0.002) G_GAN: 0.688 G_L1: 0.246 D_real: 0.645 D_fake: 0.728 \n",
            "(epoch: 36, iters: 536, time: 0.067, data: 0.002) G_GAN: 1.243 G_L1: 0.691 D_real: 0.847 D_fake: 0.552 \n",
            "(epoch: 36, iters: 636, time: 0.068, data: 0.002) G_GAN: 0.708 G_L1: 0.763 D_real: 0.723 D_fake: 0.676 \n",
            "(epoch: 36, iters: 736, time: 0.069, data: 0.002) G_GAN: 0.722 G_L1: 0.173 D_real: 0.741 D_fake: 0.643 \n",
            "(epoch: 36, iters: 836, time: 0.068, data: 0.002) G_GAN: 0.781 G_L1: 0.200 D_real: 0.610 D_fake: 0.554 \n",
            "End of epoch 36 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 37, iters: 22, time: 0.068, data: 0.002) G_GAN: 0.760 G_L1: 0.412 D_real: 0.724 D_fake: 0.499 \n",
            "(epoch: 37, iters: 122, time: 0.065, data: 0.002) G_GAN: 0.765 G_L1: 0.270 D_real: 0.916 D_fake: 0.418 \n",
            "(epoch: 37, iters: 222, time: 0.068, data: 0.002) G_GAN: 0.683 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
            "(epoch: 37, iters: 322, time: 0.067, data: 0.002) G_GAN: 0.935 G_L1: 0.838 D_real: 0.692 D_fake: 0.599 \n",
            "saving the latest model (epoch 37, total_iters 25000)\n",
            "(epoch: 37, iters: 422, time: 0.069, data: 0.002) G_GAN: 0.620 G_L1: 1.138 D_real: 0.810 D_fake: 0.437 \n",
            "(epoch: 37, iters: 522, time: 0.062, data: 0.002) G_GAN: 0.603 G_L1: 0.324 D_real: 0.579 D_fake: 0.825 \n",
            "(epoch: 37, iters: 622, time: 0.069, data: 0.002) G_GAN: 0.911 G_L1: 0.445 D_real: 0.459 D_fake: 0.860 \n",
            "(epoch: 37, iters: 722, time: 0.068, data: 0.001) G_GAN: 0.862 G_L1: 1.240 D_real: 0.582 D_fake: 0.623 \n",
            "(epoch: 37, iters: 822, time: 0.069, data: 0.002) G_GAN: 1.005 G_L1: 1.520 D_real: 0.407 D_fake: 0.740 \n",
            "End of epoch 37 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 38, iters: 8, time: 0.069, data: 0.002) G_GAN: 0.634 G_L1: 0.000 D_real: 0.624 D_fake: 0.768 \n",
            "(epoch: 38, iters: 108, time: 0.068, data: 0.001) G_GAN: 0.696 G_L1: 0.725 D_real: 0.584 D_fake: 0.813 \n",
            "(epoch: 38, iters: 208, time: 0.069, data: 0.002) G_GAN: 0.871 G_L1: 0.595 D_real: 0.513 D_fake: 0.725 \n",
            "(epoch: 38, iters: 308, time: 0.068, data: 0.002) G_GAN: 0.655 G_L1: 0.249 D_real: 0.625 D_fake: 0.770 \n",
            "(epoch: 38, iters: 408, time: 0.068, data: 0.002) G_GAN: 0.490 G_L1: 0.051 D_real: 0.460 D_fake: 1.003 \n",
            "(epoch: 38, iters: 508, time: 0.069, data: 0.002) G_GAN: 0.688 G_L1: 1.072 D_real: 0.779 D_fake: 0.521 \n",
            "(epoch: 38, iters: 608, time: 0.066, data: 0.001) G_GAN: 0.915 G_L1: 1.012 D_real: 0.507 D_fake: 0.552 \n",
            "(epoch: 38, iters: 708, time: 0.068, data: 0.002) G_GAN: 0.900 G_L1: 1.018 D_real: 0.448 D_fake: 0.675 \n",
            "(epoch: 38, iters: 808, time: 0.068, data: 0.002) G_GAN: 0.679 G_L1: 0.526 D_real: 0.651 D_fake: 0.741 \n",
            "(epoch: 38, iters: 908, time: 0.069, data: 0.002) G_GAN: 0.636 G_L1: 1.152 D_real: 0.448 D_fake: 0.958 \n",
            "End of epoch 38 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 39, iters: 94, time: 0.067, data: 0.002) G_GAN: 0.875 G_L1: 0.965 D_real: 0.555 D_fake: 0.648 \n",
            "(epoch: 39, iters: 194, time: 0.068, data: 0.002) G_GAN: 0.752 G_L1: 0.129 D_real: 0.788 D_fake: 0.617 \n",
            "(epoch: 39, iters: 294, time: 0.068, data: 0.002) G_GAN: 0.667 G_L1: 0.000 D_real: 0.646 D_fake: 0.744 \n",
            "(epoch: 39, iters: 394, time: 0.068, data: 0.002) G_GAN: 0.668 G_L1: 0.000 D_real: 0.661 D_fake: 0.727 \n",
            "(epoch: 39, iters: 494, time: 0.069, data: 0.002) G_GAN: 0.730 G_L1: 0.226 D_real: 0.753 D_fake: 0.641 \n",
            "(epoch: 39, iters: 594, time: 0.067, data: 0.002) G_GAN: 0.684 G_L1: 0.000 D_real: 0.702 D_fake: 0.684 \n",
            "(epoch: 39, iters: 694, time: 0.070, data: 0.002) G_GAN: 0.805 G_L1: 0.135 D_real: 0.726 D_fake: 0.531 \n",
            "(epoch: 39, iters: 794, time: 0.062, data: 0.002) G_GAN: 0.660 G_L1: 0.000 D_real: 0.640 D_fake: 0.749 \n",
            "(epoch: 39, iters: 894, time: 0.068, data: 0.002) G_GAN: 0.830 G_L1: 0.361 D_real: 0.235 D_fake: 1.464 \n",
            "End of epoch 39 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 40, iters: 80, time: 0.064, data: 0.002) G_GAN: 0.831 G_L1: 1.590 D_real: 0.535 D_fake: 0.830 \n",
            "(epoch: 40, iters: 180, time: 0.068, data: 0.002) G_GAN: 0.474 G_L1: 0.527 D_real: 0.863 D_fake: 0.304 \n",
            "(epoch: 40, iters: 280, time: 0.068, data: 0.002) G_GAN: 0.490 G_L1: 0.631 D_real: 0.970 D_fake: 0.419 \n",
            "(epoch: 40, iters: 380, time: 0.068, data: 0.002) G_GAN: 0.704 G_L1: 0.133 D_real: 0.683 D_fake: 0.707 \n",
            "(epoch: 40, iters: 480, time: 0.066, data: 0.002) G_GAN: 0.656 G_L1: 0.628 D_real: 0.735 D_fake: 0.485 \n",
            "(epoch: 40, iters: 580, time: 0.069, data: 0.002) G_GAN: 0.689 G_L1: 0.185 D_real: 0.706 D_fake: 0.674 \n",
            "(epoch: 40, iters: 680, time: 0.069, data: 0.002) G_GAN: 0.827 G_L1: 0.257 D_real: 0.892 D_fake: 0.505 \n",
            "(epoch: 40, iters: 780, time: 0.068, data: 0.001) G_GAN: 0.691 G_L1: 0.441 D_real: 0.661 D_fake: 0.714 \n",
            "(epoch: 40, iters: 880, time: 0.068, data: 0.002) G_GAN: 0.766 G_L1: 0.179 D_real: 0.848 D_fake: 0.535 \n",
            "saving the model at the end of epoch 40, iters 28334\n",
            "End of epoch 40 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 41, iters: 66, time: 0.065, data: 0.002) G_GAN: 1.264 G_L1: 0.934 D_real: 0.383 D_fake: 0.516 \n",
            "(epoch: 41, iters: 166, time: 0.061, data: 0.002) G_GAN: 0.669 G_L1: 0.063 D_real: 0.633 D_fake: 0.746 \n",
            "(epoch: 41, iters: 266, time: 0.068, data: 0.002) G_GAN: 0.743 G_L1: 0.355 D_real: 0.595 D_fake: 0.634 \n",
            "(epoch: 41, iters: 366, time: 0.068, data: 0.002) G_GAN: 0.740 G_L1: 0.730 D_real: 0.634 D_fake: 0.709 \n",
            "(epoch: 41, iters: 466, time: 0.068, data: 0.002) G_GAN: 0.635 G_L1: 0.000 D_real: 0.625 D_fake: 0.767 \n",
            "(epoch: 41, iters: 566, time: 0.068, data: 0.002) G_GAN: 0.658 G_L1: 0.273 D_real: 0.701 D_fake: 0.707 \n",
            "(epoch: 41, iters: 666, time: 0.068, data: 0.002) G_GAN: 0.849 G_L1: 0.191 D_real: 0.606 D_fake: 0.586 \n",
            "(epoch: 41, iters: 766, time: 0.068, data: 0.002) G_GAN: 0.787 G_L1: 0.301 D_real: 0.450 D_fake: 0.803 \n",
            "(epoch: 41, iters: 866, time: 0.069, data: 0.002) G_GAN: 0.748 G_L1: 0.200 D_real: 0.650 D_fake: 0.730 \n",
            "End of epoch 41 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 42, iters: 52, time: 0.069, data: 0.002) G_GAN: 0.674 G_L1: 0.290 D_real: 0.665 D_fake: 0.737 \n",
            "(epoch: 42, iters: 152, time: 0.067, data: 0.002) G_GAN: 0.695 G_L1: 0.138 D_real: 0.704 D_fake: 0.676 \n",
            "(epoch: 42, iters: 252, time: 0.068, data: 0.002) G_GAN: 0.826 G_L1: 0.134 D_real: 0.635 D_fake: 0.562 \n",
            "(epoch: 42, iters: 352, time: 0.068, data: 0.002) G_GAN: 0.674 G_L1: 0.404 D_real: 0.664 D_fake: 0.722 \n",
            "(epoch: 42, iters: 452, time: 0.068, data: 0.003) G_GAN: 0.710 G_L1: 1.109 D_real: 0.600 D_fake: 0.712 \n",
            "(epoch: 42, iters: 552, time: 0.067, data: 0.002) G_GAN: 1.554 G_L1: 1.570 D_real: 0.072 D_fake: 1.095 \n",
            "(epoch: 42, iters: 652, time: 0.068, data: 0.002) G_GAN: 1.008 G_L1: 0.895 D_real: 0.320 D_fake: 0.869 \n",
            "(epoch: 42, iters: 752, time: 0.069, data: 0.002) G_GAN: 0.613 G_L1: 0.000 D_real: 0.606 D_fake: 0.792 \n",
            "saving the latest model (epoch 42, total_iters 30000)\n",
            "(epoch: 42, iters: 852, time: 0.067, data: 0.002) G_GAN: 0.765 G_L1: 0.424 D_real: 0.805 D_fake: 0.605 \n",
            "End of epoch 42 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 43, iters: 38, time: 0.057, data: 0.002) G_GAN: 1.044 G_L1: 1.089 D_real: 0.307 D_fake: 0.666 \n",
            "(epoch: 43, iters: 138, time: 0.068, data: 0.002) G_GAN: 0.767 G_L1: 0.000 D_real: 0.786 D_fake: 0.612 \n",
            "(epoch: 43, iters: 238, time: 0.067, data: 0.002) G_GAN: 0.834 G_L1: 1.166 D_real: 0.599 D_fake: 0.771 \n",
            "(epoch: 43, iters: 338, time: 0.068, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.732 D_fake: 0.658 \n",
            "(epoch: 43, iters: 438, time: 0.068, data: 0.002) G_GAN: 0.624 G_L1: 0.000 D_real: 0.605 D_fake: 0.792 \n",
            "(epoch: 43, iters: 538, time: 0.068, data: 0.002) G_GAN: 1.096 G_L1: 0.320 D_real: 0.095 D_fake: 1.011 \n",
            "(epoch: 43, iters: 638, time: 0.068, data: 0.002) G_GAN: 0.776 G_L1: 0.000 D_real: 0.767 D_fake: 0.625 \n",
            "(epoch: 43, iters: 738, time: 0.068, data: 0.002) G_GAN: 0.731 G_L1: 0.173 D_real: 0.596 D_fake: 0.720 \n",
            "(epoch: 43, iters: 838, time: 0.068, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.719 D_fake: 0.669 \n",
            "End of epoch 43 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 44, iters: 24, time: 0.063, data: 0.002) G_GAN: 0.771 G_L1: 0.680 D_real: 0.628 D_fake: 0.649 \n",
            "(epoch: 44, iters: 124, time: 0.067, data: 0.002) G_GAN: 0.694 G_L1: 0.059 D_real: 0.694 D_fake: 0.698 \n",
            "(epoch: 44, iters: 224, time: 0.067, data: 0.002) G_GAN: 0.688 G_L1: 0.184 D_real: 0.671 D_fake: 0.709 \n",
            "(epoch: 44, iters: 324, time: 0.067, data: 0.002) G_GAN: 0.693 G_L1: 0.322 D_real: 0.885 D_fake: 0.312 \n",
            "(epoch: 44, iters: 424, time: 0.068, data: 0.002) G_GAN: 0.765 G_L1: 0.120 D_real: 0.595 D_fake: 0.521 \n",
            "(epoch: 44, iters: 524, time: 0.065, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.722 D_fake: 0.665 \n",
            "(epoch: 44, iters: 624, time: 0.068, data: 0.002) G_GAN: 0.670 G_L1: 0.000 D_real: 0.655 D_fake: 0.734 \n",
            "(epoch: 44, iters: 724, time: 0.059, data: 0.002) G_GAN: 0.659 G_L1: 0.163 D_real: 0.651 D_fake: 0.701 \n",
            "(epoch: 44, iters: 824, time: 0.067, data: 0.002) G_GAN: 0.681 G_L1: 0.000 D_real: 0.664 D_fake: 0.724 \n",
            "End of epoch 44 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 45, iters: 10, time: 0.068, data: 0.002) G_GAN: 0.861 G_L1: 0.865 D_real: 0.620 D_fake: 0.561 \n",
            "(epoch: 45, iters: 110, time: 0.069, data: 0.002) G_GAN: 0.657 G_L1: 0.000 D_real: 0.651 D_fake: 0.737 \n",
            "(epoch: 45, iters: 210, time: 0.068, data: 0.002) G_GAN: 1.015 G_L1: 1.024 D_real: 0.506 D_fake: 0.603 \n",
            "(epoch: 45, iters: 310, time: 0.068, data: 0.002) G_GAN: 0.639 G_L1: 0.046 D_real: 0.635 D_fake: 0.760 \n",
            "(epoch: 45, iters: 410, time: 0.067, data: 0.002) G_GAN: 1.097 G_L1: 0.845 D_real: 0.395 D_fake: 1.168 \n",
            "(epoch: 45, iters: 510, time: 0.069, data: 0.002) G_GAN: 0.651 G_L1: 0.099 D_real: 0.631 D_fake: 0.774 \n",
            "(epoch: 45, iters: 610, time: 0.066, data: 0.002) G_GAN: 0.858 G_L1: 0.176 D_real: 0.860 D_fake: 0.489 \n",
            "(epoch: 45, iters: 710, time: 0.067, data: 0.002) G_GAN: 0.700 G_L1: 0.226 D_real: 0.507 D_fake: 0.945 \n",
            "(epoch: 45, iters: 810, time: 0.067, data: 0.002) G_GAN: 0.834 G_L1: 0.448 D_real: 0.637 D_fake: 0.534 \n",
            "(epoch: 45, iters: 910, time: 0.069, data: 0.002) G_GAN: 0.768 G_L1: 0.208 D_real: 0.833 D_fake: 0.595 \n",
            "saving the model at the end of epoch 45, iters 32904\n",
            "End of epoch 45 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 46, iters: 96, time: 0.069, data: 0.002) G_GAN: 0.978 G_L1: 0.102 D_real: 0.304 D_fake: 0.861 \n",
            "(epoch: 46, iters: 196, time: 0.065, data: 0.001) G_GAN: 0.876 G_L1: 0.690 D_real: 0.960 D_fake: 0.341 \n",
            "(epoch: 46, iters: 296, time: 0.068, data: 0.002) G_GAN: 0.921 G_L1: 0.739 D_real: 0.727 D_fake: 0.465 \n",
            "(epoch: 46, iters: 396, time: 0.067, data: 0.002) G_GAN: 1.355 G_L1: 1.187 D_real: 0.754 D_fake: 0.286 \n",
            "(epoch: 46, iters: 496, time: 0.068, data: 0.002) G_GAN: 0.748 G_L1: 0.039 D_real: 0.718 D_fake: 0.675 \n",
            "(epoch: 46, iters: 596, time: 0.068, data: 0.002) G_GAN: 0.962 G_L1: 0.465 D_real: 0.354 D_fake: 0.995 \n",
            "(epoch: 46, iters: 696, time: 0.068, data: 0.002) G_GAN: 0.708 G_L1: 0.077 D_real: 0.685 D_fake: 0.682 \n",
            "(epoch: 46, iters: 796, time: 0.068, data: 0.002) G_GAN: 0.755 G_L1: 0.375 D_real: 0.725 D_fake: 0.594 \n",
            "(epoch: 46, iters: 896, time: 0.067, data: 0.002) G_GAN: 0.934 G_L1: 0.346 D_real: 0.623 D_fake: 0.670 \n",
            "End of epoch 46 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 47, iters: 82, time: 0.068, data: 0.001) G_GAN: 1.438 G_L1: 1.398 D_real: 0.319 D_fake: 0.500 \n",
            "(epoch: 47, iters: 182, time: 0.068, data: 0.002) G_GAN: 1.884 G_L1: 0.691 D_real: 0.169 D_fake: 1.264 \n",
            "(epoch: 47, iters: 282, time: 0.068, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.714 D_fake: 0.673 \n",
            "(epoch: 47, iters: 382, time: 0.067, data: 0.002) G_GAN: 0.848 G_L1: 0.337 D_real: 0.412 D_fake: 0.976 \n",
            "(epoch: 47, iters: 482, time: 0.068, data: 0.002) G_GAN: 0.943 G_L1: 0.512 D_real: 1.191 D_fake: 0.304 \n",
            "(epoch: 47, iters: 582, time: 0.064, data: 0.002) G_GAN: 0.734 G_L1: 0.507 D_real: 0.624 D_fake: 0.760 \n",
            "(epoch: 47, iters: 682, time: 0.067, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.726 D_fake: 0.661 \n",
            "(epoch: 47, iters: 782, time: 0.068, data: 0.002) G_GAN: 0.696 G_L1: 0.278 D_real: 0.720 D_fake: 0.699 \n",
            "(epoch: 47, iters: 882, time: 0.067, data: 0.001) G_GAN: 0.804 G_L1: 1.145 D_real: 0.613 D_fake: 0.329 \n",
            "End of epoch 47 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 48, iters: 68, time: 0.063, data: 0.002) G_GAN: 0.952 G_L1: 0.421 D_real: 1.082 D_fake: 0.263 \n",
            "(epoch: 48, iters: 168, time: 0.068, data: 0.002) G_GAN: 0.629 G_L1: 0.174 D_real: 0.490 D_fake: 0.891 \n",
            "(epoch: 48, iters: 268, time: 0.068, data: 0.002) G_GAN: 0.917 G_L1: 1.141 D_real: 0.723 D_fake: 0.266 \n",
            "saving the latest model (epoch 48, total_iters 35000)\n",
            "(epoch: 48, iters: 368, time: 0.069, data: 0.002) G_GAN: 0.746 G_L1: 0.443 D_real: 0.929 D_fake: 0.449 \n",
            "(epoch: 48, iters: 468, time: 0.068, data: 0.002) G_GAN: 0.683 G_L1: 0.438 D_real: 0.746 D_fake: 0.654 \n",
            "(epoch: 48, iters: 568, time: 0.068, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
            "(epoch: 48, iters: 668, time: 0.068, data: 0.002) G_GAN: 0.815 G_L1: 0.537 D_real: 0.912 D_fake: 0.367 \n",
            "(epoch: 48, iters: 768, time: 0.069, data: 0.002) G_GAN: 0.945 G_L1: 0.477 D_real: 0.621 D_fake: 0.577 \n",
            "(epoch: 48, iters: 868, time: 0.069, data: 0.002) G_GAN: 0.881 G_L1: 0.495 D_real: 0.476 D_fake: 0.780 \n",
            "End of epoch 48 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 49, iters: 54, time: 0.068, data: 0.002) G_GAN: 0.680 G_L1: 0.650 D_real: 0.559 D_fake: 0.851 \n",
            "(epoch: 49, iters: 154, time: 0.066, data: 0.002) G_GAN: 0.656 G_L1: 0.000 D_real: 0.624 D_fake: 0.769 \n",
            "(epoch: 49, iters: 254, time: 0.066, data: 0.002) G_GAN: 0.634 G_L1: 0.252 D_real: 0.455 D_fake: 1.084 \n",
            "(epoch: 49, iters: 354, time: 0.068, data: 0.002) G_GAN: 0.760 G_L1: 0.583 D_real: 1.283 D_fake: 0.331 \n",
            "(epoch: 49, iters: 454, time: 0.067, data: 0.002) G_GAN: 0.789 G_L1: 0.121 D_real: 0.796 D_fake: 0.608 \n",
            "(epoch: 49, iters: 554, time: 0.068, data: 0.002) G_GAN: 1.699 G_L1: 1.570 D_real: 0.210 D_fake: 0.588 \n",
            "(epoch: 49, iters: 654, time: 0.063, data: 0.002) G_GAN: 1.145 G_L1: 0.963 D_real: 0.577 D_fake: 0.312 \n",
            "(epoch: 49, iters: 754, time: 0.068, data: 0.002) G_GAN: 0.827 G_L1: 0.536 D_real: 0.626 D_fake: 0.527 \n",
            "(epoch: 49, iters: 854, time: 0.062, data: 0.002) G_GAN: 0.653 G_L1: 0.000 D_real: 0.675 D_fake: 0.718 \n",
            "End of epoch 49 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 50, iters: 40, time: 0.068, data: 0.002) G_GAN: 1.235 G_L1: 0.400 D_real: 0.412 D_fake: 0.787 \n",
            "(epoch: 50, iters: 140, time: 0.068, data: 0.002) G_GAN: 1.596 G_L1: 1.413 D_real: 0.181 D_fake: 0.957 \n",
            "(epoch: 50, iters: 240, time: 0.068, data: 0.002) G_GAN: 0.668 G_L1: 0.000 D_real: 0.723 D_fake: 0.669 \n",
            "(epoch: 50, iters: 340, time: 0.066, data: 0.001) G_GAN: 0.687 G_L1: 0.000 D_real: 0.706 D_fake: 0.681 \n",
            "(epoch: 50, iters: 440, time: 0.068, data: 0.002) G_GAN: 0.615 G_L1: 0.280 D_real: 0.614 D_fake: 0.781 \n",
            "(epoch: 50, iters: 540, time: 0.068, data: 0.002) G_GAN: 0.717 G_L1: 0.108 D_real: 0.600 D_fake: 0.662 \n",
            "(epoch: 50, iters: 640, time: 0.068, data: 0.002) G_GAN: 0.792 G_L1: 0.302 D_real: 0.706 D_fake: 0.907 \n",
            "(epoch: 50, iters: 740, time: 0.068, data: 0.002) G_GAN: 0.966 G_L1: 0.428 D_real: 1.085 D_fake: 0.342 \n",
            "(epoch: 50, iters: 840, time: 0.068, data: 0.002) G_GAN: 0.739 G_L1: 0.489 D_real: 0.881 D_fake: 0.466 \n",
            "saving the model at the end of epoch 50, iters 37474\n",
            "End of epoch 50 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 51, iters: 26, time: 0.069, data: 0.002) G_GAN: 1.407 G_L1: 0.774 D_real: 0.283 D_fake: 0.824 \n",
            "(epoch: 51, iters: 126, time: 0.057, data: 0.002) G_GAN: 0.670 G_L1: 0.000 D_real: 0.670 D_fake: 0.718 \n",
            "(epoch: 51, iters: 226, time: 0.068, data: 0.002) G_GAN: 0.723 G_L1: 0.328 D_real: 0.741 D_fake: 0.657 \n",
            "(epoch: 51, iters: 326, time: 0.068, data: 0.002) G_GAN: 0.810 G_L1: 0.918 D_real: 0.911 D_fake: 0.490 \n",
            "(epoch: 51, iters: 426, time: 0.068, data: 0.002) G_GAN: 0.688 G_L1: 0.073 D_real: 0.689 D_fake: 0.700 \n",
            "(epoch: 51, iters: 526, time: 0.067, data: 0.002) G_GAN: 0.512 G_L1: 0.493 D_real: 1.427 D_fake: 0.243 \n",
            "(epoch: 51, iters: 626, time: 0.069, data: 0.002) G_GAN: 0.947 G_L1: 0.457 D_real: 0.248 D_fake: 1.158 \n",
            "(epoch: 51, iters: 726, time: 0.067, data: 0.002) G_GAN: 1.068 G_L1: 0.223 D_real: 0.708 D_fake: 0.470 \n",
            "(epoch: 51, iters: 826, time: 0.069, data: 0.002) G_GAN: 0.768 G_L1: 0.418 D_real: 0.782 D_fake: 0.619 \n",
            "End of epoch 51 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 52, iters: 12, time: 0.066, data: 0.002) G_GAN: 1.393 G_L1: 1.377 D_real: 0.511 D_fake: 0.319 \n",
            "(epoch: 52, iters: 112, time: 0.068, data: 0.002) G_GAN: 0.606 G_L1: 0.515 D_real: 0.614 D_fake: 0.783 \n",
            "(epoch: 52, iters: 212, time: 0.062, data: 0.002) G_GAN: 0.481 G_L1: 0.472 D_real: 0.145 D_fake: 1.740 \n",
            "(epoch: 52, iters: 312, time: 0.068, data: 0.001) G_GAN: 0.712 G_L1: 0.000 D_real: 0.703 D_fake: 0.686 \n",
            "(epoch: 52, iters: 412, time: 0.068, data: 0.002) G_GAN: 0.748 G_L1: 0.619 D_real: 0.825 D_fake: 0.576 \n",
            "(epoch: 52, iters: 512, time: 0.067, data: 0.002) G_GAN: 0.765 G_L1: 0.162 D_real: 0.596 D_fake: 0.715 \n",
            "(epoch: 52, iters: 612, time: 0.068, data: 0.002) G_GAN: 0.590 G_L1: 0.000 D_real: 0.561 D_fake: 0.848 \n",
            "(epoch: 52, iters: 712, time: 0.065, data: 0.002) G_GAN: 0.808 G_L1: 0.570 D_real: 0.610 D_fake: 0.604 \n",
            "(epoch: 52, iters: 812, time: 0.067, data: 0.002) G_GAN: 0.773 G_L1: 0.350 D_real: 0.823 D_fake: 0.594 \n",
            "(epoch: 52, iters: 912, time: 0.066, data: 0.002) G_GAN: 0.739 G_L1: 0.147 D_real: 0.810 D_fake: 0.595 \n",
            "End of epoch 52 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 53, iters: 98, time: 0.069, data: 0.002) G_GAN: 0.583 G_L1: 0.440 D_real: 1.227 D_fake: 0.314 \n",
            "(epoch: 53, iters: 198, time: 0.066, data: 0.002) G_GAN: 0.862 G_L1: 0.143 D_real: 0.857 D_fake: 0.512 \n",
            "(epoch: 53, iters: 298, time: 0.067, data: 0.002) G_GAN: 0.792 G_L1: 0.000 D_real: 0.802 D_fake: 0.596 \n",
            "(epoch: 53, iters: 398, time: 0.066, data: 0.002) G_GAN: 0.722 G_L1: 0.582 D_real: 0.642 D_fake: 0.751 \n",
            "(epoch: 53, iters: 498, time: 0.067, data: 0.002) G_GAN: 0.667 G_L1: 0.000 D_real: 0.651 D_fake: 0.737 \n",
            "(epoch: 53, iters: 598, time: 0.068, data: 0.002) G_GAN: 0.842 G_L1: 0.449 D_real: 0.769 D_fake: 0.513 \n",
            "(epoch: 53, iters: 698, time: 0.068, data: 0.002) G_GAN: 0.927 G_L1: 0.898 D_real: 0.484 D_fake: 0.289 \n",
            "saving the latest model (epoch 53, total_iters 40000)\n",
            "(epoch: 53, iters: 798, time: 0.068, data: 0.002) G_GAN: 0.887 G_L1: 1.267 D_real: 0.705 D_fake: 0.278 \n",
            "(epoch: 53, iters: 898, time: 0.067, data: 0.002) G_GAN: 0.686 G_L1: 0.119 D_real: 0.705 D_fake: 0.693 \n",
            "End of epoch 53 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 54, iters: 84, time: 0.057, data: 0.002) G_GAN: 0.665 G_L1: 0.245 D_real: 0.797 D_fake: 0.543 \n",
            "(epoch: 54, iters: 184, time: 0.068, data: 0.002) G_GAN: 0.652 G_L1: 0.000 D_real: 0.643 D_fake: 0.748 \n",
            "(epoch: 54, iters: 284, time: 0.063, data: 0.002) G_GAN: 0.700 G_L1: 0.199 D_real: 0.616 D_fake: 0.774 \n",
            "(epoch: 54, iters: 384, time: 0.069, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.722 D_fake: 0.666 \n",
            "(epoch: 54, iters: 484, time: 0.068, data: 0.002) G_GAN: 0.663 G_L1: 0.000 D_real: 0.672 D_fake: 0.716 \n",
            "(epoch: 54, iters: 584, time: 0.068, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.691 D_fake: 0.696 \n",
            "(epoch: 54, iters: 684, time: 0.068, data: 0.002) G_GAN: 0.821 G_L1: 0.321 D_real: 0.453 D_fake: 0.731 \n",
            "(epoch: 54, iters: 784, time: 0.068, data: 0.002) G_GAN: 0.657 G_L1: 0.196 D_real: 0.763 D_fake: 0.742 \n",
            "(epoch: 54, iters: 884, time: 0.068, data: 0.002) G_GAN: 0.837 G_L1: 0.329 D_real: 0.901 D_fake: 0.508 \n",
            "End of epoch 54 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 55, iters: 70, time: 0.068, data: 0.002) G_GAN: 0.635 G_L1: 0.570 D_real: 0.963 D_fake: 0.422 \n",
            "(epoch: 55, iters: 170, time: 0.069, data: 0.001) G_GAN: 0.717 G_L1: 0.000 D_real: 0.717 D_fake: 0.671 \n",
            "(epoch: 55, iters: 270, time: 0.066, data: 0.002) G_GAN: 0.664 G_L1: 0.401 D_real: 0.574 D_fake: 0.795 \n",
            "(epoch: 55, iters: 370, time: 0.069, data: 0.002) G_GAN: 0.900 G_L1: 0.361 D_real: 0.906 D_fake: 0.435 \n",
            "(epoch: 55, iters: 470, time: 0.068, data: 0.002) G_GAN: 0.681 G_L1: 0.425 D_real: 0.666 D_fake: 0.707 \n",
            "(epoch: 55, iters: 570, time: 0.068, data: 0.002) G_GAN: 0.637 G_L1: 0.062 D_real: 0.650 D_fake: 0.744 \n",
            "(epoch: 55, iters: 670, time: 0.069, data: 0.002) G_GAN: 0.603 G_L1: 0.118 D_real: 0.587 D_fake: 0.807 \n",
            "(epoch: 55, iters: 770, time: 0.069, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.722 D_fake: 0.666 \n",
            "(epoch: 55, iters: 870, time: 0.068, data: 0.002) G_GAN: 0.966 G_L1: 0.577 D_real: 0.683 D_fake: 0.415 \n",
            "saving the model at the end of epoch 55, iters 42044\n",
            "End of epoch 55 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 56, iters: 56, time: 0.063, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.712 D_fake: 0.680 \n",
            "(epoch: 56, iters: 156, time: 0.058, data: 0.002) G_GAN: 0.694 G_L1: 0.862 D_real: 0.904 D_fake: 0.517 \n",
            "(epoch: 56, iters: 256, time: 0.067, data: 0.002) G_GAN: 0.777 G_L1: 0.248 D_real: 0.819 D_fake: 0.441 \n",
            "(epoch: 56, iters: 356, time: 0.067, data: 0.002) G_GAN: 0.651 G_L1: 0.000 D_real: 0.660 D_fake: 0.728 \n",
            "(epoch: 56, iters: 456, time: 0.064, data: 0.002) G_GAN: 0.789 G_L1: 0.476 D_real: 0.814 D_fake: 0.502 \n",
            "(epoch: 56, iters: 556, time: 0.067, data: 0.002) G_GAN: 0.671 G_L1: 0.108 D_real: 0.675 D_fake: 0.713 \n",
            "(epoch: 56, iters: 656, time: 0.078, data: 0.002) G_GAN: 0.385 G_L1: 0.348 D_real: 1.007 D_fake: 0.218 \n",
            "(epoch: 56, iters: 756, time: 0.068, data: 0.002) G_GAN: 0.626 G_L1: 0.352 D_real: 0.615 D_fake: 0.787 \n",
            "(epoch: 56, iters: 856, time: 0.068, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.738 D_fake: 0.651 \n",
            "End of epoch 56 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 57, iters: 42, time: 0.068, data: 0.001) G_GAN: 0.605 G_L1: 0.445 D_real: 0.580 D_fake: 0.835 \n",
            "(epoch: 57, iters: 142, time: 0.068, data: 0.002) G_GAN: 0.633 G_L1: 0.263 D_real: 0.464 D_fake: 0.967 \n",
            "(epoch: 57, iters: 242, time: 0.068, data: 0.002) G_GAN: 0.711 G_L1: 0.339 D_real: 0.712 D_fake: 0.676 \n",
            "(epoch: 57, iters: 342, time: 0.069, data: 0.002) G_GAN: 0.862 G_L1: 0.142 D_real: 0.861 D_fake: 0.518 \n",
            "(epoch: 57, iters: 442, time: 0.067, data: 0.002) G_GAN: 0.675 G_L1: 0.000 D_real: 0.679 D_fake: 0.711 \n",
            "(epoch: 57, iters: 542, time: 0.071, data: 0.002) G_GAN: 0.666 G_L1: 0.000 D_real: 0.664 D_fake: 0.723 \n",
            "(epoch: 57, iters: 642, time: 0.068, data: 0.002) G_GAN: 0.724 G_L1: 0.687 D_real: 0.756 D_fake: 0.479 \n",
            "(epoch: 57, iters: 742, time: 0.069, data: 0.002) G_GAN: 0.689 G_L1: 0.290 D_real: 0.498 D_fake: 0.854 \n",
            "(epoch: 57, iters: 842, time: 0.068, data: 0.002) G_GAN: 0.912 G_L1: 0.568 D_real: 0.645 D_fake: 0.413 \n",
            "End of epoch 57 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 58, iters: 28, time: 0.068, data: 0.001) G_GAN: 1.479 G_L1: 0.609 D_real: 0.348 D_fake: 0.674 \n",
            "(epoch: 58, iters: 128, time: 0.065, data: 0.005) G_GAN: 0.840 G_L1: 0.676 D_real: 0.581 D_fake: 0.639 \n",
            "(epoch: 58, iters: 228, time: 0.068, data: 0.002) G_GAN: 0.768 G_L1: 0.454 D_real: 0.798 D_fake: 0.604 \n",
            "(epoch: 58, iters: 328, time: 0.068, data: 0.002) G_GAN: 0.582 G_L1: 0.280 D_real: 0.561 D_fake: 0.896 \n",
            "(epoch: 58, iters: 428, time: 0.068, data: 0.002) G_GAN: 0.990 G_L1: 0.836 D_real: 0.467 D_fake: 0.781 \n",
            "(epoch: 58, iters: 528, time: 0.068, data: 0.002) G_GAN: 1.226 G_L1: 0.984 D_real: 0.616 D_fake: 0.188 \n",
            "(epoch: 58, iters: 628, time: 0.062, data: 0.002) G_GAN: 0.686 G_L1: 0.890 D_real: 0.929 D_fake: 0.508 \n",
            "(epoch: 58, iters: 728, time: 0.068, data: 0.002) G_GAN: 0.927 G_L1: 0.343 D_real: 0.432 D_fake: 0.886 \n",
            "(epoch: 58, iters: 828, time: 0.068, data: 0.002) G_GAN: 0.855 G_L1: 0.302 D_real: 0.371 D_fake: 1.110 \n",
            "End of epoch 58 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 59, iters: 14, time: 0.068, data: 0.002) G_GAN: 0.802 G_L1: 1.050 D_real: 0.825 D_fake: 0.584 \n",
            "(epoch: 59, iters: 114, time: 0.066, data: 0.002) G_GAN: 0.644 G_L1: 0.423 D_real: 0.558 D_fake: 0.861 \n",
            "(epoch: 59, iters: 214, time: 0.067, data: 0.002) G_GAN: 0.919 G_L1: 0.162 D_real: 0.624 D_fake: 0.617 \n",
            "saving the latest model (epoch 59, total_iters 45000)\n",
            "(epoch: 59, iters: 314, time: 0.069, data: 0.001) G_GAN: 0.710 G_L1: 0.000 D_real: 0.708 D_fake: 0.678 \n",
            "(epoch: 59, iters: 414, time: 0.067, data: 0.002) G_GAN: 0.763 G_L1: 0.408 D_real: 0.508 D_fake: 0.754 \n",
            "(epoch: 59, iters: 514, time: 0.068, data: 0.002) G_GAN: 0.679 G_L1: 0.353 D_real: 0.737 D_fake: 0.701 \n",
            "(epoch: 59, iters: 614, time: 0.068, data: 0.002) G_GAN: 0.835 G_L1: 0.332 D_real: 0.407 D_fake: 0.877 \n",
            "(epoch: 59, iters: 714, time: 0.065, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.736 D_fake: 0.652 \n",
            "(epoch: 59, iters: 814, time: 0.067, data: 0.002) G_GAN: 1.076 G_L1: 0.350 D_real: 0.572 D_fake: 0.679 \n",
            "(epoch: 59, iters: 914, time: 0.067, data: 0.002) G_GAN: 0.777 G_L1: 0.098 D_real: 0.644 D_fake: 0.644 \n",
            "End of epoch 59 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 60, iters: 100, time: 0.068, data: 0.208) G_GAN: 0.741 G_L1: 0.000 D_real: 0.738 D_fake: 0.652 \n",
            "(epoch: 60, iters: 200, time: 0.065, data: 0.002) G_GAN: 0.733 G_L1: 0.182 D_real: 0.756 D_fake: 0.631 \n",
            "(epoch: 60, iters: 300, time: 0.068, data: 0.002) G_GAN: 0.788 G_L1: 0.292 D_real: 0.798 D_fake: 0.589 \n",
            "(epoch: 60, iters: 400, time: 0.068, data: 0.002) G_GAN: 1.418 G_L1: 0.524 D_real: 0.268 D_fake: 0.443 \n",
            "(epoch: 60, iters: 500, time: 0.067, data: 0.002) G_GAN: 0.793 G_L1: 1.316 D_real: 0.913 D_fake: 0.290 \n",
            "(epoch: 60, iters: 600, time: 0.068, data: 0.002) G_GAN: 0.579 G_L1: 0.169 D_real: 0.594 D_fake: 0.810 \n",
            "(epoch: 60, iters: 700, time: 0.068, data: 0.002) G_GAN: 0.830 G_L1: 0.172 D_real: 0.593 D_fake: 0.598 \n",
            "(epoch: 60, iters: 800, time: 0.068, data: 0.002) G_GAN: 0.819 G_L1: 0.345 D_real: 0.742 D_fake: 0.497 \n",
            "(epoch: 60, iters: 900, time: 0.063, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.707 D_fake: 0.680 \n",
            "saving the model at the end of epoch 60, iters 46614\n",
            "End of epoch 60 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 61, iters: 86, time: 0.068, data: 0.002) G_GAN: 0.816 G_L1: 1.414 D_real: 0.659 D_fake: 0.504 \n",
            "(epoch: 61, iters: 186, time: 0.067, data: 0.002) G_GAN: 0.679 G_L1: 0.121 D_real: 0.669 D_fake: 0.709 \n",
            "(epoch: 61, iters: 286, time: 0.068, data: 0.002) G_GAN: 0.810 G_L1: 0.240 D_real: 0.956 D_fake: 0.499 \n",
            "(epoch: 61, iters: 386, time: 0.069, data: 0.002) G_GAN: 0.715 G_L1: 0.095 D_real: 0.716 D_fake: 0.673 \n",
            "(epoch: 61, iters: 486, time: 0.068, data: 0.002) G_GAN: 0.674 G_L1: 0.210 D_real: 0.660 D_fake: 0.740 \n",
            "(epoch: 61, iters: 586, time: 0.067, data: 0.002) G_GAN: 0.789 G_L1: 0.457 D_real: 1.656 D_fake: 0.203 \n",
            "(epoch: 61, iters: 686, time: 0.069, data: 0.002) G_GAN: 1.100 G_L1: 1.072 D_real: 0.969 D_fake: 0.179 \n",
            "(epoch: 61, iters: 786, time: 0.066, data: 0.002) G_GAN: 0.699 G_L1: 1.026 D_real: 0.749 D_fake: 0.451 \n",
            "(epoch: 61, iters: 886, time: 0.069, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.719 D_fake: 0.669 \n",
            "End of epoch 61 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 62, iters: 72, time: 0.068, data: 0.001) G_GAN: 0.642 G_L1: 0.072 D_real: 0.632 D_fake: 0.759 \n",
            "(epoch: 62, iters: 172, time: 0.067, data: 0.002) G_GAN: 0.720 G_L1: 0.788 D_real: 0.610 D_fake: 0.763 \n",
            "(epoch: 62, iters: 272, time: 0.068, data: 0.002) G_GAN: 0.671 G_L1: 0.416 D_real: 0.704 D_fake: 0.669 \n",
            "(epoch: 62, iters: 372, time: 0.068, data: 0.002) G_GAN: 0.697 G_L1: 0.168 D_real: 0.663 D_fake: 0.705 \n",
            "(epoch: 62, iters: 472, time: 0.068, data: 0.002) G_GAN: 0.643 G_L1: 0.463 D_real: 0.319 D_fake: 1.117 \n",
            "(epoch: 62, iters: 572, time: 0.068, data: 0.002) G_GAN: 0.912 G_L1: 0.194 D_real: 0.652 D_fake: 0.511 \n",
            "(epoch: 62, iters: 672, time: 0.068, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.716 D_fake: 0.672 \n",
            "(epoch: 62, iters: 772, time: 0.067, data: 0.002) G_GAN: 0.769 G_L1: 0.369 D_real: 0.795 D_fake: 0.597 \n",
            "(epoch: 62, iters: 872, time: 0.065, data: 0.002) G_GAN: 0.640 G_L1: 1.230 D_real: 0.463 D_fake: 1.084 \n",
            "End of epoch 62 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 63, iters: 58, time: 0.068, data: 0.002) G_GAN: 0.594 G_L1: 0.084 D_real: 0.554 D_fake: 0.851 \n",
            "(epoch: 63, iters: 158, time: 0.068, data: 0.001) G_GAN: 0.821 G_L1: 0.159 D_real: 0.795 D_fake: 0.500 \n",
            "(epoch: 63, iters: 258, time: 0.068, data: 0.002) G_GAN: 0.643 G_L1: 0.000 D_real: 0.639 D_fake: 0.750 \n",
            "(epoch: 63, iters: 358, time: 0.063, data: 0.002) G_GAN: 0.640 G_L1: 0.171 D_real: 0.639 D_fake: 0.771 \n",
            "(epoch: 63, iters: 458, time: 0.068, data: 0.002) G_GAN: 1.174 G_L1: 0.489 D_real: 0.734 D_fake: 0.253 \n",
            "(epoch: 63, iters: 558, time: 0.068, data: 0.002) G_GAN: 0.684 G_L1: 0.000 D_real: 0.685 D_fake: 0.702 \n",
            "(epoch: 63, iters: 658, time: 0.067, data: 0.002) G_GAN: 0.704 G_L1: 0.076 D_real: 0.724 D_fake: 0.666 \n",
            "(epoch: 63, iters: 758, time: 0.068, data: 0.002) G_GAN: 0.895 G_L1: 1.017 D_real: 0.656 D_fake: 0.482 \n",
            "(epoch: 63, iters: 858, time: 0.068, data: 0.002) G_GAN: 0.803 G_L1: 0.209 D_real: 0.683 D_fake: 0.595 \n",
            "End of epoch 63 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 64, iters: 44, time: 0.067, data: 0.002) G_GAN: 1.255 G_L1: 0.442 D_real: 0.337 D_fake: 1.010 \n",
            "(epoch: 64, iters: 144, time: 0.068, data: 0.002) G_GAN: 0.645 G_L1: 0.000 D_real: 0.655 D_fake: 0.734 \n",
            "(epoch: 64, iters: 244, time: 0.067, data: 0.002) G_GAN: 0.773 G_L1: 0.552 D_real: 0.786 D_fake: 0.603 \n",
            "(epoch: 64, iters: 344, time: 0.068, data: 0.002) G_GAN: 0.852 G_L1: 0.608 D_real: 0.598 D_fake: 0.492 \n",
            "(epoch: 64, iters: 444, time: 0.068, data: 0.002) G_GAN: 0.860 G_L1: 0.444 D_real: 0.688 D_fake: 0.618 \n",
            "(epoch: 64, iters: 544, time: 0.061, data: 0.002) G_GAN: 0.698 G_L1: 0.834 D_real: 0.511 D_fake: 0.979 \n",
            "(epoch: 64, iters: 644, time: 0.067, data: 0.002) G_GAN: 0.756 G_L1: 0.437 D_real: 1.211 D_fake: 0.231 \n",
            "saving the latest model (epoch 64, total_iters 50000)\n",
            "(epoch: 64, iters: 744, time: 0.069, data: 0.002) G_GAN: 0.750 G_L1: 0.534 D_real: 0.323 D_fake: 1.101 \n",
            "(epoch: 64, iters: 844, time: 0.068, data: 0.002) G_GAN: 0.681 G_L1: 0.087 D_real: 0.875 D_fake: 0.632 \n",
            "End of epoch 64 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 65, iters: 30, time: 0.068, data: 0.002) G_GAN: 0.769 G_L1: 0.141 D_real: 0.645 D_fake: 0.657 \n",
            "(epoch: 65, iters: 130, time: 0.068, data: 0.002) G_GAN: 0.679 G_L1: 0.000 D_real: 0.684 D_fake: 0.702 \n",
            "(epoch: 65, iters: 230, time: 0.067, data: 0.002) G_GAN: 0.743 G_L1: 0.258 D_real: 0.746 D_fake: 0.646 \n",
            "(epoch: 65, iters: 330, time: 0.068, data: 0.002) G_GAN: 0.777 G_L1: 0.664 D_real: 0.737 D_fake: 0.569 \n",
            "(epoch: 65, iters: 430, time: 0.068, data: 0.002) G_GAN: 0.727 G_L1: 0.117 D_real: 0.481 D_fake: 0.983 \n",
            "(epoch: 65, iters: 530, time: 0.068, data: 0.002) G_GAN: 0.661 G_L1: 0.000 D_real: 0.669 D_fake: 0.719 \n",
            "(epoch: 65, iters: 630, time: 0.069, data: 0.002) G_GAN: 0.663 G_L1: 0.141 D_real: 0.646 D_fake: 0.746 \n",
            "(epoch: 65, iters: 730, time: 0.069, data: 0.002) G_GAN: 0.630 G_L1: 0.000 D_real: 0.642 D_fake: 0.748 \n",
            "(epoch: 65, iters: 830, time: 0.068, data: 0.002) G_GAN: 0.799 G_L1: 0.000 D_real: 0.807 D_fake: 0.591 \n",
            "saving the model at the end of epoch 65, iters 51184\n",
            "End of epoch 65 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 66, iters: 16, time: 0.068, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.685 D_fake: 0.701 \n",
            "(epoch: 66, iters: 116, time: 0.069, data: 0.002) G_GAN: 0.767 G_L1: 0.211 D_real: 0.573 D_fake: 0.705 \n",
            "(epoch: 66, iters: 216, time: 0.057, data: 0.002) G_GAN: 0.733 G_L1: 0.306 D_real: 0.743 D_fake: 0.639 \n",
            "(epoch: 66, iters: 316, time: 0.068, data: 0.002) G_GAN: 0.688 G_L1: 0.000 D_real: 0.672 D_fake: 0.717 \n",
            "(epoch: 66, iters: 416, time: 0.068, data: 0.001) G_GAN: 0.975 G_L1: 0.251 D_real: 0.231 D_fake: 1.110 \n",
            "(epoch: 66, iters: 516, time: 0.068, data: 0.001) G_GAN: 0.427 G_L1: 0.714 D_real: 1.173 D_fake: 0.280 \n",
            "(epoch: 66, iters: 616, time: 0.069, data: 0.002) G_GAN: 0.898 G_L1: 0.361 D_real: 0.704 D_fake: 0.495 \n",
            "(epoch: 66, iters: 716, time: 0.071, data: 0.002) G_GAN: 0.822 G_L1: 0.328 D_real: 0.811 D_fake: 0.407 \n",
            "(epoch: 66, iters: 816, time: 0.068, data: 0.002) G_GAN: 0.649 G_L1: 0.000 D_real: 0.662 D_fake: 0.727 \n",
            "End of epoch 66 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 67, iters: 2, time: 0.057, data: 0.002) G_GAN: 0.732 G_L1: 0.157 D_real: 0.482 D_fake: 0.787 \n",
            "(epoch: 67, iters: 102, time: 0.068, data: 0.000) G_GAN: 0.624 G_L1: 0.459 D_real: 0.555 D_fake: 0.867 \n",
            "(epoch: 67, iters: 202, time: 0.068, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.733 D_fake: 0.656 \n",
            "(epoch: 67, iters: 302, time: 0.068, data: 0.001) G_GAN: 1.210 G_L1: 1.145 D_real: 0.379 D_fake: 0.588 \n",
            "(epoch: 67, iters: 402, time: 0.069, data: 0.002) G_GAN: 0.899 G_L1: 0.544 D_real: 0.596 D_fake: 0.468 \n",
            "(epoch: 67, iters: 502, time: 0.069, data: 0.002) G_GAN: 0.638 G_L1: 0.150 D_real: 0.632 D_fake: 0.754 \n",
            "(epoch: 67, iters: 602, time: 0.069, data: 0.001) G_GAN: 0.888 G_L1: 0.729 D_real: 1.022 D_fake: 0.359 \n",
            "(epoch: 67, iters: 702, time: 0.064, data: 0.002) G_GAN: 0.759 G_L1: 0.681 D_real: 0.743 D_fake: 0.619 \n",
            "(epoch: 67, iters: 802, time: 0.068, data: 0.002) G_GAN: 0.566 G_L1: 0.898 D_real: 0.961 D_fake: 0.486 \n",
            "(epoch: 67, iters: 902, time: 0.068, data: 0.002) G_GAN: 1.232 G_L1: 0.264 D_real: 0.275 D_fake: 0.544 \n",
            "End of epoch 67 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 68, iters: 88, time: 0.068, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.752 D_fake: 0.643 \n",
            "(epoch: 68, iters: 188, time: 0.065, data: 0.002) G_GAN: 0.650 G_L1: 0.471 D_real: 0.632 D_fake: 0.763 \n",
            "(epoch: 68, iters: 288, time: 0.068, data: 0.002) G_GAN: 0.753 G_L1: 0.434 D_real: 0.743 D_fake: 0.619 \n",
            "(epoch: 68, iters: 388, time: 0.068, data: 0.002) G_GAN: 0.722 G_L1: 0.096 D_real: 0.773 D_fake: 0.634 \n",
            "(epoch: 68, iters: 488, time: 0.067, data: 0.002) G_GAN: 0.745 G_L1: 0.396 D_real: 0.662 D_fake: 0.673 \n",
            "(epoch: 68, iters: 588, time: 0.068, data: 0.002) G_GAN: 0.757 G_L1: 1.452 D_real: 0.568 D_fake: 0.756 \n",
            "(epoch: 68, iters: 688, time: 0.068, data: 0.002) G_GAN: 0.699 G_L1: 0.093 D_real: 0.695 D_fake: 0.693 \n",
            "(epoch: 68, iters: 788, time: 0.069, data: 0.002) G_GAN: 0.821 G_L1: 0.236 D_real: 0.902 D_fake: 0.599 \n",
            "(epoch: 68, iters: 888, time: 0.062, data: 0.002) G_GAN: 0.827 G_L1: 0.455 D_real: 0.646 D_fake: 0.568 \n",
            "End of epoch 68 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 69, iters: 74, time: 0.068, data: 0.002) G_GAN: 0.704 G_L1: 0.000 D_real: 0.707 D_fake: 0.680 \n",
            "(epoch: 69, iters: 174, time: 0.069, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.753 D_fake: 0.638 \n",
            "(epoch: 69, iters: 274, time: 0.068, data: 0.002) G_GAN: 1.099 G_L1: 1.979 D_real: 0.280 D_fake: 0.622 \n",
            "(epoch: 69, iters: 374, time: 0.068, data: 0.002) G_GAN: 0.671 G_L1: 0.000 D_real: 0.676 D_fake: 0.711 \n",
            "(epoch: 69, iters: 474, time: 0.068, data: 0.002) G_GAN: 1.093 G_L1: 1.111 D_real: 0.397 D_fake: 0.480 \n",
            "(epoch: 69, iters: 574, time: 0.067, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.712 D_fake: 0.675 \n",
            "(epoch: 69, iters: 674, time: 0.068, data: 0.002) G_GAN: 0.707 G_L1: 0.075 D_real: 0.810 D_fake: 0.582 \n",
            "(epoch: 69, iters: 774, time: 0.068, data: 0.002) G_GAN: 0.791 G_L1: 0.219 D_real: 0.647 D_fake: 0.637 \n",
            "(epoch: 69, iters: 874, time: 0.068, data: 0.002) G_GAN: 0.757 G_L1: 0.124 D_real: 0.771 D_fake: 0.579 \n",
            "End of epoch 69 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 70, iters: 60, time: 0.068, data: 0.002) G_GAN: 0.843 G_L1: 0.553 D_real: 0.888 D_fake: 0.488 \n",
            "(epoch: 70, iters: 160, time: 0.066, data: 0.002) G_GAN: 0.672 G_L1: 1.017 D_real: 0.782 D_fake: 0.648 \n",
            "saving the latest model (epoch 70, total_iters 55000)\n",
            "(epoch: 70, iters: 260, time: 0.068, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.714 D_fake: 0.675 \n",
            "(epoch: 70, iters: 360, time: 0.062, data: 0.002) G_GAN: 0.787 G_L1: 0.318 D_real: 0.945 D_fake: 0.502 \n",
            "(epoch: 70, iters: 460, time: 0.067, data: 0.002) G_GAN: 0.668 G_L1: 0.000 D_real: 0.652 D_fake: 0.737 \n",
            "(epoch: 70, iters: 560, time: 0.069, data: 0.002) G_GAN: 1.647 G_L1: 0.748 D_real: 0.327 D_fake: 0.807 \n",
            "(epoch: 70, iters: 660, time: 0.068, data: 0.002) G_GAN: 1.560 G_L1: 1.914 D_real: 0.157 D_fake: 0.446 \n",
            "(epoch: 70, iters: 760, time: 0.069, data: 0.002) G_GAN: 0.857 G_L1: 0.313 D_real: 0.526 D_fake: 0.743 \n",
            "(epoch: 70, iters: 860, time: 0.068, data: 0.002) G_GAN: 0.644 G_L1: 0.000 D_real: 0.637 D_fake: 0.753 \n",
            "saving the model at the end of epoch 70, iters 55754\n",
            "End of epoch 70 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 71, iters: 46, time: 0.070, data: 0.002) G_GAN: 0.605 G_L1: 0.241 D_real: 0.434 D_fake: 0.959 \n",
            "(epoch: 71, iters: 146, time: 0.058, data: 0.002) G_GAN: 0.783 G_L1: 0.195 D_real: 0.710 D_fake: 0.610 \n",
            "(epoch: 71, iters: 246, time: 0.068, data: 0.003) G_GAN: 0.854 G_L1: 2.137 D_real: 0.722 D_fake: 0.309 \n",
            "(epoch: 71, iters: 346, time: 0.069, data: 0.002) G_GAN: 1.078 G_L1: 0.202 D_real: 0.327 D_fake: 0.786 \n",
            "(epoch: 71, iters: 446, time: 0.064, data: 0.002) G_GAN: 0.720 G_L1: 0.396 D_real: 0.720 D_fake: 0.670 \n",
            "(epoch: 71, iters: 546, time: 0.068, data: 0.002) G_GAN: 0.955 G_L1: 0.818 D_real: 0.904 D_fake: 0.275 \n",
            "(epoch: 71, iters: 646, time: 0.068, data: 0.002) G_GAN: 0.714 G_L1: 0.830 D_real: 0.445 D_fake: 0.919 \n",
            "(epoch: 71, iters: 746, time: 0.068, data: 0.002) G_GAN: 0.686 G_L1: 0.019 D_real: 0.663 D_fake: 0.725 \n",
            "(epoch: 71, iters: 846, time: 0.068, data: 0.002) G_GAN: 0.655 G_L1: 0.496 D_real: 0.584 D_fake: 0.867 \n",
            "End of epoch 71 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 72, iters: 32, time: 0.069, data: 0.002) G_GAN: 0.533 G_L1: 0.475 D_real: 0.946 D_fake: 0.328 \n",
            "(epoch: 72, iters: 132, time: 0.068, data: 0.002) G_GAN: 0.786 G_L1: 0.281 D_real: 0.823 D_fake: 0.454 \n",
            "(epoch: 72, iters: 232, time: 0.067, data: 0.002) G_GAN: 0.716 G_L1: 0.015 D_real: 0.709 D_fake: 0.668 \n",
            "(epoch: 72, iters: 332, time: 0.068, data: 0.002) G_GAN: 0.615 G_L1: 0.612 D_real: 0.773 D_fake: 0.448 \n",
            "(epoch: 72, iters: 432, time: 0.068, data: 0.002) G_GAN: 0.472 G_L1: 0.489 D_real: 0.922 D_fake: 0.297 \n",
            "(epoch: 72, iters: 532, time: 0.068, data: 0.002) G_GAN: 1.074 G_L1: 0.633 D_real: 0.535 D_fake: 0.450 \n",
            "(epoch: 72, iters: 632, time: 0.068, data: 0.002) G_GAN: 0.716 G_L1: 0.076 D_real: 0.719 D_fake: 0.672 \n",
            "(epoch: 72, iters: 732, time: 0.068, data: 0.002) G_GAN: 1.079 G_L1: 1.103 D_real: 0.349 D_fake: 0.925 \n",
            "(epoch: 72, iters: 832, time: 0.068, data: 0.002) G_GAN: 0.659 G_L1: 0.000 D_real: 0.641 D_fake: 0.748 \n",
            "End of epoch 72 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 73, iters: 18, time: 0.066, data: 0.002) G_GAN: 0.978 G_L1: 0.554 D_real: 0.619 D_fake: 0.534 \n",
            "(epoch: 73, iters: 118, time: 0.067, data: 0.002) G_GAN: 1.215 G_L1: 0.385 D_real: 0.554 D_fake: 1.197 \n",
            "(epoch: 73, iters: 218, time: 0.065, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.725 D_fake: 0.663 \n",
            "(epoch: 73, iters: 318, time: 0.069, data: 0.002) G_GAN: 0.741 G_L1: 0.183 D_real: 0.729 D_fake: 0.657 \n",
            "(epoch: 73, iters: 418, time: 0.062, data: 0.002) G_GAN: 0.789 G_L1: 0.605 D_real: 0.951 D_fake: 0.485 \n",
            "(epoch: 73, iters: 518, time: 0.068, data: 0.002) G_GAN: 0.798 G_L1: 0.538 D_real: 0.640 D_fake: 0.555 \n",
            "(epoch: 73, iters: 618, time: 0.066, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.738 D_fake: 0.650 \n",
            "(epoch: 73, iters: 718, time: 0.069, data: 0.002) G_GAN: 0.748 G_L1: 0.306 D_real: 0.776 D_fake: 0.605 \n",
            "(epoch: 73, iters: 818, time: 0.067, data: 0.002) G_GAN: 0.653 G_L1: 0.000 D_real: 0.648 D_fake: 0.745 \n",
            "End of epoch 73 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 74, iters: 4, time: 0.068, data: 0.002) G_GAN: 0.609 G_L1: 0.108 D_real: 0.610 D_fake: 0.823 \n",
            "(epoch: 74, iters: 104, time: 0.068, data: 0.004) G_GAN: 0.595 G_L1: 0.000 D_real: 0.574 D_fake: 0.829 \n",
            "(epoch: 74, iters: 204, time: 0.068, data: 0.002) G_GAN: 0.796 G_L1: 0.494 D_real: 0.754 D_fake: 0.582 \n",
            "(epoch: 74, iters: 304, time: 0.068, data: 0.002) G_GAN: 0.838 G_L1: 0.250 D_real: 0.916 D_fake: 0.510 \n",
            "(epoch: 74, iters: 404, time: 0.068, data: 0.002) G_GAN: 0.811 G_L1: 1.437 D_real: 0.724 D_fake: 0.548 \n",
            "(epoch: 74, iters: 504, time: 0.068, data: 0.002) G_GAN: 0.694 G_L1: 0.463 D_real: 0.869 D_fake: 0.438 \n",
            "(epoch: 74, iters: 604, time: 0.068, data: 0.001) G_GAN: 0.709 G_L1: 0.137 D_real: 0.718 D_fake: 0.674 \n",
            "(epoch: 74, iters: 704, time: 0.069, data: 0.002) G_GAN: 2.079 G_L1: 1.065 D_real: 0.250 D_fake: 0.570 \n",
            "(epoch: 74, iters: 804, time: 0.069, data: 0.002) G_GAN: 0.715 G_L1: 0.080 D_real: 0.696 D_fake: 0.681 \n",
            "(epoch: 74, iters: 904, time: 0.069, data: 0.002) G_GAN: 0.660 G_L1: 0.082 D_real: 0.629 D_fake: 0.787 \n",
            "End of epoch 74 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 75, iters: 90, time: 0.067, data: 0.002) G_GAN: 0.674 G_L1: 0.806 D_real: 1.004 D_fake: 0.385 \n",
            "(epoch: 75, iters: 190, time: 0.069, data: 0.002) G_GAN: 0.616 G_L1: 0.100 D_real: 0.594 D_fake: 0.813 \n",
            "(epoch: 75, iters: 290, time: 0.069, data: 0.002) G_GAN: 0.606 G_L1: 0.834 D_real: 0.574 D_fake: 0.790 \n",
            "(epoch: 75, iters: 390, time: 0.068, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.771 D_fake: 0.622 \n",
            "(epoch: 75, iters: 490, time: 0.068, data: 0.002) G_GAN: 0.676 G_L1: 0.626 D_real: 0.689 D_fake: 0.679 \n",
            "(epoch: 75, iters: 590, time: 0.068, data: 0.002) G_GAN: 0.727 G_L1: 0.624 D_real: 0.747 D_fake: 0.649 \n",
            "saving the latest model (epoch 75, total_iters 60000)\n",
            "(epoch: 75, iters: 690, time: 0.068, data: 0.002) G_GAN: 1.631 G_L1: 1.152 D_real: 0.309 D_fake: 0.446 \n",
            "(epoch: 75, iters: 790, time: 0.069, data: 0.002) G_GAN: 0.733 G_L1: 0.130 D_real: 0.652 D_fake: 0.726 \n",
            "(epoch: 75, iters: 890, time: 0.068, data: 0.003) G_GAN: 0.704 G_L1: 0.111 D_real: 0.693 D_fake: 0.689 \n",
            "saving the model at the end of epoch 75, iters 60324\n",
            "End of epoch 75 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 76, iters: 76, time: 0.068, data: 0.002) G_GAN: 0.729 G_L1: 0.479 D_real: 0.378 D_fake: 0.924 \n",
            "(epoch: 76, iters: 176, time: 0.060, data: 0.002) G_GAN: 0.655 G_L1: 0.000 D_real: 0.645 D_fake: 0.744 \n",
            "(epoch: 76, iters: 276, time: 0.068, data: 0.002) G_GAN: 0.863 G_L1: 0.347 D_real: 0.773 D_fake: 0.608 \n",
            "(epoch: 76, iters: 376, time: 0.069, data: 0.002) G_GAN: 0.758 G_L1: 0.269 D_real: 1.169 D_fake: 0.269 \n",
            "(epoch: 76, iters: 476, time: 0.067, data: 0.002) G_GAN: 0.714 G_L1: 0.161 D_real: 0.726 D_fake: 0.667 \n",
            "(epoch: 76, iters: 576, time: 0.069, data: 0.002) G_GAN: 0.588 G_L1: 0.213 D_real: 0.549 D_fake: 0.888 \n",
            "(epoch: 76, iters: 676, time: 0.069, data: 0.002) G_GAN: 0.591 G_L1: 0.132 D_real: 0.483 D_fake: 0.960 \n",
            "(epoch: 76, iters: 776, time: 0.065, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.741 D_fake: 0.647 \n",
            "(epoch: 76, iters: 876, time: 0.063, data: 0.002) G_GAN: 0.937 G_L1: 1.186 D_real: 0.562 D_fake: 0.560 \n",
            "End of epoch 76 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 77, iters: 62, time: 0.068, data: 0.002) G_GAN: 0.600 G_L1: 0.844 D_real: 1.371 D_fake: 0.254 \n",
            "(epoch: 77, iters: 162, time: 0.069, data: 0.002) G_GAN: 0.802 G_L1: 0.440 D_real: 0.388 D_fake: 0.953 \n",
            "(epoch: 77, iters: 262, time: 0.068, data: 0.002) G_GAN: 0.696 G_L1: 0.212 D_real: 0.701 D_fake: 0.695 \n",
            "(epoch: 77, iters: 362, time: 0.069, data: 0.002) G_GAN: 0.760 G_L1: 0.007 D_real: 0.782 D_fake: 0.613 \n",
            "(epoch: 77, iters: 462, time: 0.066, data: 0.002) G_GAN: 0.811 G_L1: 0.536 D_real: 0.878 D_fake: 0.432 \n",
            "(epoch: 77, iters: 562, time: 0.068, data: 0.002) G_GAN: 0.863 G_L1: 0.710 D_real: 0.568 D_fake: 0.746 \n",
            "(epoch: 77, iters: 662, time: 0.068, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.734 D_fake: 0.654 \n",
            "(epoch: 77, iters: 762, time: 0.068, data: 0.002) G_GAN: 0.618 G_L1: 0.453 D_real: 0.599 D_fake: 0.808 \n",
            "(epoch: 77, iters: 862, time: 0.068, data: 0.002) G_GAN: 0.641 G_L1: 0.397 D_real: 0.582 D_fake: 0.847 \n",
            "End of epoch 77 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 78, iters: 48, time: 0.068, data: 0.002) G_GAN: 0.796 G_L1: 1.124 D_real: 0.552 D_fake: 0.846 \n",
            "(epoch: 78, iters: 148, time: 0.068, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.721 D_fake: 0.667 \n",
            "(epoch: 78, iters: 248, time: 0.068, data: 0.002) G_GAN: 1.089 G_L1: 0.277 D_real: 0.490 D_fake: 0.642 \n",
            "(epoch: 78, iters: 348, time: 0.068, data: 0.002) G_GAN: 1.414 G_L1: 1.556 D_real: 0.381 D_fake: 0.923 \n",
            "(epoch: 78, iters: 448, time: 0.066, data: 0.002) G_GAN: 1.019 G_L1: 0.376 D_real: 0.601 D_fake: 0.507 \n",
            "(epoch: 78, iters: 548, time: 0.068, data: 0.002) G_GAN: 0.732 G_L1: 0.520 D_real: 0.507 D_fake: 0.876 \n",
            "(epoch: 78, iters: 648, time: 0.068, data: 0.001) G_GAN: 1.014 G_L1: 1.240 D_real: 0.462 D_fake: 0.706 \n",
            "(epoch: 78, iters: 748, time: 0.068, data: 0.002) G_GAN: 0.721 G_L1: 0.110 D_real: 0.777 D_fake: 0.650 \n",
            "(epoch: 78, iters: 848, time: 0.068, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
            "End of epoch 78 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 79, iters: 34, time: 0.067, data: 0.002) G_GAN: 0.900 G_L1: 0.772 D_real: 0.646 D_fake: 0.428 \n",
            "(epoch: 79, iters: 134, time: 0.069, data: 0.002) G_GAN: 0.690 G_L1: 0.153 D_real: 0.709 D_fake: 0.701 \n",
            "(epoch: 79, iters: 234, time: 0.068, data: 0.002) G_GAN: 0.876 G_L1: 0.575 D_real: 0.631 D_fake: 0.351 \n",
            "(epoch: 79, iters: 334, time: 0.068, data: 0.002) G_GAN: 0.727 G_L1: 0.011 D_real: 0.724 D_fake: 0.667 \n",
            "(epoch: 79, iters: 434, time: 0.068, data: 0.002) G_GAN: 0.997 G_L1: 0.373 D_real: 0.423 D_fake: 0.951 \n",
            "(epoch: 79, iters: 534, time: 0.068, data: 0.001) G_GAN: 0.863 G_L1: 0.950 D_real: 0.615 D_fake: 0.600 \n",
            "(epoch: 79, iters: 634, time: 0.067, data: 0.002) G_GAN: 0.753 G_L1: 0.133 D_real: 0.883 D_fake: 0.609 \n",
            "(epoch: 79, iters: 734, time: 0.067, data: 0.002) G_GAN: 0.669 G_L1: 0.000 D_real: 0.655 D_fake: 0.733 \n",
            "(epoch: 79, iters: 834, time: 0.067, data: 0.002) G_GAN: 0.721 G_L1: 0.638 D_real: 0.702 D_fake: 0.628 \n",
            "End of epoch 79 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 80, iters: 20, time: 0.068, data: 0.002) G_GAN: 0.712 G_L1: 0.084 D_real: 0.729 D_fake: 0.662 \n",
            "(epoch: 80, iters: 120, time: 0.072, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.658 D_fake: 0.733 \n",
            "(epoch: 80, iters: 220, time: 0.063, data: 0.002) G_GAN: 0.600 G_L1: 0.079 D_real: 0.363 D_fake: 1.095 \n",
            "(epoch: 80, iters: 320, time: 0.067, data: 0.002) G_GAN: 0.767 G_L1: 0.407 D_real: 0.683 D_fake: 0.629 \n",
            "(epoch: 80, iters: 420, time: 0.068, data: 0.002) G_GAN: 0.954 G_L1: 0.181 D_real: 0.650 D_fake: 0.406 \n",
            "(epoch: 80, iters: 520, time: 0.068, data: 0.001) G_GAN: 0.687 G_L1: 0.381 D_real: 0.687 D_fake: 0.697 \n",
            "(epoch: 80, iters: 620, time: 0.068, data: 0.002) G_GAN: 1.815 G_L1: 1.015 D_real: 0.087 D_fake: 1.365 \n",
            "(epoch: 80, iters: 720, time: 0.067, data: 0.002) G_GAN: 0.656 G_L1: 0.865 D_real: 0.562 D_fake: 0.806 \n",
            "(epoch: 80, iters: 820, time: 0.065, data: 0.002) G_GAN: 0.632 G_L1: 0.829 D_real: 0.781 D_fake: 0.321 \n",
            "saving the model at the end of epoch 80, iters 64894\n",
            "End of epoch 80 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 81, iters: 6, time: 0.068, data: 0.002) G_GAN: 0.732 G_L1: 0.498 D_real: 0.496 D_fake: 0.754 \n",
            "(epoch: 81, iters: 106, time: 0.068, data: 0.002) G_GAN: 0.544 G_L1: 0.199 D_real: 0.367 D_fake: 1.014 \n",
            "saving the latest model (epoch 81, total_iters 65000)\n",
            "(epoch: 81, iters: 206, time: 0.058, data: 0.002) G_GAN: 0.670 G_L1: 0.000 D_real: 0.655 D_fake: 0.733 \n",
            "(epoch: 81, iters: 306, time: 0.060, data: 0.002) G_GAN: 0.526 G_L1: 0.509 D_real: 0.683 D_fake: 0.880 \n",
            "(epoch: 81, iters: 406, time: 0.069, data: 0.002) G_GAN: 0.782 G_L1: 0.365 D_real: 0.748 D_fake: 0.679 \n",
            "(epoch: 81, iters: 506, time: 0.067, data: 0.002) G_GAN: 0.741 G_L1: 0.034 D_real: 0.766 D_fake: 0.632 \n",
            "(epoch: 81, iters: 606, time: 0.068, data: 0.002) G_GAN: 0.702 G_L1: 0.064 D_real: 0.683 D_fake: 0.697 \n",
            "(epoch: 81, iters: 706, time: 0.068, data: 0.002) G_GAN: 0.768 G_L1: 0.298 D_real: 0.769 D_fake: 0.619 \n",
            "(epoch: 81, iters: 806, time: 0.068, data: 0.002) G_GAN: 0.718 G_L1: 0.117 D_real: 0.712 D_fake: 0.676 \n",
            "(epoch: 81, iters: 906, time: 0.068, data: 0.002) G_GAN: 0.957 G_L1: 0.016 D_real: 1.063 D_fake: 0.429 \n",
            "End of epoch 81 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 82, iters: 92, time: 0.065, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.762 D_fake: 0.630 \n",
            "(epoch: 82, iters: 192, time: 0.068, data: 0.002) G_GAN: 0.681 G_L1: 0.867 D_real: 1.316 D_fake: 0.348 \n",
            "(epoch: 82, iters: 292, time: 0.067, data: 0.002) G_GAN: 0.664 G_L1: 0.000 D_real: 0.666 D_fake: 0.723 \n",
            "(epoch: 82, iters: 392, time: 0.068, data: 0.002) G_GAN: 0.480 G_L1: 0.498 D_real: 0.401 D_fake: 1.507 \n",
            "(epoch: 82, iters: 492, time: 0.068, data: 0.002) G_GAN: 0.799 G_L1: 0.645 D_real: 0.721 D_fake: 0.577 \n",
            "(epoch: 82, iters: 592, time: 0.068, data: 0.002) G_GAN: 0.551 G_L1: 0.109 D_real: 0.561 D_fake: 0.816 \n",
            "(epoch: 82, iters: 692, time: 0.061, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.690 D_fake: 0.697 \n",
            "(epoch: 82, iters: 792, time: 0.068, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.704 D_fake: 0.683 \n",
            "(epoch: 82, iters: 892, time: 0.068, data: 0.002) G_GAN: 0.714 G_L1: 0.089 D_real: 0.694 D_fake: 0.675 \n",
            "End of epoch 82 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 83, iters: 78, time: 0.068, data: 0.002) G_GAN: 0.792 G_L1: 0.756 D_real: 0.603 D_fake: 0.450 \n",
            "(epoch: 83, iters: 178, time: 0.068, data: 0.002) G_GAN: 0.817 G_L1: 0.287 D_real: 0.786 D_fake: 0.549 \n",
            "(epoch: 83, iters: 278, time: 0.068, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.724 D_fake: 0.664 \n",
            "(epoch: 83, iters: 378, time: 0.068, data: 0.003) G_GAN: 0.699 G_L1: 0.000 D_real: 0.708 D_fake: 0.679 \n",
            "(epoch: 83, iters: 478, time: 0.068, data: 0.002) G_GAN: 0.883 G_L1: 0.893 D_real: 0.644 D_fake: 0.361 \n",
            "(epoch: 83, iters: 578, time: 0.068, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.718 D_fake: 0.670 \n",
            "(epoch: 83, iters: 678, time: 0.068, data: 0.002) G_GAN: 0.627 G_L1: 0.426 D_real: 0.608 D_fake: 0.842 \n",
            "(epoch: 83, iters: 778, time: 0.068, data: 0.002) G_GAN: 1.161 G_L1: 0.617 D_real: 0.843 D_fake: 0.136 \n",
            "(epoch: 83, iters: 878, time: 0.064, data: 0.002) G_GAN: 0.834 G_L1: 0.279 D_real: 0.451 D_fake: 0.778 \n",
            "End of epoch 83 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 84, iters: 64, time: 0.066, data: 0.002) G_GAN: 0.709 G_L1: 0.079 D_real: 0.728 D_fake: 0.653 \n",
            "(epoch: 84, iters: 164, time: 0.068, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.720 D_fake: 0.668 \n",
            "(epoch: 84, iters: 264, time: 0.068, data: 0.002) G_GAN: 0.566 G_L1: 0.929 D_real: 1.090 D_fake: 0.239 \n",
            "(epoch: 84, iters: 364, time: 0.067, data: 0.002) G_GAN: 0.768 G_L1: 0.270 D_real: 0.771 D_fake: 0.585 \n",
            "(epoch: 84, iters: 464, time: 0.068, data: 0.002) G_GAN: 0.794 G_L1: 0.476 D_real: 0.720 D_fake: 0.572 \n",
            "(epoch: 84, iters: 564, time: 0.067, data: 0.002) G_GAN: 0.648 G_L1: 0.000 D_real: 0.642 D_fake: 0.748 \n",
            "(epoch: 84, iters: 664, time: 0.068, data: 0.002) G_GAN: 0.659 G_L1: 0.065 D_real: 0.640 D_fake: 0.750 \n",
            "(epoch: 84, iters: 764, time: 0.067, data: 0.002) G_GAN: 1.015 G_L1: 0.770 D_real: 0.710 D_fake: 0.358 \n",
            "(epoch: 84, iters: 864, time: 0.068, data: 0.001) G_GAN: 0.906 G_L1: 0.377 D_real: 0.715 D_fake: 0.239 \n",
            "End of epoch 84 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 85, iters: 50, time: 0.068, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.748 D_fake: 0.648 \n",
            "(epoch: 85, iters: 150, time: 0.068, data: 0.002) G_GAN: 0.627 G_L1: 0.219 D_real: 0.595 D_fake: 0.778 \n",
            "(epoch: 85, iters: 250, time: 0.067, data: 0.002) G_GAN: 0.886 G_L1: 0.332 D_real: 0.638 D_fake: 0.586 \n",
            "(epoch: 85, iters: 350, time: 0.068, data: 0.002) G_GAN: 0.847 G_L1: 0.433 D_real: 0.989 D_fake: 0.383 \n",
            "(epoch: 85, iters: 450, time: 0.068, data: 0.002) G_GAN: 0.677 G_L1: 0.000 D_real: 0.687 D_fake: 0.700 \n",
            "(epoch: 85, iters: 550, time: 0.068, data: 0.002) G_GAN: 0.650 G_L1: 0.000 D_real: 0.651 D_fake: 0.738 \n",
            "(epoch: 85, iters: 650, time: 0.066, data: 0.002) G_GAN: 1.936 G_L1: 0.652 D_real: 0.139 D_fake: 0.501 \n",
            "(epoch: 85, iters: 750, time: 0.069, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.732 D_fake: 0.656 \n",
            "(epoch: 85, iters: 850, time: 0.068, data: 0.002) G_GAN: 0.780 G_L1: 0.362 D_real: 0.932 D_fake: 0.438 \n",
            "saving the model at the end of epoch 85, iters 69464\n",
            "End of epoch 85 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 86, iters: 36, time: 0.068, data: 0.002) G_GAN: 0.656 G_L1: 0.029 D_real: 0.627 D_fake: 0.738 \n",
            "(epoch: 86, iters: 136, time: 0.058, data: 0.002) G_GAN: 0.905 G_L1: 0.408 D_real: 0.976 D_fake: 0.459 \n",
            "(epoch: 86, iters: 236, time: 0.068, data: 0.002) G_GAN: 1.713 G_L1: 0.600 D_real: 0.246 D_fake: 0.883 \n",
            "(epoch: 86, iters: 336, time: 0.068, data: 0.002) G_GAN: 0.665 G_L1: 0.172 D_real: 0.752 D_fake: 0.740 \n",
            "(epoch: 86, iters: 436, time: 0.068, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.696 D_fake: 0.692 \n",
            "(epoch: 86, iters: 536, time: 0.068, data: 0.002) G_GAN: 0.691 G_L1: 0.442 D_real: 0.700 D_fake: 0.732 \n",
            "saving the latest model (epoch 86, total_iters 70000)\n",
            "(epoch: 86, iters: 636, time: 0.068, data: 0.002) G_GAN: 0.793 G_L1: 0.222 D_real: 0.417 D_fake: 0.885 \n",
            "(epoch: 86, iters: 736, time: 0.069, data: 0.003) G_GAN: 1.016 G_L1: 0.462 D_real: 0.632 D_fake: 0.429 \n",
            "(epoch: 86, iters: 836, time: 0.069, data: 0.002) G_GAN: 1.064 G_L1: 0.709 D_real: 0.826 D_fake: 0.345 \n",
            "End of epoch 86 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 87, iters: 22, time: 0.068, data: 0.002) G_GAN: 0.668 G_L1: 0.189 D_real: 0.658 D_fake: 0.730 \n",
            "(epoch: 87, iters: 122, time: 0.068, data: 0.002) G_GAN: 0.702 G_L1: 0.000 D_real: 0.704 D_fake: 0.683 \n",
            "(epoch: 87, iters: 222, time: 0.065, data: 0.002) G_GAN: 0.699 G_L1: 0.191 D_real: 0.605 D_fake: 0.752 \n",
            "(epoch: 87, iters: 322, time: 0.062, data: 0.002) G_GAN: 0.805 G_L1: 1.507 D_real: 0.762 D_fake: 0.637 \n",
            "(epoch: 87, iters: 422, time: 0.067, data: 0.003) G_GAN: 0.718 G_L1: 0.000 D_real: 0.728 D_fake: 0.660 \n",
            "(epoch: 87, iters: 522, time: 0.066, data: 0.002) G_GAN: 0.675 G_L1: 0.229 D_real: 0.685 D_fake: 0.707 \n",
            "(epoch: 87, iters: 622, time: 0.067, data: 0.002) G_GAN: 0.960 G_L1: 0.353 D_real: 0.363 D_fake: 0.967 \n",
            "(epoch: 87, iters: 722, time: 0.067, data: 0.002) G_GAN: 0.721 G_L1: 0.358 D_real: 0.407 D_fake: 0.855 \n",
            "(epoch: 87, iters: 822, time: 0.067, data: 0.002) G_GAN: 1.921 G_L1: 1.548 D_real: 0.243 D_fake: 0.452 \n",
            "End of epoch 87 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 88, iters: 8, time: 0.065, data: 0.002) G_GAN: 0.830 G_L1: 0.298 D_real: 0.464 D_fake: 0.806 \n",
            "(epoch: 88, iters: 108, time: 0.068, data: 0.002) G_GAN: 1.399 G_L1: 1.392 D_real: 0.248 D_fake: 0.407 \n",
            "(epoch: 88, iters: 208, time: 0.068, data: 0.002) G_GAN: 1.272 G_L1: 0.166 D_real: 0.305 D_fake: 0.391 \n",
            "(epoch: 88, iters: 308, time: 0.067, data: 0.002) G_GAN: 0.705 G_L1: 0.261 D_real: 0.695 D_fake: 0.687 \n",
            "(epoch: 88, iters: 408, time: 0.068, data: 0.002) G_GAN: 2.349 G_L1: 0.625 D_real: 0.078 D_fake: 0.467 \n",
            "(epoch: 88, iters: 508, time: 0.068, data: 0.002) G_GAN: 0.680 G_L1: 0.308 D_real: 0.702 D_fake: 0.686 \n",
            "(epoch: 88, iters: 608, time: 0.067, data: 0.002) G_GAN: 0.851 G_L1: 0.420 D_real: 0.791 D_fake: 0.320 \n",
            "(epoch: 88, iters: 708, time: 0.068, data: 0.002) G_GAN: 1.273 G_L1: 1.272 D_real: 0.366 D_fake: 0.579 \n",
            "(epoch: 88, iters: 808, time: 0.068, data: 0.002) G_GAN: 1.006 G_L1: 0.342 D_real: 0.622 D_fake: 0.393 \n",
            "(epoch: 88, iters: 908, time: 0.068, data: 0.002) G_GAN: 0.758 G_L1: 0.165 D_real: 0.775 D_fake: 0.609 \n",
            "End of epoch 88 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 89, iters: 94, time: 0.071, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.736 D_fake: 0.653 \n",
            "(epoch: 89, iters: 194, time: 0.069, data: 0.002) G_GAN: 0.589 G_L1: 0.529 D_real: 0.545 D_fake: 0.845 \n",
            "(epoch: 89, iters: 294, time: 0.067, data: 0.002) G_GAN: 0.992 G_L1: 0.431 D_real: 0.620 D_fake: 0.495 \n",
            "(epoch: 89, iters: 394, time: 0.066, data: 0.002) G_GAN: 0.759 G_L1: 0.404 D_real: 0.719 D_fake: 0.643 \n",
            "(epoch: 89, iters: 494, time: 0.066, data: 0.001) G_GAN: 1.440 G_L1: 0.771 D_real: 0.364 D_fake: 0.447 \n",
            "(epoch: 89, iters: 594, time: 0.068, data: 0.002) G_GAN: 0.747 G_L1: 0.120 D_real: 0.794 D_fake: 0.622 \n",
            "(epoch: 89, iters: 694, time: 0.067, data: 0.002) G_GAN: 0.674 G_L1: 0.114 D_real: 0.716 D_fake: 0.740 \n",
            "(epoch: 89, iters: 794, time: 0.064, data: 0.002) G_GAN: 1.281 G_L1: 0.874 D_real: 0.295 D_fake: 0.506 \n",
            "(epoch: 89, iters: 894, time: 0.067, data: 0.002) G_GAN: 0.677 G_L1: 0.125 D_real: 0.664 D_fake: 0.718 \n",
            "End of epoch 89 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 90, iters: 80, time: 0.068, data: 0.002) G_GAN: 0.845 G_L1: 0.312 D_real: 0.540 D_fake: 0.671 \n",
            "(epoch: 90, iters: 180, time: 0.069, data: 0.002) G_GAN: 0.363 G_L1: 2.103 D_real: 1.303 D_fake: 0.232 \n",
            "(epoch: 90, iters: 280, time: 0.068, data: 0.002) G_GAN: 0.595 G_L1: 0.685 D_real: 0.488 D_fake: 0.900 \n",
            "(epoch: 90, iters: 380, time: 0.068, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.686 D_fake: 0.701 \n",
            "(epoch: 90, iters: 480, time: 0.067, data: 0.002) G_GAN: 0.994 G_L1: 0.239 D_real: 0.260 D_fake: 0.750 \n",
            "(epoch: 90, iters: 580, time: 0.068, data: 0.002) G_GAN: 0.676 G_L1: 0.547 D_real: 0.680 D_fake: 0.709 \n",
            "(epoch: 90, iters: 680, time: 0.068, data: 0.002) G_GAN: 0.932 G_L1: 1.102 D_real: 0.571 D_fake: 0.322 \n",
            "(epoch: 90, iters: 780, time: 0.068, data: 0.002) G_GAN: 0.662 G_L1: 0.000 D_real: 0.649 D_fake: 0.740 \n",
            "(epoch: 90, iters: 880, time: 0.068, data: 0.002) G_GAN: 1.928 G_L1: 0.873 D_real: 0.470 D_fake: 0.400 \n",
            "saving the model at the end of epoch 90, iters 74034\n",
            "End of epoch 90 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 91, iters: 66, time: 0.068, data: 0.002) G_GAN: 0.650 G_L1: 0.000 D_real: 0.662 D_fake: 0.729 \n",
            "(epoch: 91, iters: 166, time: 0.063, data: 0.002) G_GAN: 0.675 G_L1: 0.215 D_real: 0.693 D_fake: 0.732 \n",
            "(epoch: 91, iters: 266, time: 0.061, data: 0.002) G_GAN: 0.683 G_L1: 0.409 D_real: 0.680 D_fake: 0.711 \n",
            "(epoch: 91, iters: 366, time: 0.067, data: 0.002) G_GAN: 1.272 G_L1: 1.137 D_real: 0.333 D_fake: 0.302 \n",
            "(epoch: 91, iters: 466, time: 0.063, data: 0.002) G_GAN: 0.797 G_L1: 0.449 D_real: 0.774 D_fake: 0.581 \n",
            "(epoch: 91, iters: 566, time: 0.068, data: 0.002) G_GAN: 0.523 G_L1: 0.487 D_real: 0.430 D_fake: 1.113 \n",
            "(epoch: 91, iters: 666, time: 0.068, data: 0.002) G_GAN: 0.724 G_L1: 0.368 D_real: 0.707 D_fake: 0.680 \n",
            "(epoch: 91, iters: 766, time: 0.068, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.702 D_fake: 0.686 \n",
            "(epoch: 91, iters: 866, time: 0.062, data: 0.002) G_GAN: 0.875 G_L1: 0.324 D_real: 0.646 D_fake: 0.611 \n",
            "End of epoch 91 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 92, iters: 52, time: 0.067, data: 0.002) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.690 \n",
            "saving the latest model (epoch 92, total_iters 75000)\n",
            "(epoch: 92, iters: 152, time: 0.066, data: 0.002) G_GAN: 1.016 G_L1: 0.275 D_real: 1.499 D_fake: 0.267 \n",
            "(epoch: 92, iters: 252, time: 0.068, data: 0.002) G_GAN: 0.801 G_L1: 0.155 D_real: 0.771 D_fake: 0.661 \n",
            "(epoch: 92, iters: 352, time: 0.068, data: 0.002) G_GAN: 1.027 G_L1: 0.491 D_real: 0.441 D_fake: 0.393 \n",
            "(epoch: 92, iters: 452, time: 0.064, data: 0.002) G_GAN: 0.981 G_L1: 1.354 D_real: 1.817 D_fake: 0.178 \n",
            "(epoch: 92, iters: 552, time: 0.067, data: 0.002) G_GAN: 1.903 G_L1: 0.366 D_real: 0.383 D_fake: 0.753 \n",
            "(epoch: 92, iters: 652, time: 0.068, data: 0.002) G_GAN: 0.705 G_L1: 0.231 D_real: 0.618 D_fake: 0.789 \n",
            "(epoch: 92, iters: 752, time: 0.069, data: 0.002) G_GAN: 0.891 G_L1: 0.832 D_real: 0.673 D_fake: 0.473 \n",
            "(epoch: 92, iters: 852, time: 0.068, data: 0.002) G_GAN: 1.694 G_L1: 0.924 D_real: 0.333 D_fake: 0.359 \n",
            "End of epoch 92 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 93, iters: 38, time: 0.068, data: 0.002) G_GAN: 1.053 G_L1: 0.362 D_real: 0.499 D_fake: 0.340 \n",
            "(epoch: 93, iters: 138, time: 0.068, data: 0.002) G_GAN: 0.825 G_L1: 1.062 D_real: 0.977 D_fake: 0.335 \n",
            "(epoch: 93, iters: 238, time: 0.067, data: 0.002) G_GAN: 0.781 G_L1: 1.136 D_real: 1.131 D_fake: 0.263 \n",
            "(epoch: 93, iters: 338, time: 0.068, data: 0.001) G_GAN: 0.684 G_L1: 0.049 D_real: 0.660 D_fake: 0.780 \n",
            "(epoch: 93, iters: 438, time: 0.068, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.703 D_fake: 0.684 \n",
            "(epoch: 93, iters: 538, time: 0.068, data: 0.002) G_GAN: 0.731 G_L1: 0.142 D_real: 0.732 D_fake: 0.410 \n",
            "(epoch: 93, iters: 638, time: 0.068, data: 0.002) G_GAN: 0.657 G_L1: 0.000 D_real: 0.648 D_fake: 0.742 \n",
            "(epoch: 93, iters: 738, time: 0.068, data: 0.002) G_GAN: 0.724 G_L1: 0.532 D_real: 0.947 D_fake: 0.413 \n",
            "(epoch: 93, iters: 838, time: 0.068, data: 0.002) G_GAN: 0.689 G_L1: 0.000 D_real: 0.675 D_fake: 0.713 \n",
            "End of epoch 93 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 94, iters: 24, time: 0.068, data: 0.002) G_GAN: 0.547 G_L1: 0.138 D_real: 2.364 D_fake: 0.033 \n",
            "(epoch: 94, iters: 124, time: 0.068, data: 0.002) G_GAN: 0.939 G_L1: 0.422 D_real: 0.936 D_fake: 0.412 \n",
            "(epoch: 94, iters: 224, time: 0.069, data: 0.002) G_GAN: 0.762 G_L1: 0.000 D_real: 0.795 D_fake: 0.601 \n",
            "(epoch: 94, iters: 324, time: 0.068, data: 0.002) G_GAN: 0.761 G_L1: 0.521 D_real: 0.735 D_fake: 0.644 \n",
            "(epoch: 94, iters: 424, time: 0.068, data: 0.002) G_GAN: 0.665 G_L1: 0.106 D_real: 0.638 D_fake: 0.738 \n",
            "(epoch: 94, iters: 524, time: 0.067, data: 0.002) G_GAN: 0.842 G_L1: 0.239 D_real: 0.797 D_fake: 0.538 \n",
            "(epoch: 94, iters: 624, time: 0.067, data: 0.002) G_GAN: 2.193 G_L1: 0.865 D_real: 0.056 D_fake: 0.788 \n",
            "(epoch: 94, iters: 724, time: 0.062, data: 0.002) G_GAN: 0.724 G_L1: 0.246 D_real: 0.660 D_fake: 0.495 \n",
            "(epoch: 94, iters: 824, time: 0.067, data: 0.003) G_GAN: 0.785 G_L1: 0.068 D_real: 0.730 D_fake: 0.530 \n",
            "End of epoch 94 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 95, iters: 10, time: 0.062, data: 0.002) G_GAN: 0.662 G_L1: 0.146 D_real: 0.661 D_fake: 0.756 \n",
            "(epoch: 95, iters: 110, time: 0.067, data: 0.002) G_GAN: 1.091 G_L1: 0.366 D_real: 1.190 D_fake: 0.180 \n",
            "(epoch: 95, iters: 210, time: 0.068, data: 0.002) G_GAN: 0.634 G_L1: 0.488 D_real: 1.308 D_fake: 0.317 \n",
            "(epoch: 95, iters: 310, time: 0.061, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.733 D_fake: 0.660 \n",
            "(epoch: 95, iters: 410, time: 0.068, data: 0.001) G_GAN: 0.943 G_L1: 0.139 D_real: 1.080 D_fake: 0.308 \n",
            "(epoch: 95, iters: 510, time: 0.068, data: 0.002) G_GAN: 0.859 G_L1: 0.201 D_real: 0.659 D_fake: 0.610 \n",
            "(epoch: 95, iters: 610, time: 0.068, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.734 D_fake: 0.657 \n",
            "(epoch: 95, iters: 710, time: 0.068, data: 0.002) G_GAN: 1.898 G_L1: 0.501 D_real: 0.557 D_fake: 0.089 \n",
            "(epoch: 95, iters: 810, time: 0.067, data: 0.002) G_GAN: 1.142 G_L1: 1.133 D_real: 1.208 D_fake: 0.112 \n",
            "(epoch: 95, iters: 910, time: 0.068, data: 0.002) G_GAN: 0.666 G_L1: 0.000 D_real: 0.674 D_fake: 0.714 \n",
            "saving the model at the end of epoch 95, iters 78604\n",
            "End of epoch 95 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 96, iters: 96, time: 0.068, data: 0.001) G_GAN: 0.638 G_L1: 0.035 D_real: 0.597 D_fake: 0.799 \n",
            "(epoch: 96, iters: 196, time: 0.061, data: 0.002) G_GAN: 0.730 G_L1: 0.222 D_real: 0.681 D_fake: 0.708 \n",
            "(epoch: 96, iters: 296, time: 0.068, data: 0.003) G_GAN: 0.709 G_L1: 0.001 D_real: 0.700 D_fake: 0.689 \n",
            "(epoch: 96, iters: 396, time: 0.068, data: 0.002) G_GAN: 1.021 G_L1: 0.408 D_real: 0.734 D_fake: 0.450 \n",
            "(epoch: 96, iters: 496, time: 0.068, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.722 D_fake: 0.667 \n",
            "(epoch: 96, iters: 596, time: 0.068, data: 0.002) G_GAN: 0.689 G_L1: 0.000 D_real: 0.679 D_fake: 0.711 \n",
            "(epoch: 96, iters: 696, time: 0.067, data: 0.001) G_GAN: 0.794 G_L1: 0.333 D_real: 0.656 D_fake: 0.726 \n",
            "(epoch: 96, iters: 796, time: 0.068, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.735 D_fake: 0.654 \n",
            "(epoch: 96, iters: 896, time: 0.068, data: 0.002) G_GAN: 1.695 G_L1: 1.416 D_real: 0.212 D_fake: 0.661 \n",
            "End of epoch 96 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 97, iters: 82, time: 0.069, data: 0.002) G_GAN: 1.575 G_L1: 0.286 D_real: 0.250 D_fake: 0.643 \n",
            "(epoch: 97, iters: 182, time: 0.069, data: 0.002) G_GAN: 0.630 G_L1: 0.097 D_real: 0.232 D_fake: 1.135 \n",
            "(epoch: 97, iters: 282, time: 0.068, data: 0.002) G_GAN: 2.994 G_L1: 0.375 D_real: 0.094 D_fake: 1.106 \n",
            "(epoch: 97, iters: 382, time: 0.068, data: 0.002) G_GAN: 0.888 G_L1: 0.099 D_real: 1.333 D_fake: 0.353 \n",
            "(epoch: 97, iters: 482, time: 0.066, data: 0.002) G_GAN: 2.280 G_L1: 1.080 D_real: 0.056 D_fake: 0.183 \n",
            "saving the latest model (epoch 97, total_iters 80000)\n",
            "(epoch: 97, iters: 582, time: 0.068, data: 0.002) G_GAN: 0.872 G_L1: 0.413 D_real: 0.502 D_fake: 0.877 \n",
            "(epoch: 97, iters: 682, time: 0.068, data: 0.002) G_GAN: 0.832 G_L1: 0.483 D_real: 0.736 D_fake: 0.098 \n",
            "(epoch: 97, iters: 782, time: 0.067, data: 0.002) G_GAN: 0.563 G_L1: 0.500 D_real: 0.922 D_fake: 0.159 \n",
            "(epoch: 97, iters: 882, time: 0.068, data: 0.002) G_GAN: 2.346 G_L1: 0.228 D_real: 0.119 D_fake: 0.509 \n",
            "End of epoch 97 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 98, iters: 68, time: 0.068, data: 0.001) G_GAN: 1.345 G_L1: 0.373 D_real: 0.294 D_fake: 0.595 \n",
            "(epoch: 98, iters: 168, time: 0.068, data: 0.002) G_GAN: 0.536 G_L1: 0.000 D_real: 0.547 D_fake: 0.872 \n",
            "(epoch: 98, iters: 268, time: 0.067, data: 0.002) G_GAN: 1.154 G_L1: 0.225 D_real: 2.382 D_fake: 0.064 \n",
            "(epoch: 98, iters: 368, time: 0.063, data: 0.002) G_GAN: 0.781 G_L1: 0.000 D_real: 0.824 D_fake: 0.580 \n",
            "(epoch: 98, iters: 468, time: 0.068, data: 0.002) G_GAN: 1.548 G_L1: 0.443 D_real: 0.032 D_fake: 0.661 \n",
            "(epoch: 98, iters: 568, time: 0.068, data: 0.002) G_GAN: 0.982 G_L1: 0.107 D_real: 0.088 D_fake: 1.759 \n",
            "(epoch: 98, iters: 668, time: 0.068, data: 0.002) G_GAN: 3.462 G_L1: 1.473 D_real: 0.066 D_fake: 0.044 \n",
            "(epoch: 98, iters: 768, time: 0.068, data: 0.002) G_GAN: 0.768 G_L1: 0.471 D_real: 0.815 D_fake: 0.633 \n",
            "(epoch: 98, iters: 868, time: 0.068, data: 0.002) G_GAN: 2.578 G_L1: 0.638 D_real: 0.064 D_fake: 0.146 \n",
            "End of epoch 98 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 99, iters: 54, time: 0.068, data: 0.002) G_GAN: 0.852 G_L1: 0.290 D_real: 0.738 D_fake: 0.549 \n",
            "(epoch: 99, iters: 154, time: 0.068, data: 0.002) G_GAN: 2.718 G_L1: 0.153 D_real: 0.099 D_fake: 0.071 \n",
            "(epoch: 99, iters: 254, time: 0.068, data: 0.002) G_GAN: 0.743 G_L1: 0.541 D_real: 0.685 D_fake: 0.683 \n",
            "(epoch: 99, iters: 354, time: 0.068, data: 0.002) G_GAN: 0.796 G_L1: 0.000 D_real: 0.816 D_fake: 0.592 \n",
            "(epoch: 99, iters: 454, time: 0.067, data: 0.002) G_GAN: 0.781 G_L1: 0.186 D_real: 0.585 D_fake: 0.630 \n",
            "(epoch: 99, iters: 554, time: 0.068, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.764 D_fake: 0.627 \n",
            "(epoch: 99, iters: 654, time: 0.068, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.738 D_fake: 0.654 \n",
            "(epoch: 99, iters: 754, time: 0.069, data: 0.002) G_GAN: 1.695 G_L1: 0.457 D_real: 0.083 D_fake: 1.210 \n",
            "(epoch: 99, iters: 854, time: 0.068, data: 0.002) G_GAN: 2.346 G_L1: 1.202 D_real: 0.315 D_fake: 0.066 \n",
            "End of epoch 99 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0001980\n",
            "(epoch: 100, iters: 40, time: 0.068, data: 0.002) G_GAN: 3.954 G_L1: 1.533 D_real: 0.007 D_fake: 0.026 \n",
            "(epoch: 100, iters: 140, time: 0.062, data: 0.002) G_GAN: 0.859 G_L1: 0.724 D_real: 0.606 D_fake: 0.640 \n",
            "(epoch: 100, iters: 240, time: 0.068, data: 0.002) G_GAN: 0.877 G_L1: 0.001 D_real: 0.985 D_fake: 0.473 \n",
            "(epoch: 100, iters: 340, time: 0.068, data: 0.002) G_GAN: 1.082 G_L1: 0.355 D_real: 0.543 D_fake: 0.563 \n",
            "(epoch: 100, iters: 440, time: 0.064, data: 0.002) G_GAN: 1.044 G_L1: 0.692 D_real: 0.450 D_fake: 0.501 \n",
            "(epoch: 100, iters: 540, time: 0.067, data: 0.002) G_GAN: 0.821 G_L1: 0.020 D_real: 0.757 D_fake: 0.583 \n",
            "(epoch: 100, iters: 640, time: 0.068, data: 0.002) G_GAN: 0.401 G_L1: 0.078 D_real: 1.145 D_fake: 0.510 \n",
            "(epoch: 100, iters: 740, time: 0.068, data: 0.002) G_GAN: 0.720 G_L1: 0.890 D_real: 0.959 D_fake: 0.113 \n",
            "(epoch: 100, iters: 840, time: 0.067, data: 0.002) G_GAN: 1.196 G_L1: 1.024 D_real: 0.413 D_fake: 0.804 \n",
            "saving the model at the end of epoch 100, iters 83174\n",
            "End of epoch 100 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001980 -> 0.0001960\n",
            "(epoch: 101, iters: 26, time: 0.068, data: 0.002) G_GAN: 1.319 G_L1: 0.325 D_real: 0.150 D_fake: 0.557 \n",
            "(epoch: 101, iters: 126, time: 0.069, data: 0.002) G_GAN: 3.160 G_L1: 0.286 D_real: 0.404 D_fake: 0.038 \n",
            "(epoch: 101, iters: 226, time: 0.057, data: 0.002) G_GAN: 0.660 G_L1: 0.188 D_real: 0.685 D_fake: 0.856 \n",
            "(epoch: 101, iters: 326, time: 0.068, data: 0.002) G_GAN: 0.591 G_L1: 0.000 D_real: 0.509 D_fake: 0.925 \n",
            "(epoch: 101, iters: 426, time: 0.069, data: 0.002) G_GAN: 0.678 G_L1: 0.000 D_real: 0.650 D_fake: 0.742 \n",
            "(epoch: 101, iters: 526, time: 0.066, data: 0.001) G_GAN: 0.758 G_L1: 0.937 D_real: 0.756 D_fake: 0.649 \n",
            "(epoch: 101, iters: 626, time: 0.068, data: 0.002) G_GAN: 0.784 G_L1: 0.124 D_real: 0.695 D_fake: 0.645 \n",
            "(epoch: 101, iters: 726, time: 0.067, data: 0.002) G_GAN: 1.044 G_L1: 0.563 D_real: 0.497 D_fake: 0.495 \n",
            "(epoch: 101, iters: 826, time: 0.068, data: 0.002) G_GAN: 0.808 G_L1: 0.000 D_real: 0.899 D_fake: 0.526 \n",
            "End of epoch 101 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001960 -> 0.0001941\n",
            "(epoch: 102, iters: 12, time: 0.068, data: 0.002) G_GAN: 0.583 G_L1: 0.000 D_real: 0.551 D_fake: 0.867 \n",
            "(epoch: 102, iters: 112, time: 0.062, data: 0.002) G_GAN: 2.345 G_L1: 0.710 D_real: 0.050 D_fake: 0.206 \n",
            "(epoch: 102, iters: 212, time: 0.067, data: 0.002) G_GAN: 0.789 G_L1: 0.000 D_real: 0.767 D_fake: 0.627 \n",
            "(epoch: 102, iters: 312, time: 0.067, data: 0.002) G_GAN: 0.584 G_L1: 0.221 D_real: 0.409 D_fake: 0.994 \n",
            "(epoch: 102, iters: 412, time: 0.068, data: 0.002) G_GAN: 0.653 G_L1: 0.000 D_real: 0.645 D_fake: 0.748 \n",
            "(epoch: 102, iters: 512, time: 0.067, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.726 D_fake: 0.662 \n",
            "(epoch: 102, iters: 612, time: 0.061, data: 0.002) G_GAN: 0.493 G_L1: 0.127 D_real: 0.362 D_fake: 1.382 \n",
            "(epoch: 102, iters: 712, time: 0.068, data: 0.002) G_GAN: 0.672 G_L1: 0.000 D_real: 0.668 D_fake: 0.721 \n",
            "(epoch: 102, iters: 812, time: 0.068, data: 0.002) G_GAN: 0.782 G_L1: 0.000 D_real: 0.793 D_fake: 0.608 \n",
            "(epoch: 102, iters: 912, time: 0.068, data: 0.003) G_GAN: 0.669 G_L1: 0.000 D_real: 0.657 D_fake: 0.737 \n",
            "saving the latest model (epoch 102, total_iters 85000)\n",
            "End of epoch 102 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0001941 -> 0.0001921\n",
            "(epoch: 103, iters: 98, time: 0.068, data: 0.003) G_GAN: 1.162 G_L1: 2.127 D_real: 0.925 D_fake: 0.326 \n",
            "(epoch: 103, iters: 198, time: 0.061, data: 0.002) G_GAN: 3.733 G_L1: 0.134 D_real: 0.388 D_fake: 0.027 \n",
            "(epoch: 103, iters: 298, time: 0.068, data: 0.002) G_GAN: 0.670 G_L1: 0.000 D_real: 0.654 D_fake: 0.738 \n",
            "(epoch: 103, iters: 398, time: 0.068, data: 0.002) G_GAN: 0.985 G_L1: 0.211 D_real: 0.297 D_fake: 0.859 \n",
            "(epoch: 103, iters: 498, time: 0.067, data: 0.002) G_GAN: 0.811 G_L1: 0.719 D_real: 0.372 D_fake: 0.845 \n",
            "(epoch: 103, iters: 598, time: 0.069, data: 0.002) G_GAN: 0.675 G_L1: 0.229 D_real: 0.710 D_fake: 0.680 \n",
            "(epoch: 103, iters: 698, time: 0.068, data: 0.002) G_GAN: 0.655 G_L1: 0.294 D_real: 0.636 D_fake: 0.755 \n",
            "(epoch: 103, iters: 798, time: 0.063, data: 0.002) G_GAN: 0.907 G_L1: 0.504 D_real: 1.115 D_fake: 0.338 \n",
            "(epoch: 103, iters: 898, time: 0.067, data: 0.002) G_GAN: 0.783 G_L1: 0.367 D_real: 0.563 D_fake: 0.614 \n",
            "End of epoch 103 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001921 -> 0.0001901\n",
            "(epoch: 104, iters: 84, time: 0.068, data: 0.002) G_GAN: 0.627 G_L1: 0.059 D_real: 0.433 D_fake: 0.999 \n",
            "(epoch: 104, iters: 184, time: 0.069, data: 0.002) G_GAN: 0.876 G_L1: 0.000 D_real: 0.893 D_fake: 0.528 \n",
            "(epoch: 104, iters: 284, time: 0.068, data: 0.001) G_GAN: 3.592 G_L1: 1.322 D_real: 0.122 D_fake: 0.031 \n",
            "(epoch: 104, iters: 384, time: 0.068, data: 0.002) G_GAN: 0.803 G_L1: 0.077 D_real: 0.854 D_fake: 0.523 \n",
            "(epoch: 104, iters: 484, time: 0.069, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.702 D_fake: 0.685 \n",
            "(epoch: 104, iters: 584, time: 0.068, data: 0.002) G_GAN: 1.264 G_L1: 0.238 D_real: 0.556 D_fake: 0.337 \n",
            "(epoch: 104, iters: 684, time: 0.068, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.684 D_fake: 0.708 \n",
            "(epoch: 104, iters: 784, time: 0.066, data: 0.002) G_GAN: 1.138 G_L1: 0.282 D_real: 0.192 D_fake: 0.777 \n",
            "(epoch: 104, iters: 884, time: 0.069, data: 0.002) G_GAN: 2.215 G_L1: 0.197 D_real: 0.133 D_fake: 0.193 \n",
            "End of epoch 104 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001901 -> 0.0001881\n",
            "(epoch: 105, iters: 70, time: 0.069, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.722 D_fake: 0.668 \n",
            "(epoch: 105, iters: 170, time: 0.067, data: 0.002) G_GAN: 1.608 G_L1: 0.543 D_real: 0.312 D_fake: 0.277 \n",
            "(epoch: 105, iters: 270, time: 0.062, data: 0.002) G_GAN: 1.088 G_L1: 0.288 D_real: 0.419 D_fake: 0.491 \n",
            "(epoch: 105, iters: 370, time: 0.067, data: 0.002) G_GAN: 0.672 G_L1: 0.000 D_real: 0.666 D_fake: 0.727 \n",
            "(epoch: 105, iters: 470, time: 0.067, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.731 D_fake: 0.659 \n",
            "(epoch: 105, iters: 570, time: 0.069, data: 0.002) G_GAN: 0.723 G_L1: 0.103 D_real: 0.190 D_fake: 0.855 \n",
            "(epoch: 105, iters: 670, time: 0.068, data: 0.002) G_GAN: 1.258 G_L1: 0.205 D_real: 1.151 D_fake: 0.050 \n",
            "(epoch: 105, iters: 770, time: 0.069, data: 0.001) G_GAN: 2.168 G_L1: 0.127 D_real: 0.379 D_fake: 0.128 \n",
            "(epoch: 105, iters: 870, time: 0.068, data: 0.002) G_GAN: 3.433 G_L1: 0.414 D_real: 0.105 D_fake: 0.039 \n",
            "saving the model at the end of epoch 105, iters 87744\n",
            "End of epoch 105 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001881 -> 0.0001861\n",
            "(epoch: 106, iters: 56, time: 0.068, data: 0.002) G_GAN: 2.188 G_L1: 0.027 D_real: 0.295 D_fake: 0.085 \n",
            "(epoch: 106, iters: 156, time: 0.055, data: 0.002) G_GAN: 3.635 G_L1: 1.858 D_real: 0.114 D_fake: 0.038 \n",
            "(epoch: 106, iters: 256, time: 0.066, data: 0.002) G_GAN: 0.862 G_L1: 0.089 D_real: 0.617 D_fake: 0.987 \n",
            "(epoch: 106, iters: 356, time: 0.069, data: 0.002) G_GAN: 4.138 G_L1: 0.155 D_real: 0.243 D_fake: 0.012 \n",
            "(epoch: 106, iters: 456, time: 0.068, data: 0.002) G_GAN: 2.318 G_L1: 0.659 D_real: 0.258 D_fake: 0.435 \n",
            "(epoch: 106, iters: 556, time: 0.068, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.661 D_fake: 0.729 \n",
            "(epoch: 106, iters: 656, time: 0.068, data: 0.002) G_GAN: 2.885 G_L1: 0.403 D_real: 0.021 D_fake: 0.104 \n",
            "(epoch: 106, iters: 756, time: 0.068, data: 0.002) G_GAN: 2.827 G_L1: 0.587 D_real: 0.536 D_fake: 0.030 \n",
            "(epoch: 106, iters: 856, time: 0.068, data: 0.002) G_GAN: 2.623 G_L1: 0.904 D_real: 0.066 D_fake: 0.104 \n",
            "End of epoch 106 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001861 -> 0.0001842\n",
            "(epoch: 107, iters: 42, time: 0.067, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.704 D_fake: 0.686 \n",
            "(epoch: 107, iters: 142, time: 0.067, data: 0.002) G_GAN: 2.779 G_L1: 0.461 D_real: 0.027 D_fake: 0.201 \n",
            "(epoch: 107, iters: 242, time: 0.069, data: 0.002) G_GAN: 3.293 G_L1: 0.628 D_real: 0.043 D_fake: 0.060 \n",
            "(epoch: 107, iters: 342, time: 0.064, data: 0.002) G_GAN: 0.626 G_L1: 0.020 D_real: 0.392 D_fake: 0.975 \n",
            "(epoch: 107, iters: 442, time: 0.068, data: 0.002) G_GAN: 3.218 G_L1: 0.985 D_real: 0.061 D_fake: 0.060 \n",
            "(epoch: 107, iters: 542, time: 0.068, data: 0.002) G_GAN: 2.811 G_L1: 1.192 D_real: 0.080 D_fake: 0.134 \n",
            "(epoch: 107, iters: 642, time: 0.064, data: 0.002) G_GAN: 0.829 G_L1: 0.000 D_real: 1.004 D_fake: 0.467 \n",
            "(epoch: 107, iters: 742, time: 0.067, data: 0.002) G_GAN: 0.677 G_L1: 0.000 D_real: 0.684 D_fake: 0.718 \n",
            "(epoch: 107, iters: 842, time: 0.068, data: 0.002) G_GAN: 1.240 G_L1: 0.189 D_real: 1.769 D_fake: 0.186 \n",
            "End of epoch 107 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001842 -> 0.0001822\n",
            "(epoch: 108, iters: 28, time: 0.068, data: 0.002) G_GAN: 2.533 G_L1: 1.197 D_real: 0.191 D_fake: 0.130 \n",
            "(epoch: 108, iters: 128, time: 0.068, data: 0.002) G_GAN: 2.459 G_L1: 0.618 D_real: 0.023 D_fake: 0.841 \n",
            "(epoch: 108, iters: 228, time: 0.067, data: 0.001) G_GAN: 0.684 G_L1: 0.000 D_real: 0.698 D_fake: 0.689 \n",
            "(epoch: 108, iters: 328, time: 0.054, data: 0.001) G_GAN: 1.192 G_L1: 0.762 D_real: 0.146 D_fake: 0.666 \n",
            "(epoch: 108, iters: 428, time: 0.068, data: 0.001) G_GAN: 3.185 G_L1: 0.183 D_real: 0.011 D_fake: 0.101 \n",
            "saving the latest model (epoch 108, total_iters 90000)\n",
            "(epoch: 108, iters: 528, time: 0.063, data: 0.002) G_GAN: 5.528 G_L1: 0.816 D_real: 0.009 D_fake: 0.007 \n",
            "(epoch: 108, iters: 628, time: 0.058, data: 0.002) G_GAN: 3.771 G_L1: 0.401 D_real: 0.048 D_fake: 0.025 \n",
            "(epoch: 108, iters: 728, time: 0.067, data: 0.001) G_GAN: 0.617 G_L1: 0.000 D_real: 0.634 D_fake: 0.758 \n",
            "(epoch: 108, iters: 828, time: 0.068, data: 0.002) G_GAN: 0.961 G_L1: 0.000 D_real: 0.962 D_fake: 0.497 \n",
            "End of epoch 108 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0001822 -> 0.0001802\n",
            "(epoch: 109, iters: 14, time: 0.068, data: 0.002) G_GAN: 2.072 G_L1: 0.650 D_real: 0.075 D_fake: 0.258 \n",
            "(epoch: 109, iters: 114, time: 0.068, data: 0.002) G_GAN: 0.649 G_L1: 0.000 D_real: 0.631 D_fake: 0.762 \n",
            "(epoch: 109, iters: 214, time: 0.068, data: 0.002) G_GAN: 2.864 G_L1: 0.230 D_real: 0.435 D_fake: 0.114 \n",
            "(epoch: 109, iters: 314, time: 0.068, data: 0.002) G_GAN: 1.915 G_L1: 0.870 D_real: 0.138 D_fake: 0.120 \n",
            "(epoch: 109, iters: 414, time: 0.067, data: 0.002) G_GAN: 2.704 G_L1: 0.145 D_real: 0.065 D_fake: 0.161 \n",
            "(epoch: 109, iters: 514, time: 0.068, data: 0.002) G_GAN: 2.683 G_L1: 0.131 D_real: 0.019 D_fake: 0.244 \n",
            "(epoch: 109, iters: 614, time: 0.068, data: 0.002) G_GAN: 3.718 G_L1: 0.435 D_real: 0.016 D_fake: 0.040 \n",
            "(epoch: 109, iters: 714, time: 0.068, data: 0.002) G_GAN: 2.813 G_L1: 0.590 D_real: 0.042 D_fake: 0.127 \n",
            "(epoch: 109, iters: 814, time: 0.068, data: 0.002) G_GAN: 0.617 G_L1: 0.000 D_real: 0.548 D_fake: 0.866 \n",
            "(epoch: 109, iters: 914, time: 0.068, data: 0.002) G_GAN: 3.310 G_L1: 1.148 D_real: 0.007 D_fake: 0.042 \n",
            "End of epoch 109 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001802 -> 0.0001782\n",
            "(epoch: 110, iters: 100, time: 0.068, data: 0.211) G_GAN: 3.180 G_L1: 1.784 D_real: 0.103 D_fake: 0.096 \n",
            "(epoch: 110, iters: 200, time: 0.068, data: 0.003) G_GAN: 5.617 G_L1: 0.623 D_real: 0.109 D_fake: 0.006 \n",
            "(epoch: 110, iters: 300, time: 0.068, data: 0.002) G_GAN: 3.425 G_L1: 0.276 D_real: 0.012 D_fake: 0.084 \n",
            "(epoch: 110, iters: 400, time: 0.068, data: 0.002) G_GAN: 5.542 G_L1: 0.810 D_real: 0.028 D_fake: 0.008 \n",
            "(epoch: 110, iters: 500, time: 0.067, data: 0.002) G_GAN: 2.919 G_L1: 0.069 D_real: 0.414 D_fake: 0.336 \n",
            "(epoch: 110, iters: 600, time: 0.063, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.699 D_fake: 0.690 \n",
            "(epoch: 110, iters: 700, time: 0.068, data: 0.002) G_GAN: 0.535 G_L1: 1.794 D_real: 1.024 D_fake: 0.076 \n",
            "(epoch: 110, iters: 800, time: 0.068, data: 0.001) G_GAN: 4.613 G_L1: 1.146 D_real: 0.007 D_fake: 0.017 \n",
            "(epoch: 110, iters: 900, time: 0.063, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.735 D_fake: 0.672 \n",
            "saving the model at the end of epoch 110, iters 92314\n",
            "End of epoch 110 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001782 -> 0.0001762\n",
            "(epoch: 111, iters: 86, time: 0.068, data: 0.001) G_GAN: 2.407 G_L1: 0.360 D_real: 0.043 D_fake: 0.219 \n",
            "(epoch: 111, iters: 186, time: 0.059, data: 0.002) G_GAN: 5.486 G_L1: 0.436 D_real: 0.019 D_fake: 0.006 \n",
            "(epoch: 111, iters: 286, time: 0.068, data: 0.002) G_GAN: 0.766 G_L1: 0.061 D_real: 0.680 D_fake: 0.569 \n",
            "(epoch: 111, iters: 386, time: 0.069, data: 0.002) G_GAN: 0.685 G_L1: 0.000 D_real: 0.649 D_fake: 0.741 \n",
            "(epoch: 111, iters: 486, time: 0.068, data: 0.002) G_GAN: 2.779 G_L1: 0.251 D_real: 0.126 D_fake: 0.105 \n",
            "(epoch: 111, iters: 586, time: 0.068, data: 0.002) G_GAN: 4.365 G_L1: 1.223 D_real: 0.022 D_fake: 0.031 \n",
            "(epoch: 111, iters: 686, time: 0.068, data: 0.002) G_GAN: 5.409 G_L1: 0.066 D_real: 0.053 D_fake: 0.834 \n",
            "(epoch: 111, iters: 786, time: 0.068, data: 0.002) G_GAN: 2.810 G_L1: 0.224 D_real: 0.040 D_fake: 0.119 \n",
            "(epoch: 111, iters: 886, time: 0.068, data: 0.002) G_GAN: 4.198 G_L1: 0.397 D_real: 0.019 D_fake: 0.078 \n",
            "End of epoch 111 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001762 -> 0.0001743\n",
            "(epoch: 112, iters: 72, time: 0.068, data: 0.002) G_GAN: 2.317 G_L1: 0.921 D_real: 0.089 D_fake: 0.859 \n",
            "(epoch: 112, iters: 172, time: 0.068, data: 0.002) G_GAN: 4.582 G_L1: 0.337 D_real: 0.029 D_fake: 0.012 \n",
            "(epoch: 112, iters: 272, time: 0.068, data: 0.002) G_GAN: 5.269 G_L1: 1.279 D_real: 0.016 D_fake: 0.010 \n",
            "(epoch: 112, iters: 372, time: 0.067, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.704 D_fake: 0.685 \n",
            "(epoch: 112, iters: 472, time: 0.068, data: 0.002) G_GAN: 3.328 G_L1: 0.671 D_real: 0.308 D_fake: 0.070 \n",
            "(epoch: 112, iters: 572, time: 0.068, data: 0.002) G_GAN: 3.291 G_L1: 0.797 D_real: 0.168 D_fake: 0.047 \n",
            "(epoch: 112, iters: 672, time: 0.067, data: 0.002) G_GAN: 0.828 G_L1: 0.336 D_real: 1.812 D_fake: 0.118 \n",
            "(epoch: 112, iters: 772, time: 0.068, data: 0.002) G_GAN: 0.696 G_L1: 0.001 D_real: 0.715 D_fake: 0.673 \n",
            "(epoch: 112, iters: 872, time: 0.068, data: 0.002) G_GAN: 4.652 G_L1: 1.110 D_real: 0.026 D_fake: 0.019 \n",
            "End of epoch 112 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001743 -> 0.0001723\n",
            "(epoch: 113, iters: 58, time: 0.067, data: 0.002) G_GAN: 1.384 G_L1: 0.547 D_real: 1.835 D_fake: 0.487 \n",
            "(epoch: 113, iters: 158, time: 0.067, data: 0.002) G_GAN: 0.762 G_L1: 0.294 D_real: 0.696 D_fake: 0.735 \n",
            "(epoch: 113, iters: 258, time: 0.068, data: 0.002) G_GAN: 0.861 G_L1: 0.070 D_real: 0.893 D_fake: 0.581 \n",
            "(epoch: 113, iters: 358, time: 0.068, data: 0.002) G_GAN: 0.708 G_L1: 1.199 D_real: 0.779 D_fake: 0.737 \n",
            "(epoch: 113, iters: 458, time: 0.067, data: 0.002) G_GAN: 0.784 G_L1: 0.921 D_real: 0.812 D_fake: 0.642 \n",
            "(epoch: 113, iters: 558, time: 0.066, data: 0.002) G_GAN: 0.727 G_L1: 0.489 D_real: 0.770 D_fake: 0.667 \n",
            "(epoch: 113, iters: 658, time: 0.067, data: 0.002) G_GAN: 0.669 G_L1: 0.000 D_real: 0.683 D_fake: 0.705 \n",
            "(epoch: 113, iters: 758, time: 0.068, data: 0.002) G_GAN: 0.771 G_L1: 0.465 D_real: 0.817 D_fake: 0.627 \n",
            "(epoch: 113, iters: 858, time: 0.068, data: 0.002) G_GAN: 0.667 G_L1: 0.000 D_real: 0.654 D_fake: 0.734 \n",
            "saving the latest model (epoch 113, total_iters 95000)\n",
            "End of epoch 113 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0001723 -> 0.0001703\n",
            "(epoch: 114, iters: 44, time: 0.064, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.678 D_fake: 0.710 \n",
            "(epoch: 114, iters: 144, time: 0.068, data: 0.002) G_GAN: 0.805 G_L1: 0.486 D_real: 0.838 D_fake: 0.605 \n",
            "(epoch: 114, iters: 244, time: 0.067, data: 0.002) G_GAN: 0.724 G_L1: 0.083 D_real: 0.746 D_fake: 0.657 \n",
            "(epoch: 114, iters: 344, time: 0.068, data: 0.004) G_GAN: 0.685 G_L1: 0.195 D_real: 0.653 D_fake: 0.757 \n",
            "(epoch: 114, iters: 444, time: 0.068, data: 0.002) G_GAN: 0.761 G_L1: 0.473 D_real: 0.806 D_fake: 0.607 \n",
            "(epoch: 114, iters: 544, time: 0.067, data: 0.001) G_GAN: 0.687 G_L1: 0.386 D_real: 0.685 D_fake: 0.727 \n",
            "(epoch: 114, iters: 644, time: 0.068, data: 0.002) G_GAN: 0.741 G_L1: 0.328 D_real: 0.795 D_fake: 0.609 \n",
            "(epoch: 114, iters: 744, time: 0.068, data: 0.002) G_GAN: 0.700 G_L1: 0.122 D_real: 0.700 D_fake: 0.698 \n",
            "(epoch: 114, iters: 844, time: 0.068, data: 0.002) G_GAN: 0.665 G_L1: 0.706 D_real: 0.594 D_fake: 0.784 \n",
            "End of epoch 114 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001703 -> 0.0001683\n",
            "(epoch: 115, iters: 30, time: 0.067, data: 0.002) G_GAN: 0.725 G_L1: 0.741 D_real: 0.732 D_fake: 0.656 \n",
            "(epoch: 115, iters: 130, time: 0.068, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.696 D_fake: 0.691 \n",
            "(epoch: 115, iters: 230, time: 0.068, data: 0.002) G_GAN: 0.677 G_L1: 0.770 D_real: 0.687 D_fake: 0.702 \n",
            "(epoch: 115, iters: 330, time: 0.068, data: 0.003) G_GAN: 0.691 G_L1: 0.254 D_real: 0.604 D_fake: 0.796 \n",
            "(epoch: 115, iters: 430, time: 0.068, data: 0.002) G_GAN: 0.779 G_L1: 0.349 D_real: 0.898 D_fake: 0.552 \n",
            "(epoch: 115, iters: 530, time: 0.068, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.719 D_fake: 0.670 \n",
            "(epoch: 115, iters: 630, time: 0.068, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.733 D_fake: 0.656 \n",
            "(epoch: 115, iters: 730, time: 0.061, data: 0.001) G_GAN: 0.721 G_L1: 0.301 D_real: 0.748 D_fake: 0.628 \n",
            "(epoch: 115, iters: 830, time: 0.069, data: 0.002) G_GAN: 0.848 G_L1: 3.551 D_real: 0.501 D_fake: 0.664 \n",
            "saving the model at the end of epoch 115, iters 96884\n",
            "End of epoch 115 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001683 -> 0.0001663\n",
            "(epoch: 116, iters: 16, time: 0.068, data: 0.002) G_GAN: 0.748 G_L1: 0.073 D_real: 0.800 D_fake: 0.594 \n",
            "(epoch: 116, iters: 116, time: 0.067, data: 0.002) G_GAN: 0.712 G_L1: 0.243 D_real: 0.658 D_fake: 0.719 \n",
            "(epoch: 116, iters: 216, time: 0.059, data: 0.002) G_GAN: 2.017 G_L1: 0.528 D_real: 0.278 D_fake: 0.405 \n",
            "(epoch: 116, iters: 316, time: 0.068, data: 0.002) G_GAN: 2.447 G_L1: 0.342 D_real: 0.382 D_fake: 0.777 \n",
            "(epoch: 116, iters: 416, time: 0.065, data: 0.002) G_GAN: 3.350 G_L1: 1.734 D_real: 0.149 D_fake: 0.038 \n",
            "(epoch: 116, iters: 516, time: 0.067, data: 0.003) G_GAN: 2.602 G_L1: 0.634 D_real: 0.073 D_fake: 0.251 \n",
            "(epoch: 116, iters: 616, time: 0.068, data: 0.002) G_GAN: 3.040 G_L1: 0.884 D_real: 0.045 D_fake: 0.136 \n",
            "(epoch: 116, iters: 716, time: 0.068, data: 0.001) G_GAN: 3.857 G_L1: 0.842 D_real: 0.015 D_fake: 0.054 \n",
            "(epoch: 116, iters: 816, time: 0.058, data: 0.002) G_GAN: 0.645 G_L1: 0.000 D_real: 0.631 D_fake: 0.762 \n",
            "End of epoch 116 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001663 -> 0.0001644\n",
            "(epoch: 117, iters: 2, time: 0.055, data: 0.002) G_GAN: 0.717 G_L1: 0.245 D_real: 0.634 D_fake: 1.199 \n",
            "(epoch: 117, iters: 102, time: 0.067, data: 0.001) G_GAN: 3.167 G_L1: 1.510 D_real: 0.005 D_fake: 0.145 \n",
            "(epoch: 117, iters: 202, time: 0.069, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.713 D_fake: 0.674 \n",
            "(epoch: 117, iters: 302, time: 0.065, data: 0.002) G_GAN: 3.397 G_L1: 0.484 D_real: 0.117 D_fake: 0.064 \n",
            "(epoch: 117, iters: 402, time: 0.068, data: 0.002) G_GAN: 0.687 G_L1: 0.002 D_real: 0.580 D_fake: 0.848 \n",
            "(epoch: 117, iters: 502, time: 0.068, data: 0.002) G_GAN: 3.103 G_L1: 0.200 D_real: 0.046 D_fake: 0.143 \n",
            "(epoch: 117, iters: 602, time: 0.068, data: 0.002) G_GAN: 2.643 G_L1: 0.872 D_real: 0.035 D_fake: 0.146 \n",
            "(epoch: 117, iters: 702, time: 0.068, data: 0.002) G_GAN: 1.837 G_L1: 0.131 D_real: 0.669 D_fake: 0.093 \n",
            "(epoch: 117, iters: 802, time: 0.068, data: 0.002) G_GAN: 2.999 G_L1: 0.269 D_real: 0.103 D_fake: 0.275 \n",
            "(epoch: 117, iters: 902, time: 0.068, data: 0.002) G_GAN: 3.902 G_L1: 1.029 D_real: 0.036 D_fake: 0.035 \n",
            "End of epoch 117 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001644 -> 0.0001624\n",
            "(epoch: 118, iters: 88, time: 0.068, data: 0.002) G_GAN: 3.321 G_L1: 0.663 D_real: 0.027 D_fake: 0.060 \n",
            "(epoch: 118, iters: 188, time: 0.068, data: 0.003) G_GAN: 0.918 G_L1: 0.016 D_real: 1.410 D_fake: 0.556 \n",
            "(epoch: 118, iters: 288, time: 0.067, data: 0.002) G_GAN: 3.600 G_L1: 0.601 D_real: 0.006 D_fake: 0.045 \n",
            "(epoch: 118, iters: 388, time: 0.068, data: 0.002) G_GAN: 2.569 G_L1: 0.344 D_real: 0.025 D_fake: 0.141 \n",
            "(epoch: 118, iters: 488, time: 0.069, data: 0.002) G_GAN: 0.614 G_L1: 0.000 D_real: 0.577 D_fake: 0.831 \n",
            "(epoch: 118, iters: 588, time: 0.068, data: 0.002) G_GAN: 4.377 G_L1: 1.308 D_real: 0.112 D_fake: 0.013 \n",
            "(epoch: 118, iters: 688, time: 0.068, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.717 D_fake: 0.678 \n",
            "(epoch: 118, iters: 788, time: 0.068, data: 0.002) G_GAN: 2.299 G_L1: 0.336 D_real: 0.029 D_fake: 0.156 \n",
            "(epoch: 118, iters: 888, time: 0.068, data: 0.002) G_GAN: 2.361 G_L1: 0.086 D_real: 0.098 D_fake: 0.560 \n",
            "End of epoch 118 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001624 -> 0.0001604\n",
            "(epoch: 119, iters: 74, time: 0.068, data: 0.002) G_GAN: 3.977 G_L1: 2.075 D_real: 0.016 D_fake: 0.029 \n",
            "(epoch: 119, iters: 174, time: 0.068, data: 0.002) G_GAN: 6.565 G_L1: 0.306 D_real: 0.002 D_fake: 0.003 \n",
            "(epoch: 119, iters: 274, time: 0.068, data: 0.003) G_GAN: 2.586 G_L1: 0.086 D_real: 0.161 D_fake: 0.086 \n",
            "(epoch: 119, iters: 374, time: 0.067, data: 0.002) G_GAN: 2.101 G_L1: 0.028 D_real: 0.208 D_fake: 0.230 \n",
            "saving the latest model (epoch 119, total_iters 100000)\n",
            "(epoch: 119, iters: 474, time: 0.068, data: 0.002) G_GAN: 3.882 G_L1: 0.797 D_real: 0.021 D_fake: 0.032 \n",
            "(epoch: 119, iters: 574, time: 0.064, data: 0.002) G_GAN: 2.371 G_L1: 0.732 D_real: 0.096 D_fake: 0.268 \n",
            "(epoch: 119, iters: 674, time: 0.068, data: 0.002) G_GAN: 4.222 G_L1: 1.561 D_real: 0.030 D_fake: 0.056 \n",
            "(epoch: 119, iters: 774, time: 0.070, data: 0.002) G_GAN: 4.092 G_L1: 0.814 D_real: 1.235 D_fake: 0.005 \n",
            "(epoch: 119, iters: 874, time: 0.064, data: 0.002) G_GAN: 2.802 G_L1: 0.161 D_real: 0.116 D_fake: 0.423 \n",
            "End of epoch 119 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0001604 -> 0.0001584\n",
            "(epoch: 120, iters: 60, time: 0.062, data: 0.002) G_GAN: 4.515 G_L1: 1.831 D_real: 0.009 D_fake: 0.021 \n",
            "(epoch: 120, iters: 160, time: 0.067, data: 0.002) G_GAN: 5.161 G_L1: 0.520 D_real: 0.016 D_fake: 0.008 \n",
            "(epoch: 120, iters: 260, time: 0.067, data: 0.002) G_GAN: 4.447 G_L1: 0.895 D_real: 0.037 D_fake: 0.019 \n",
            "(epoch: 120, iters: 360, time: 0.068, data: 0.002) G_GAN: 3.743 G_L1: 0.091 D_real: 0.072 D_fake: 1.209 \n",
            "(epoch: 120, iters: 460, time: 0.068, data: 0.002) G_GAN: 5.679 G_L1: 1.146 D_real: 0.848 D_fake: 0.005 \n",
            "(epoch: 120, iters: 560, time: 0.069, data: 0.002) G_GAN: 5.360 G_L1: 0.218 D_real: 0.022 D_fake: 0.006 \n",
            "(epoch: 120, iters: 660, time: 0.068, data: 0.002) G_GAN: 3.113 G_L1: 1.302 D_real: 0.055 D_fake: 0.057 \n",
            "(epoch: 120, iters: 760, time: 0.067, data: 0.002) G_GAN: 1.996 G_L1: 0.305 D_real: 0.107 D_fake: 1.542 \n",
            "(epoch: 120, iters: 860, time: 0.066, data: 0.002) G_GAN: 0.673 G_L1: 0.001 D_real: 0.661 D_fake: 0.728 \n",
            "saving the model at the end of epoch 120, iters 101454\n",
            "End of epoch 120 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001584 -> 0.0001564\n",
            "(epoch: 121, iters: 46, time: 0.068, data: 0.002) G_GAN: 4.359 G_L1: 0.990 D_real: 0.006 D_fake: 0.018 \n",
            "(epoch: 121, iters: 146, time: 0.069, data: 0.002) G_GAN: 0.750 G_L1: 0.004 D_real: 0.775 D_fake: 0.629 \n",
            "(epoch: 121, iters: 246, time: 0.068, data: 0.002) G_GAN: 0.772 G_L1: 0.503 D_real: 1.856 D_fake: 0.825 \n",
            "(epoch: 121, iters: 346, time: 0.068, data: 0.002) G_GAN: 2.158 G_L1: 0.386 D_real: 0.123 D_fake: 0.209 \n",
            "(epoch: 121, iters: 446, time: 0.068, data: 0.002) G_GAN: 4.996 G_L1: 0.922 D_real: 0.019 D_fake: 0.014 \n",
            "(epoch: 121, iters: 546, time: 0.069, data: 0.002) G_GAN: 2.911 G_L1: 0.518 D_real: 0.021 D_fake: 0.090 \n",
            "(epoch: 121, iters: 646, time: 0.066, data: 0.002) G_GAN: 4.604 G_L1: 0.968 D_real: 0.006 D_fake: 0.015 \n",
            "(epoch: 121, iters: 746, time: 0.068, data: 0.002) G_GAN: 6.680 G_L1: 0.423 D_real: 0.017 D_fake: 0.003 \n",
            "(epoch: 121, iters: 846, time: 0.068, data: 0.002) G_GAN: 4.642 G_L1: 0.645 D_real: 0.013 D_fake: 0.018 \n",
            "End of epoch 121 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001564 -> 0.0001545\n",
            "(epoch: 122, iters: 32, time: 0.067, data: 0.001) G_GAN: 1.967 G_L1: 1.105 D_real: 0.013 D_fake: 0.450 \n",
            "(epoch: 122, iters: 132, time: 0.068, data: 0.002) G_GAN: 4.963 G_L1: 0.118 D_real: 0.017 D_fake: 0.012 \n",
            "(epoch: 122, iters: 232, time: 0.068, data: 0.002) G_GAN: 3.584 G_L1: 0.148 D_real: 0.033 D_fake: 0.037 \n",
            "(epoch: 122, iters: 332, time: 0.068, data: 0.001) G_GAN: 4.867 G_L1: 0.479 D_real: 0.009 D_fake: 0.018 \n",
            "(epoch: 122, iters: 432, time: 0.058, data: 0.002) G_GAN: 1.356 G_L1: 0.557 D_real: 0.011 D_fake: 2.371 \n",
            "(epoch: 122, iters: 532, time: 0.069, data: 0.002) G_GAN: 7.545 G_L1: 1.306 D_real: 0.005 D_fake: 0.001 \n",
            "(epoch: 122, iters: 632, time: 0.068, data: 0.002) G_GAN: 5.628 G_L1: 0.415 D_real: 0.008 D_fake: 0.005 \n",
            "(epoch: 122, iters: 732, time: 0.068, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.716 D_fake: 0.677 \n",
            "(epoch: 122, iters: 832, time: 0.065, data: 0.002) G_GAN: 3.609 G_L1: 0.495 D_real: 0.081 D_fake: 0.038 \n",
            "End of epoch 122 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001545 -> 0.0001525\n",
            "(epoch: 123, iters: 18, time: 0.068, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.782 D_fake: 0.612 \n",
            "(epoch: 123, iters: 118, time: 0.068, data: 0.002) G_GAN: 4.590 G_L1: 0.452 D_real: 0.064 D_fake: 0.014 \n",
            "(epoch: 123, iters: 218, time: 0.068, data: 0.002) G_GAN: 5.975 G_L1: 0.210 D_real: 0.007 D_fake: 0.006 \n",
            "(epoch: 123, iters: 318, time: 0.064, data: 0.002) G_GAN: 2.768 G_L1: 0.199 D_real: 0.045 D_fake: 0.102 \n",
            "(epoch: 123, iters: 418, time: 0.068, data: 0.002) G_GAN: 2.999 G_L1: 0.464 D_real: 0.008 D_fake: 0.122 \n",
            "(epoch: 123, iters: 518, time: 0.062, data: 0.002) G_GAN: 3.762 G_L1: 0.163 D_real: 0.005 D_fake: 0.046 \n",
            "(epoch: 123, iters: 618, time: 0.066, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.773 D_fake: 0.620 \n",
            "(epoch: 123, iters: 718, time: 0.068, data: 0.002) G_GAN: 2.060 G_L1: 1.187 D_real: 0.052 D_fake: 0.291 \n",
            "(epoch: 123, iters: 818, time: 0.068, data: 0.002) G_GAN: 4.353 G_L1: 4.052 D_real: 0.005 D_fake: 0.026 \n",
            "End of epoch 123 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001525 -> 0.0001505\n",
            "(epoch: 124, iters: 4, time: 0.068, data: 0.002) G_GAN: 3.013 G_L1: 0.843 D_real: 0.063 D_fake: 0.129 \n",
            "(epoch: 124, iters: 104, time: 0.067, data: 0.002) G_GAN: 0.686 G_L1: 0.000 D_real: 0.676 D_fake: 0.711 \n",
            "(epoch: 124, iters: 204, time: 0.067, data: 0.002) G_GAN: 4.912 G_L1: 0.711 D_real: 0.146 D_fake: 0.011 \n",
            "(epoch: 124, iters: 304, time: 0.067, data: 0.002) G_GAN: 6.685 G_L1: 1.222 D_real: 0.036 D_fake: 0.003 \n",
            "(epoch: 124, iters: 404, time: 0.067, data: 0.002) G_GAN: 4.355 G_L1: 1.101 D_real: 0.103 D_fake: 0.017 \n",
            "(epoch: 124, iters: 504, time: 0.064, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.800 D_fake: 0.612 \n",
            "(epoch: 124, iters: 604, time: 0.067, data: 0.002) G_GAN: 0.667 G_L1: 0.000 D_real: 0.689 D_fake: 0.728 \n",
            "(epoch: 124, iters: 704, time: 0.067, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
            "(epoch: 124, iters: 804, time: 0.068, data: 0.002) G_GAN: 4.049 G_L1: 2.222 D_real: 0.024 D_fake: 0.029 \n",
            "saving the latest model (epoch 124, total_iters 105000)\n",
            "(epoch: 124, iters: 904, time: 0.068, data: 0.002) G_GAN: 6.635 G_L1: 0.981 D_real: 0.000 D_fake: 0.003 \n",
            "End of epoch 124 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0001505 -> 0.0001485\n",
            "(epoch: 125, iters: 90, time: 0.067, data: 0.002) G_GAN: 6.621 G_L1: 1.032 D_real: 0.007 D_fake: 0.004 \n",
            "(epoch: 125, iters: 190, time: 0.068, data: 0.002) G_GAN: 0.730 G_L1: 0.004 D_real: 0.802 D_fake: 0.604 \n",
            "(epoch: 125, iters: 290, time: 0.068, data: 0.002) G_GAN: 4.735 G_L1: 1.668 D_real: 0.002 D_fake: 0.019 \n",
            "(epoch: 125, iters: 390, time: 0.068, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.795 D_fake: 0.621 \n",
            "(epoch: 125, iters: 490, time: 0.066, data: 0.002) G_GAN: 1.958 G_L1: 0.197 D_real: 0.711 D_fake: 0.062 \n",
            "(epoch: 125, iters: 590, time: 0.062, data: 0.002) G_GAN: 7.273 G_L1: 0.456 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 125, iters: 690, time: 0.068, data: 0.002) G_GAN: 8.774 G_L1: 0.273 D_real: 0.016 D_fake: 0.000 \n",
            "(epoch: 125, iters: 790, time: 0.067, data: 0.002) G_GAN: 3.776 G_L1: 0.785 D_real: 0.001 D_fake: 0.087 \n",
            "(epoch: 125, iters: 890, time: 0.067, data: 0.002) G_GAN: 2.110 G_L1: 0.073 D_real: 0.430 D_fake: 0.082 \n",
            "saving the model at the end of epoch 125, iters 106024\n",
            "End of epoch 125 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001485 -> 0.0001465\n",
            "(epoch: 126, iters: 76, time: 0.066, data: 0.002) G_GAN: 3.914 G_L1: 0.763 D_real: 0.008 D_fake: 0.033 \n",
            "(epoch: 126, iters: 176, time: 0.057, data: 0.002) G_GAN: 5.964 G_L1: 1.008 D_real: 0.001 D_fake: 0.004 \n",
            "(epoch: 126, iters: 276, time: 0.069, data: 0.002) G_GAN: 3.036 G_L1: 0.509 D_real: 0.050 D_fake: 0.100 \n",
            "(epoch: 126, iters: 376, time: 0.068, data: 0.002) G_GAN: 3.278 G_L1: 0.420 D_real: 0.003 D_fake: 0.093 \n",
            "(epoch: 126, iters: 476, time: 0.068, data: 0.002) G_GAN: 0.661 G_L1: 0.000 D_real: 0.650 D_fake: 0.744 \n",
            "(epoch: 126, iters: 576, time: 0.068, data: 0.002) G_GAN: 0.701 G_L1: 0.000 D_real: 0.692 D_fake: 0.713 \n",
            "(epoch: 126, iters: 676, time: 0.068, data: 0.002) G_GAN: 8.324 G_L1: 1.824 D_real: 0.007 D_fake: 0.001 \n",
            "(epoch: 126, iters: 776, time: 0.068, data: 0.002) G_GAN: 6.459 G_L1: 0.699 D_real: 1.256 D_fake: 0.003 \n",
            "(epoch: 126, iters: 876, time: 0.068, data: 0.002) G_GAN: 4.292 G_L1: 0.320 D_real: 0.015 D_fake: 0.023 \n",
            "End of epoch 126 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001465 -> 0.0001446\n",
            "(epoch: 127, iters: 62, time: 0.068, data: 0.002) G_GAN: 4.204 G_L1: 0.436 D_real: 0.008 D_fake: 0.024 \n",
            "(epoch: 127, iters: 162, time: 0.068, data: 0.002) G_GAN: 7.087 G_L1: 0.672 D_real: 0.009 D_fake: 0.002 \n",
            "(epoch: 127, iters: 262, time: 0.068, data: 0.002) G_GAN: 2.774 G_L1: 0.777 D_real: 0.001 D_fake: 0.162 \n",
            "(epoch: 127, iters: 362, time: 0.069, data: 0.002) G_GAN: 1.486 G_L1: 0.241 D_real: 1.582 D_fake: 0.033 \n",
            "(epoch: 127, iters: 462, time: 0.064, data: 0.002) G_GAN: 5.464 G_L1: 0.590 D_real: 0.008 D_fake: 0.006 \n",
            "(epoch: 127, iters: 562, time: 0.068, data: 0.002) G_GAN: 5.431 G_L1: 4.181 D_real: 0.003 D_fake: 0.024 \n",
            "(epoch: 127, iters: 662, time: 0.063, data: 0.002) G_GAN: 4.822 G_L1: 0.748 D_real: 0.006 D_fake: 0.014 \n",
            "(epoch: 127, iters: 762, time: 0.068, data: 0.002) G_GAN: 4.886 G_L1: 0.343 D_real: 0.008 D_fake: 0.016 \n",
            "(epoch: 127, iters: 862, time: 0.068, data: 0.002) G_GAN: 6.602 G_L1: 0.291 D_real: 0.006 D_fake: 0.002 \n",
            "End of epoch 127 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001446 -> 0.0001426\n",
            "(epoch: 128, iters: 48, time: 0.068, data: 0.002) G_GAN: 4.798 G_L1: 1.241 D_real: 0.014 D_fake: 0.015 \n",
            "(epoch: 128, iters: 148, time: 0.067, data: 0.002) G_GAN: 6.680 G_L1: 0.576 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 128, iters: 248, time: 0.068, data: 0.002) G_GAN: 4.803 G_L1: 0.958 D_real: 0.002 D_fake: 0.013 \n",
            "(epoch: 128, iters: 348, time: 0.068, data: 0.002) G_GAN: 0.674 G_L1: 0.000 D_real: 0.682 D_fake: 0.707 \n",
            "(epoch: 128, iters: 448, time: 0.068, data: 0.002) G_GAN: 4.455 G_L1: 0.187 D_real: 0.092 D_fake: 0.012 \n",
            "(epoch: 128, iters: 548, time: 0.068, data: 0.002) G_GAN: 3.777 G_L1: 0.684 D_real: 0.007 D_fake: 0.055 \n",
            "(epoch: 128, iters: 648, time: 0.065, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.814 D_fake: 0.587 \n",
            "(epoch: 128, iters: 748, time: 0.068, data: 0.002) G_GAN: 7.050 G_L1: 0.658 D_real: 0.015 D_fake: 0.002 \n",
            "(epoch: 128, iters: 848, time: 0.068, data: 0.002) G_GAN: 2.622 G_L1: 0.599 D_real: 0.021 D_fake: 0.211 \n",
            "End of epoch 128 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001426 -> 0.0001406\n",
            "(epoch: 129, iters: 34, time: 0.068, data: 0.002) G_GAN: 4.920 G_L1: 0.658 D_real: 0.008 D_fake: 0.013 \n",
            "(epoch: 129, iters: 134, time: 0.065, data: 0.002) G_GAN: 3.526 G_L1: 0.888 D_real: 0.004 D_fake: 0.073 \n",
            "(epoch: 129, iters: 234, time: 0.068, data: 0.002) G_GAN: 4.105 G_L1: 0.221 D_real: 0.007 D_fake: 0.021 \n",
            "(epoch: 129, iters: 334, time: 0.066, data: 0.002) G_GAN: 0.724 G_L1: 0.001 D_real: 0.772 D_fake: 0.646 \n",
            "(epoch: 129, iters: 434, time: 0.069, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.715 D_fake: 0.676 \n",
            "(epoch: 129, iters: 534, time: 0.069, data: 0.002) G_GAN: 1.791 G_L1: 0.011 D_real: 0.228 D_fake: 1.233 \n",
            "(epoch: 129, iters: 634, time: 0.068, data: 0.001) G_GAN: 3.784 G_L1: 0.663 D_real: 0.006 D_fake: 0.031 \n",
            "(epoch: 129, iters: 734, time: 0.069, data: 0.002) G_GAN: 3.535 G_L1: 1.180 D_real: 0.027 D_fake: 0.055 \n",
            "(epoch: 129, iters: 834, time: 0.068, data: 0.002) G_GAN: 5.195 G_L1: 0.272 D_real: 0.009 D_fake: 0.385 \n",
            "End of epoch 129 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001406 -> 0.0001386\n",
            "(epoch: 130, iters: 20, time: 0.068, data: 0.002) G_GAN: 3.888 G_L1: 0.337 D_real: 0.001 D_fake: 0.046 \n",
            "(epoch: 130, iters: 120, time: 0.068, data: 0.002) G_GAN: 7.370 G_L1: 0.210 D_real: 0.003 D_fake: 0.003 \n",
            "(epoch: 130, iters: 220, time: 0.068, data: 0.002) G_GAN: 0.711 G_L1: 0.001 D_real: 0.681 D_fake: 0.707 \n",
            "(epoch: 130, iters: 320, time: 0.064, data: 0.002) G_GAN: 4.258 G_L1: 0.485 D_real: 0.003 D_fake: 0.022 \n",
            "saving the latest model (epoch 130, total_iters 110000)\n",
            "(epoch: 130, iters: 420, time: 0.068, data: 0.002) G_GAN: 6.079 G_L1: 0.823 D_real: 0.079 D_fake: 0.003 \n",
            "(epoch: 130, iters: 520, time: 0.065, data: 0.002) G_GAN: 2.993 G_L1: 1.092 D_real: 0.037 D_fake: 0.108 \n",
            "(epoch: 130, iters: 620, time: 0.068, data: 0.002) G_GAN: 3.127 G_L1: 0.222 D_real: 0.098 D_fake: 0.304 \n",
            "(epoch: 130, iters: 720, time: 0.066, data: 0.002) G_GAN: 6.256 G_L1: 0.294 D_real: 0.011 D_fake: 0.004 \n",
            "(epoch: 130, iters: 820, time: 0.068, data: 0.002) G_GAN: 7.420 G_L1: 2.528 D_real: 0.004 D_fake: 0.002 \n",
            "saving the model at the end of epoch 130, iters 110594\n",
            "End of epoch 130 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0001386 -> 0.0001366\n",
            "(epoch: 131, iters: 6, time: 0.068, data: 0.002) G_GAN: 5.052 G_L1: 1.600 D_real: 0.209 D_fake: 0.005 \n",
            "(epoch: 131, iters: 106, time: 0.069, data: 0.001) G_GAN: 2.716 G_L1: 0.387 D_real: 0.168 D_fake: 0.268 \n",
            "(epoch: 131, iters: 206, time: 0.068, data: 0.002) G_GAN: 0.694 G_L1: 0.001 D_real: 0.694 D_fake: 0.692 \n",
            "(epoch: 131, iters: 306, time: 0.068, data: 0.002) G_GAN: 3.976 G_L1: 0.692 D_real: 0.116 D_fake: 0.037 \n",
            "(epoch: 131, iters: 406, time: 0.067, data: 0.002) G_GAN: 0.696 G_L1: 0.001 D_real: 0.692 D_fake: 0.696 \n",
            "(epoch: 131, iters: 506, time: 0.068, data: 0.002) G_GAN: 0.695 G_L1: 0.006 D_real: 0.544 D_fake: 0.904 \n",
            "(epoch: 131, iters: 606, time: 0.068, data: 0.002) G_GAN: 2.424 G_L1: 0.072 D_real: 0.006 D_fake: 0.660 \n",
            "(epoch: 131, iters: 706, time: 0.067, data: 0.002) G_GAN: 6.504 G_L1: 0.911 D_real: 0.003 D_fake: 0.003 \n",
            "(epoch: 131, iters: 806, time: 0.069, data: 0.002) G_GAN: 3.555 G_L1: 0.939 D_real: 0.005 D_fake: 0.051 \n",
            "(epoch: 131, iters: 906, time: 0.068, data: 0.002) G_GAN: 3.689 G_L1: 1.094 D_real: 0.009 D_fake: 0.085 \n",
            "End of epoch 131 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001366 -> 0.0001347\n",
            "(epoch: 132, iters: 92, time: 0.072, data: 0.002) G_GAN: 6.688 G_L1: 1.222 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 132, iters: 192, time: 0.066, data: 0.003) G_GAN: 8.186 G_L1: 0.606 D_real: 0.003 D_fake: 0.001 \n",
            "(epoch: 132, iters: 292, time: 0.067, data: 0.002) G_GAN: 4.579 G_L1: 0.890 D_real: 0.002 D_fake: 0.019 \n",
            "(epoch: 132, iters: 392, time: 0.068, data: 0.002) G_GAN: 0.683 G_L1: 0.001 D_real: 0.671 D_fake: 0.717 \n",
            "(epoch: 132, iters: 492, time: 0.068, data: 0.002) G_GAN: 7.061 G_L1: 0.385 D_real: 0.063 D_fake: 0.001 \n",
            "(epoch: 132, iters: 592, time: 0.068, data: 0.002) G_GAN: 0.757 G_L1: 0.001 D_real: 0.760 D_fake: 0.633 \n",
            "(epoch: 132, iters: 692, time: 0.067, data: 0.002) G_GAN: 0.695 G_L1: 0.001 D_real: 0.694 D_fake: 0.693 \n",
            "(epoch: 132, iters: 792, time: 0.068, data: 0.002) G_GAN: 3.575 G_L1: 0.320 D_real: 0.077 D_fake: 0.260 \n",
            "(epoch: 132, iters: 892, time: 0.067, data: 0.002) G_GAN: 5.942 G_L1: 0.516 D_real: 0.216 D_fake: 0.002 \n",
            "End of epoch 132 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001347 -> 0.0001327\n",
            "(epoch: 133, iters: 78, time: 0.068, data: 0.002) G_GAN: 4.430 G_L1: 1.468 D_real: 0.553 D_fake: 0.004 \n",
            "(epoch: 133, iters: 178, time: 0.067, data: 0.002) G_GAN: 3.996 G_L1: 1.431 D_real: 0.004 D_fake: 0.030 \n",
            "(epoch: 133, iters: 278, time: 0.068, data: 0.002) G_GAN: 7.491 G_L1: 0.804 D_real: 0.012 D_fake: 0.001 \n",
            "(epoch: 133, iters: 378, time: 0.068, data: 0.002) G_GAN: 6.803 G_L1: 0.528 D_real: 0.003 D_fake: 0.002 \n",
            "(epoch: 133, iters: 478, time: 0.067, data: 0.002) G_GAN: 6.744 G_L1: 0.080 D_real: 0.031 D_fake: 0.003 \n",
            "(epoch: 133, iters: 578, time: 0.067, data: 0.002) G_GAN: 8.602 G_L1: 0.445 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 133, iters: 678, time: 0.068, data: 0.002) G_GAN: 5.961 G_L1: 1.482 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 133, iters: 778, time: 0.066, data: 0.002) G_GAN: 2.575 G_L1: 0.144 D_real: 0.208 D_fake: 0.284 \n",
            "(epoch: 133, iters: 878, time: 0.068, data: 0.002) G_GAN: 2.818 G_L1: 0.632 D_real: 0.001 D_fake: 0.291 \n",
            "End of epoch 133 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001327 -> 0.0001307\n",
            "(epoch: 134, iters: 64, time: 0.068, data: 0.002) G_GAN: 3.716 G_L1: 0.538 D_real: 0.154 D_fake: 0.031 \n",
            "(epoch: 134, iters: 164, time: 0.068, data: 0.002) G_GAN: 0.694 G_L1: 0.001 D_real: 0.691 D_fake: 0.695 \n",
            "(epoch: 134, iters: 264, time: 0.068, data: 0.002) G_GAN: 0.727 G_L1: 0.001 D_real: 0.685 D_fake: 0.704 \n",
            "(epoch: 134, iters: 364, time: 0.068, data: 0.002) G_GAN: 0.771 G_L1: 0.001 D_real: 0.829 D_fake: 0.594 \n",
            "(epoch: 134, iters: 464, time: 0.064, data: 0.002) G_GAN: 2.774 G_L1: 0.218 D_real: 0.013 D_fake: 0.135 \n",
            "(epoch: 134, iters: 564, time: 0.070, data: 0.002) G_GAN: 0.737 G_L1: 0.001 D_real: 0.753 D_fake: 0.639 \n",
            "(epoch: 134, iters: 664, time: 0.068, data: 0.002) G_GAN: 2.810 G_L1: 1.616 D_real: 0.001 D_fake: 0.155 \n",
            "(epoch: 134, iters: 764, time: 0.060, data: 0.002) G_GAN: 3.300 G_L1: 0.916 D_real: 0.199 D_fake: 0.194 \n",
            "(epoch: 134, iters: 864, time: 0.068, data: 0.002) G_GAN: 4.324 G_L1: 0.871 D_real: 0.001 D_fake: 0.050 \n",
            "End of epoch 134 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001307 -> 0.0001287\n",
            "(epoch: 135, iters: 50, time: 0.067, data: 0.002) G_GAN: 4.471 G_L1: 0.341 D_real: 0.001 D_fake: 0.024 \n",
            "(epoch: 135, iters: 150, time: 0.068, data: 0.002) G_GAN: 3.447 G_L1: 0.538 D_real: 0.020 D_fake: 0.062 \n",
            "(epoch: 135, iters: 250, time: 0.068, data: 0.002) G_GAN: 5.064 G_L1: 1.844 D_real: 0.107 D_fake: 0.008 \n",
            "(epoch: 135, iters: 350, time: 0.062, data: 0.002) G_GAN: 3.230 G_L1: 0.504 D_real: 0.067 D_fake: 0.045 \n",
            "(epoch: 135, iters: 450, time: 0.068, data: 0.002) G_GAN: 7.017 G_L1: 0.982 D_real: 0.005 D_fake: 0.002 \n",
            "(epoch: 135, iters: 550, time: 0.068, data: 0.003) G_GAN: 3.532 G_L1: 0.116 D_real: 0.054 D_fake: 0.640 \n",
            "(epoch: 135, iters: 650, time: 0.068, data: 0.002) G_GAN: 8.109 G_L1: 0.298 D_real: 0.004 D_fake: 0.001 \n",
            "(epoch: 135, iters: 750, time: 0.068, data: 0.002) G_GAN: 0.653 G_L1: 0.001 D_real: 0.630 D_fake: 0.777 \n",
            "saving the latest model (epoch 135, total_iters 115000)\n",
            "(epoch: 135, iters: 850, time: 0.069, data: 0.002) G_GAN: 2.955 G_L1: 0.650 D_real: 0.026 D_fake: 0.153 \n",
            "saving the model at the end of epoch 135, iters 115164\n",
            "End of epoch 135 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0001287 -> 0.0001267\n",
            "(epoch: 136, iters: 36, time: 0.067, data: 0.002) G_GAN: 5.540 G_L1: 1.427 D_real: 0.014 D_fake: 0.007 \n",
            "(epoch: 136, iters: 136, time: 0.068, data: 0.002) G_GAN: 0.696 G_L1: 0.001 D_real: 0.700 D_fake: 0.687 \n",
            "(epoch: 136, iters: 236, time: 0.068, data: 0.002) G_GAN: 5.587 G_L1: 1.086 D_real: 0.001 D_fake: 0.007 \n",
            "(epoch: 136, iters: 336, time: 0.067, data: 0.002) G_GAN: 5.282 G_L1: 0.245 D_real: 0.006 D_fake: 0.007 \n",
            "(epoch: 136, iters: 436, time: 0.068, data: 0.002) G_GAN: 3.786 G_L1: 0.215 D_real: 0.010 D_fake: 0.045 \n",
            "(epoch: 136, iters: 536, time: 0.068, data: 0.002) G_GAN: 6.881 G_L1: 0.919 D_real: 0.009 D_fake: 0.003 \n",
            "(epoch: 136, iters: 636, time: 0.068, data: 0.002) G_GAN: 6.486 G_L1: 1.357 D_real: 0.004 D_fake: 0.004 \n",
            "(epoch: 136, iters: 736, time: 0.069, data: 0.002) G_GAN: 4.252 G_L1: 0.157 D_real: 0.005 D_fake: 0.027 \n",
            "(epoch: 136, iters: 836, time: 0.065, data: 0.002) G_GAN: 3.599 G_L1: 2.512 D_real: 1.440 D_fake: 0.014 \n",
            "End of epoch 136 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001267 -> 0.0001248\n",
            "(epoch: 137, iters: 22, time: 0.068, data: 0.002) G_GAN: 6.421 G_L1: 0.630 D_real: 0.233 D_fake: 0.001 \n",
            "(epoch: 137, iters: 122, time: 0.068, data: 0.002) G_GAN: 3.191 G_L1: 0.526 D_real: 0.015 D_fake: 0.117 \n",
            "(epoch: 137, iters: 222, time: 0.067, data: 0.002) G_GAN: 2.504 G_L1: 0.106 D_real: 0.054 D_fake: 0.580 \n",
            "(epoch: 137, iters: 322, time: 0.067, data: 0.002) G_GAN: 2.654 G_L1: 0.304 D_real: 2.683 D_fake: 0.007 \n",
            "(epoch: 137, iters: 422, time: 0.068, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.775 D_fake: 0.620 \n",
            "(epoch: 137, iters: 522, time: 0.061, data: 0.002) G_GAN: 4.351 G_L1: 0.355 D_real: 0.038 D_fake: 0.020 \n",
            "(epoch: 137, iters: 622, time: 0.067, data: 0.002) G_GAN: 9.682 G_L1: 0.421 D_real: 0.047 D_fake: 0.000 \n",
            "(epoch: 137, iters: 722, time: 0.065, data: 0.002) G_GAN: 0.693 G_L1: 0.001 D_real: 0.693 D_fake: 0.694 \n",
            "(epoch: 137, iters: 822, time: 0.068, data: 0.002) G_GAN: 5.192 G_L1: 1.031 D_real: 0.060 D_fake: 0.008 \n",
            "End of epoch 137 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001248 -> 0.0001228\n",
            "(epoch: 138, iters: 8, time: 0.069, data: 0.002) G_GAN: 2.967 G_L1: 0.562 D_real: 0.105 D_fake: 0.291 \n",
            "(epoch: 138, iters: 108, time: 0.067, data: 0.002) G_GAN: 0.666 G_L1: 0.001 D_real: 0.639 D_fake: 0.752 \n",
            "(epoch: 138, iters: 208, time: 0.061, data: 0.002) G_GAN: 0.613 G_L1: 0.001 D_real: 0.630 D_fake: 0.765 \n",
            "(epoch: 138, iters: 308, time: 0.067, data: 0.002) G_GAN: 4.640 G_L1: 1.178 D_real: 0.272 D_fake: 0.010 \n",
            "(epoch: 138, iters: 408, time: 0.068, data: 0.002) G_GAN: 3.557 G_L1: 0.484 D_real: 0.027 D_fake: 0.045 \n",
            "(epoch: 138, iters: 508, time: 0.068, data: 0.002) G_GAN: 7.511 G_L1: 0.795 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 138, iters: 608, time: 0.065, data: 0.002) G_GAN: 0.839 G_L1: 0.038 D_real: 0.753 D_fake: 0.485 \n",
            "(epoch: 138, iters: 708, time: 0.069, data: 0.002) G_GAN: 8.240 G_L1: 0.231 D_real: 0.038 D_fake: 0.001 \n",
            "(epoch: 138, iters: 808, time: 0.068, data: 0.002) G_GAN: 6.668 G_L1: 1.038 D_real: 0.009 D_fake: 0.001 \n",
            "(epoch: 138, iters: 908, time: 0.068, data: 0.002) G_GAN: 4.267 G_L1: 1.167 D_real: 0.002 D_fake: 0.026 \n",
            "End of epoch 138 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001228 -> 0.0001208\n",
            "(epoch: 139, iters: 94, time: 0.067, data: 0.001) G_GAN: 0.741 G_L1: 0.001 D_real: 0.765 D_fake: 0.634 \n",
            "(epoch: 139, iters: 194, time: 0.068, data: 0.002) G_GAN: 7.263 G_L1: 0.250 D_real: 0.074 D_fake: 0.001 \n",
            "(epoch: 139, iters: 294, time: 0.068, data: 0.002) G_GAN: 0.834 G_L1: 0.721 D_real: 0.916 D_fake: 0.110 \n",
            "(epoch: 139, iters: 394, time: 0.060, data: 0.002) G_GAN: 5.228 G_L1: 0.861 D_real: 0.004 D_fake: 0.009 \n",
            "(epoch: 139, iters: 494, time: 0.068, data: 0.002) G_GAN: 5.874 G_L1: 0.816 D_real: 0.002 D_fake: 0.004 \n",
            "(epoch: 139, iters: 594, time: 0.068, data: 0.002) G_GAN: 0.684 G_L1: 0.000 D_real: 0.680 D_fake: 0.708 \n",
            "(epoch: 139, iters: 694, time: 0.068, data: 0.002) G_GAN: 3.120 G_L1: 0.061 D_real: 0.644 D_fake: 0.070 \n",
            "(epoch: 139, iters: 794, time: 0.068, data: 0.001) G_GAN: 5.078 G_L1: 1.228 D_real: 0.039 D_fake: 0.013 \n",
            "(epoch: 139, iters: 894, time: 0.068, data: 0.002) G_GAN: 6.913 G_L1: 0.215 D_real: 0.040 D_fake: 0.002 \n",
            "End of epoch 139 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001208 -> 0.0001188\n",
            "(epoch: 140, iters: 80, time: 0.068, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.709 D_fake: 0.679 \n",
            "(epoch: 140, iters: 180, time: 0.067, data: 0.002) G_GAN: 3.495 G_L1: 0.452 D_real: 0.007 D_fake: 0.073 \n",
            "(epoch: 140, iters: 280, time: 0.067, data: 0.001) G_GAN: 4.634 G_L1: 0.236 D_real: 0.078 D_fake: 0.029 \n",
            "(epoch: 140, iters: 380, time: 0.068, data: 0.002) G_GAN: 6.299 G_L1: 2.374 D_real: 0.023 D_fake: 0.005 \n",
            "(epoch: 140, iters: 480, time: 0.068, data: 0.002) G_GAN: 0.698 G_L1: 0.000 D_real: 0.703 D_fake: 0.686 \n",
            "(epoch: 140, iters: 580, time: 0.068, data: 0.001) G_GAN: 4.157 G_L1: 0.535 D_real: 0.004 D_fake: 0.024 \n",
            "(epoch: 140, iters: 680, time: 0.068, data: 0.002) G_GAN: 5.269 G_L1: 0.421 D_real: 0.023 D_fake: 0.007 \n",
            "(epoch: 140, iters: 780, time: 0.069, data: 0.002) G_GAN: 5.292 G_L1: 1.586 D_real: 0.001 D_fake: 0.009 \n",
            "(epoch: 140, iters: 880, time: 0.068, data: 0.002) G_GAN: 8.597 G_L1: 0.922 D_real: 0.004 D_fake: 0.001 \n",
            "saving the model at the end of epoch 140, iters 119734\n",
            "End of epoch 140 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001188 -> 0.0001168\n",
            "(epoch: 141, iters: 66, time: 0.068, data: 0.002) G_GAN: 2.787 G_L1: 0.619 D_real: 0.064 D_fake: 0.619 \n",
            "(epoch: 141, iters: 166, time: 0.068, data: 0.002) G_GAN: 0.710 G_L1: 0.004 D_real: 0.806 D_fake: 0.663 \n",
            "(epoch: 141, iters: 266, time: 0.068, data: 0.002) G_GAN: 4.859 G_L1: 0.470 D_real: 0.002 D_fake: 0.015 \n",
            "saving the latest model (epoch 141, total_iters 120000)\n",
            "(epoch: 141, iters: 366, time: 0.068, data: 0.002) G_GAN: 0.748 G_L1: 0.003 D_real: 0.674 D_fake: 0.645 \n",
            "(epoch: 141, iters: 466, time: 0.069, data: 0.002) G_GAN: 4.055 G_L1: 0.717 D_real: 0.000 D_fake: 0.044 \n",
            "(epoch: 141, iters: 566, time: 0.061, data: 0.002) G_GAN: 5.836 G_L1: 0.356 D_real: 0.008 D_fake: 0.004 \n",
            "(epoch: 141, iters: 666, time: 0.068, data: 0.001) G_GAN: 2.790 G_L1: 0.217 D_real: 0.022 D_fake: 0.786 \n",
            "(epoch: 141, iters: 766, time: 0.068, data: 0.002) G_GAN: 0.685 G_L1: 0.000 D_real: 0.685 D_fake: 0.704 \n",
            "(epoch: 141, iters: 866, time: 0.062, data: 0.002) G_GAN: 6.388 G_L1: 0.116 D_real: 0.129 D_fake: 0.005 \n",
            "End of epoch 141 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0001168 -> 0.0001149\n",
            "(epoch: 142, iters: 52, time: 0.068, data: 0.001) G_GAN: 5.352 G_L1: 1.123 D_real: 0.001 D_fake: 0.007 \n",
            "(epoch: 142, iters: 152, time: 0.068, data: 0.002) G_GAN: 5.639 G_L1: 0.513 D_real: 0.005 D_fake: 0.007 \n",
            "(epoch: 142, iters: 252, time: 0.064, data: 0.002) G_GAN: 0.741 G_L1: 0.019 D_real: 0.803 D_fake: 0.626 \n",
            "(epoch: 142, iters: 352, time: 0.069, data: 0.002) G_GAN: 5.485 G_L1: 0.689 D_real: 0.010 D_fake: 0.007 \n",
            "(epoch: 142, iters: 452, time: 0.068, data: 0.002) G_GAN: 0.685 G_L1: 0.000 D_real: 0.689 D_fake: 0.698 \n",
            "(epoch: 142, iters: 552, time: 0.068, data: 0.002) G_GAN: 4.668 G_L1: 0.962 D_real: 0.002 D_fake: 0.015 \n",
            "(epoch: 142, iters: 652, time: 0.068, data: 0.002) G_GAN: 2.608 G_L1: 0.303 D_real: 0.305 D_fake: 0.050 \n",
            "(epoch: 142, iters: 752, time: 0.068, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.702 D_fake: 0.686 \n",
            "(epoch: 142, iters: 852, time: 0.067, data: 0.002) G_GAN: 0.674 G_L1: 0.000 D_real: 0.673 D_fake: 0.717 \n",
            "End of epoch 142 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001149 -> 0.0001129\n",
            "(epoch: 143, iters: 38, time: 0.067, data: 0.001) G_GAN: 3.684 G_L1: 0.172 D_real: 0.010 D_fake: 0.042 \n",
            "(epoch: 143, iters: 138, time: 0.068, data: 0.002) G_GAN: 3.705 G_L1: 0.830 D_real: 0.003 D_fake: 0.062 \n",
            "(epoch: 143, iters: 238, time: 0.068, data: 0.002) G_GAN: 0.668 G_L1: 0.000 D_real: 0.659 D_fake: 0.747 \n",
            "(epoch: 143, iters: 338, time: 0.068, data: 0.002) G_GAN: 4.323 G_L1: 0.098 D_real: 0.002 D_fake: 0.035 \n",
            "(epoch: 143, iters: 438, time: 0.068, data: 0.002) G_GAN: 5.105 G_L1: 0.990 D_real: 0.012 D_fake: 0.009 \n",
            "(epoch: 143, iters: 538, time: 0.068, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
            "(epoch: 143, iters: 638, time: 0.070, data: 0.002) G_GAN: 4.379 G_L1: 0.179 D_real: 0.002 D_fake: 0.019 \n",
            "(epoch: 143, iters: 738, time: 0.065, data: 0.003) G_GAN: 8.833 G_L1: 0.817 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 143, iters: 838, time: 0.068, data: 0.003) G_GAN: 7.727 G_L1: 1.511 D_real: 0.006 D_fake: 0.001 \n",
            "End of epoch 143 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001129 -> 0.0001109\n",
            "(epoch: 144, iters: 24, time: 0.067, data: 0.002) G_GAN: 7.060 G_L1: 0.579 D_real: 0.005 D_fake: 0.002 \n",
            "(epoch: 144, iters: 124, time: 0.068, data: 0.002) G_GAN: 5.023 G_L1: 0.189 D_real: 0.046 D_fake: 0.013 \n",
            "(epoch: 144, iters: 224, time: 0.068, data: 0.002) G_GAN: 5.382 G_L1: 1.037 D_real: 0.002 D_fake: 0.013 \n",
            "(epoch: 144, iters: 324, time: 0.068, data: 0.002) G_GAN: 2.950 G_L1: 0.436 D_real: 0.024 D_fake: 0.117 \n",
            "(epoch: 144, iters: 424, time: 0.068, data: 0.002) G_GAN: 6.266 G_L1: 0.997 D_real: 0.008 D_fake: 0.003 \n",
            "(epoch: 144, iters: 524, time: 0.068, data: 0.002) G_GAN: 3.747 G_L1: 0.154 D_real: 0.028 D_fake: 0.348 \n",
            "(epoch: 144, iters: 624, time: 0.068, data: 0.002) G_GAN: 7.432 G_L1: 0.613 D_real: 0.005 D_fake: 0.001 \n",
            "(epoch: 144, iters: 724, time: 0.065, data: 0.002) G_GAN: 5.024 G_L1: 0.916 D_real: 0.001 D_fake: 0.010 \n",
            "(epoch: 144, iters: 824, time: 0.068, data: 0.002) G_GAN: 8.551 G_L1: 0.601 D_real: 0.007 D_fake: 0.000 \n",
            "End of epoch 144 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001109 -> 0.0001089\n",
            "(epoch: 145, iters: 10, time: 0.067, data: 0.002) G_GAN: 0.702 G_L1: 0.001 D_real: 0.702 D_fake: 0.685 \n",
            "(epoch: 145, iters: 110, time: 0.067, data: 0.002) G_GAN: 2.118 G_L1: 1.796 D_real: 2.544 D_fake: 0.009 \n",
            "(epoch: 145, iters: 210, time: 0.067, data: 0.002) G_GAN: 2.760 G_L1: 1.087 D_real: 0.053 D_fake: 0.155 \n",
            "(epoch: 145, iters: 310, time: 0.067, data: 0.002) G_GAN: 6.121 G_L1: 0.903 D_real: 0.046 D_fake: 0.007 \n",
            "(epoch: 145, iters: 410, time: 0.067, data: 0.002) G_GAN: 0.589 G_L1: 0.000 D_real: 0.565 D_fake: 0.846 \n",
            "(epoch: 145, iters: 510, time: 0.067, data: 0.002) G_GAN: 4.385 G_L1: 0.332 D_real: 0.004 D_fake: 0.016 \n",
            "(epoch: 145, iters: 610, time: 0.068, data: 0.002) G_GAN: 4.762 G_L1: 0.843 D_real: 0.004 D_fake: 0.016 \n",
            "(epoch: 145, iters: 710, time: 0.066, data: 0.002) G_GAN: 4.400 G_L1: 0.298 D_real: 0.002 D_fake: 0.026 \n",
            "(epoch: 145, iters: 810, time: 0.068, data: 0.002) G_GAN: 3.688 G_L1: 0.994 D_real: 0.029 D_fake: 0.056 \n",
            "(epoch: 145, iters: 910, time: 0.068, data: 0.002) G_GAN: 3.804 G_L1: 0.530 D_real: 0.000 D_fake: 0.438 \n",
            "saving the model at the end of epoch 145, iters 124304\n",
            "End of epoch 145 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001089 -> 0.0001069\n",
            "(epoch: 146, iters: 96, time: 0.067, data: 0.002) G_GAN: 3.656 G_L1: 0.735 D_real: 0.013 D_fake: 0.051 \n",
            "(epoch: 146, iters: 196, time: 0.069, data: 0.002) G_GAN: 5.561 G_L1: 0.152 D_real: 0.004 D_fake: 0.007 \n",
            "(epoch: 146, iters: 296, time: 0.067, data: 0.002) G_GAN: 4.295 G_L1: 1.218 D_real: 0.061 D_fake: 0.028 \n",
            "(epoch: 146, iters: 396, time: 0.068, data: 0.002) G_GAN: 0.777 G_L1: 0.000 D_real: 0.850 D_fake: 0.569 \n",
            "(epoch: 146, iters: 496, time: 0.068, data: 0.002) G_GAN: 2.878 G_L1: 0.091 D_real: 0.056 D_fake: 0.179 \n",
            "(epoch: 146, iters: 596, time: 0.062, data: 0.002) G_GAN: 6.049 G_L1: 0.964 D_real: 0.008 D_fake: 0.003 \n",
            "(epoch: 146, iters: 696, time: 0.068, data: 0.001) G_GAN: 7.964 G_L1: 1.816 D_real: 0.002 D_fake: 0.002 \n",
            "saving the latest model (epoch 146, total_iters 125000)\n",
            "(epoch: 146, iters: 796, time: 0.063, data: 0.002) G_GAN: 7.042 G_L1: 1.558 D_real: 0.087 D_fake: 0.002 \n",
            "(epoch: 146, iters: 896, time: 0.068, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.699 D_fake: 0.690 \n",
            "End of epoch 146 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001069 -> 0.0001050\n",
            "(epoch: 147, iters: 82, time: 0.068, data: 0.002) G_GAN: 3.443 G_L1: 1.012 D_real: 0.014 D_fake: 0.051 \n",
            "(epoch: 147, iters: 182, time: 0.067, data: 0.002) G_GAN: 0.864 G_L1: 0.041 D_real: 0.689 D_fake: 0.582 \n",
            "(epoch: 147, iters: 282, time: 0.068, data: 0.002) G_GAN: 6.040 G_L1: 0.830 D_real: 0.006 D_fake: 0.004 \n",
            "(epoch: 147, iters: 382, time: 0.066, data: 0.002) G_GAN: 6.249 G_L1: 1.930 D_real: 0.084 D_fake: 0.008 \n",
            "(epoch: 147, iters: 482, time: 0.067, data: 0.002) G_GAN: 8.500 G_L1: 0.549 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 147, iters: 582, time: 0.065, data: 0.001) G_GAN: 5.064 G_L1: 0.339 D_real: 0.011 D_fake: 0.012 \n",
            "(epoch: 147, iters: 682, time: 0.068, data: 0.002) G_GAN: 5.084 G_L1: 0.345 D_real: 0.014 D_fake: 0.006 \n",
            "(epoch: 147, iters: 782, time: 0.067, data: 0.002) G_GAN: 6.891 G_L1: 0.681 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 147, iters: 882, time: 0.067, data: 0.002) G_GAN: 4.500 G_L1: 0.255 D_real: 0.046 D_fake: 0.012 \n",
            "End of epoch 147 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001050 -> 0.0001030\n",
            "(epoch: 148, iters: 68, time: 0.065, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.688 D_fake: 0.702 \n",
            "(epoch: 148, iters: 168, time: 0.063, data: 0.002) G_GAN: 3.144 G_L1: 0.357 D_real: 0.142 D_fake: 0.052 \n",
            "(epoch: 148, iters: 268, time: 0.068, data: 0.002) G_GAN: 7.862 G_L1: 0.548 D_real: 0.101 D_fake: 0.001 \n",
            "(epoch: 148, iters: 368, time: 0.066, data: 0.002) G_GAN: 5.358 G_L1: 0.599 D_real: 0.006 D_fake: 0.008 \n",
            "(epoch: 148, iters: 468, time: 0.068, data: 0.002) G_GAN: 6.633 G_L1: 0.987 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 148, iters: 568, time: 0.065, data: 0.002) G_GAN: 4.354 G_L1: 0.799 D_real: 0.191 D_fake: 0.012 \n",
            "(epoch: 148, iters: 668, time: 0.069, data: 0.002) G_GAN: 0.623 G_L1: 0.001 D_real: 0.528 D_fake: 0.893 \n",
            "(epoch: 148, iters: 768, time: 0.070, data: 0.002) G_GAN: 7.275 G_L1: 0.779 D_real: 0.003 D_fake: 0.002 \n",
            "(epoch: 148, iters: 868, time: 0.068, data: 0.002) G_GAN: 8.074 G_L1: 2.508 D_real: 0.003 D_fake: 0.001 \n",
            "End of epoch 148 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001030 -> 0.0001010\n",
            "(epoch: 149, iters: 54, time: 0.063, data: 0.001) G_GAN: 3.538 G_L1: 0.378 D_real: 0.006 D_fake: 0.116 \n",
            "(epoch: 149, iters: 154, time: 0.068, data: 0.002) G_GAN: 5.016 G_L1: 1.191 D_real: 0.007 D_fake: 0.018 \n",
            "(epoch: 149, iters: 254, time: 0.068, data: 0.001) G_GAN: 0.682 G_L1: 0.001 D_real: 0.678 D_fake: 0.708 \n",
            "(epoch: 149, iters: 354, time: 0.068, data: 0.002) G_GAN: 0.656 G_L1: 0.000 D_real: 0.636 D_fake: 0.758 \n",
            "(epoch: 149, iters: 454, time: 0.066, data: 0.002) G_GAN: 0.954 G_L1: 0.156 D_real: 0.379 D_fake: 3.412 \n",
            "(epoch: 149, iters: 554, time: 0.069, data: 0.001) G_GAN: 0.779 G_L1: 0.001 D_real: 0.819 D_fake: 0.590 \n",
            "(epoch: 149, iters: 654, time: 0.068, data: 0.002) G_GAN: 6.370 G_L1: 0.433 D_real: 0.029 D_fake: 0.003 \n",
            "(epoch: 149, iters: 754, time: 0.064, data: 0.002) G_GAN: 0.695 G_L1: 0.001 D_real: 0.688 D_fake: 0.702 \n",
            "(epoch: 149, iters: 854, time: 0.063, data: 0.002) G_GAN: 6.886 G_L1: 0.173 D_real: 0.031 D_fake: 0.002 \n",
            "End of epoch 149 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001010 -> 0.0000990\n",
            "(epoch: 150, iters: 40, time: 0.068, data: 0.002) G_GAN: 5.651 G_L1: 1.639 D_real: 0.014 D_fake: 0.006 \n",
            "(epoch: 150, iters: 140, time: 0.068, data: 0.002) G_GAN: 0.693 G_L1: 0.001 D_real: 0.694 D_fake: 0.693 \n",
            "(epoch: 150, iters: 240, time: 0.067, data: 0.002) G_GAN: 3.846 G_L1: 0.627 D_real: 0.005 D_fake: 1.357 \n",
            "(epoch: 150, iters: 340, time: 0.069, data: 0.002) G_GAN: 3.598 G_L1: 1.342 D_real: 0.674 D_fake: 0.030 \n",
            "(epoch: 150, iters: 440, time: 0.069, data: 0.002) G_GAN: 3.785 G_L1: 0.158 D_real: 0.024 D_fake: 0.035 \n",
            "(epoch: 150, iters: 540, time: 0.068, data: 0.002) G_GAN: 0.738 G_L1: 0.001 D_real: 0.747 D_fake: 0.646 \n",
            "(epoch: 150, iters: 640, time: 0.067, data: 0.002) G_GAN: 9.470 G_L1: 1.809 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 150, iters: 740, time: 0.068, data: 0.002) G_GAN: 9.888 G_L1: 0.725 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 150, iters: 840, time: 0.068, data: 0.002) G_GAN: 6.546 G_L1: 1.013 D_real: 0.001 D_fake: 0.003 \n",
            "saving the model at the end of epoch 150, iters 128874\n",
            "End of epoch 150 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000990 -> 0.0000970\n",
            "(epoch: 151, iters: 26, time: 0.068, data: 0.002) G_GAN: 5.580 G_L1: 0.698 D_real: 0.002 D_fake: 0.008 \n",
            "(epoch: 151, iters: 126, time: 0.068, data: 0.002) G_GAN: 0.672 G_L1: 0.000 D_real: 0.643 D_fake: 0.746 \n",
            "(epoch: 151, iters: 226, time: 0.068, data: 0.002) G_GAN: 3.191 G_L1: 0.225 D_real: 1.168 D_fake: 0.013 \n",
            "(epoch: 151, iters: 326, time: 0.068, data: 0.002) G_GAN: 1.627 G_L1: 0.227 D_real: 2.146 D_fake: 0.033 \n",
            "(epoch: 151, iters: 426, time: 0.067, data: 0.001) G_GAN: 1.986 G_L1: 0.048 D_real: 0.266 D_fake: 0.259 \n",
            "(epoch: 151, iters: 526, time: 0.068, data: 0.002) G_GAN: 0.803 G_L1: 0.001 D_real: 0.817 D_fake: 0.587 \n",
            "(epoch: 151, iters: 626, time: 0.066, data: 0.002) G_GAN: 7.794 G_L1: 0.808 D_real: 0.003 D_fake: 0.001 \n",
            "(epoch: 151, iters: 726, time: 0.068, data: 0.002) G_GAN: 0.682 G_L1: 0.001 D_real: 0.679 D_fake: 0.710 \n",
            "(epoch: 151, iters: 826, time: 0.067, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.688 D_fake: 0.698 \n",
            "End of epoch 151 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000970 -> 0.0000950\n",
            "(epoch: 152, iters: 12, time: 0.068, data: 0.002) G_GAN: 0.680 G_L1: 0.001 D_real: 0.656 D_fake: 0.737 \n",
            "(epoch: 152, iters: 112, time: 0.069, data: 0.002) G_GAN: 8.866 G_L1: 0.965 D_real: 0.013 D_fake: 0.000 \n",
            "(epoch: 152, iters: 212, time: 0.068, data: 0.002) G_GAN: 0.677 G_L1: 0.000 D_real: 0.662 D_fake: 0.726 \n",
            "saving the latest model (epoch 152, total_iters 130000)\n",
            "(epoch: 152, iters: 312, time: 0.068, data: 0.002) G_GAN: 5.468 G_L1: 2.626 D_real: 0.004 D_fake: 0.016 \n",
            "(epoch: 152, iters: 412, time: 0.069, data: 0.002) G_GAN: 5.354 G_L1: 1.123 D_real: 0.002 D_fake: 0.009 \n",
            "(epoch: 152, iters: 512, time: 0.068, data: 0.002) G_GAN: 10.169 G_L1: 0.720 D_real: 0.005 D_fake: 0.000 \n",
            "(epoch: 152, iters: 612, time: 0.066, data: 0.002) G_GAN: 6.337 G_L1: 0.177 D_real: 0.025 D_fake: 0.004 \n",
            "(epoch: 152, iters: 712, time: 0.068, data: 0.002) G_GAN: 9.037 G_L1: 0.239 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 152, iters: 812, time: 0.068, data: 0.002) G_GAN: 2.835 G_L1: 0.431 D_real: 0.000 D_fake: 0.185 \n",
            "(epoch: 152, iters: 912, time: 0.069, data: 0.002) G_GAN: 0.684 G_L1: 0.076 D_real: 1.147 D_fake: 0.311 \n",
            "End of epoch 152 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0000950 -> 0.0000931\n",
            "(epoch: 153, iters: 98, time: 0.068, data: 0.002) G_GAN: 8.160 G_L1: 0.542 D_real: 0.007 D_fake: 0.000 \n",
            "(epoch: 153, iters: 198, time: 0.068, data: 0.002) G_GAN: 8.075 G_L1: 1.260 D_real: 0.008 D_fake: 0.001 \n",
            "(epoch: 153, iters: 298, time: 0.068, data: 0.002) G_GAN: 0.709 G_L1: 0.001 D_real: 0.710 D_fake: 0.677 \n",
            "(epoch: 153, iters: 398, time: 0.062, data: 0.002) G_GAN: 6.829 G_L1: 1.130 D_real: 0.004 D_fake: 0.002 \n",
            "(epoch: 153, iters: 498, time: 0.069, data: 0.002) G_GAN: 7.935 G_L1: 0.567 D_real: 0.002 D_fake: 0.001 \n",
            "(epoch: 153, iters: 598, time: 0.068, data: 0.002) G_GAN: 4.286 G_L1: 1.616 D_real: 0.001 D_fake: 0.031 \n",
            "(epoch: 153, iters: 698, time: 0.068, data: 0.002) G_GAN: 3.212 G_L1: 1.093 D_real: 0.294 D_fake: 0.049 \n",
            "(epoch: 153, iters: 798, time: 0.067, data: 0.001) G_GAN: 0.678 G_L1: 0.034 D_real: 0.691 D_fake: 0.768 \n",
            "(epoch: 153, iters: 898, time: 0.067, data: 0.002) G_GAN: 7.270 G_L1: 1.158 D_real: 0.000 D_fake: 0.002 \n",
            "End of epoch 153 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000931 -> 0.0000911\n",
            "(epoch: 154, iters: 84, time: 0.066, data: 0.002) G_GAN: 0.694 G_L1: 0.001 D_real: 0.694 D_fake: 0.692 \n",
            "(epoch: 154, iters: 184, time: 0.068, data: 0.002) G_GAN: 3.137 G_L1: 0.292 D_real: 0.024 D_fake: 0.147 \n",
            "(epoch: 154, iters: 284, time: 0.068, data: 0.002) G_GAN: 0.683 G_L1: 0.000 D_real: 0.673 D_fake: 0.714 \n",
            "(epoch: 154, iters: 384, time: 0.069, data: 0.002) G_GAN: 0.834 G_L1: 0.033 D_real: 0.570 D_fake: 0.235 \n",
            "(epoch: 154, iters: 484, time: 0.068, data: 0.002) G_GAN: 7.744 G_L1: 0.683 D_real: 0.023 D_fake: 0.001 \n",
            "(epoch: 154, iters: 584, time: 0.062, data: 0.002) G_GAN: 4.719 G_L1: 0.836 D_real: 0.000 D_fake: 0.016 \n",
            "(epoch: 154, iters: 684, time: 0.068, data: 0.002) G_GAN: 5.409 G_L1: 0.367 D_real: 0.013 D_fake: 0.008 \n",
            "(epoch: 154, iters: 784, time: 0.068, data: 0.001) G_GAN: 0.742 G_L1: 0.001 D_real: 0.755 D_fake: 0.638 \n",
            "(epoch: 154, iters: 884, time: 0.068, data: 0.002) G_GAN: 5.284 G_L1: 1.274 D_real: 0.022 D_fake: 0.009 \n",
            "End of epoch 154 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000911 -> 0.0000891\n",
            "(epoch: 155, iters: 70, time: 0.068, data: 0.002) G_GAN: 7.049 G_L1: 0.983 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 155, iters: 170, time: 0.069, data: 0.002) G_GAN: 5.945 G_L1: 1.678 D_real: 0.014 D_fake: 0.005 \n",
            "(epoch: 155, iters: 270, time: 0.070, data: 0.002) G_GAN: 4.471 G_L1: 0.937 D_real: 0.006 D_fake: 0.021 \n",
            "(epoch: 155, iters: 370, time: 0.069, data: 0.002) G_GAN: 4.149 G_L1: 1.378 D_real: 0.000 D_fake: 0.030 \n",
            "(epoch: 155, iters: 470, time: 0.068, data: 0.002) G_GAN: 7.060 G_L1: 1.034 D_real: 0.008 D_fake: 0.001 \n",
            "(epoch: 155, iters: 570, time: 0.068, data: 0.002) G_GAN: 6.525 G_L1: 1.339 D_real: 0.003 D_fake: 0.004 \n",
            "(epoch: 155, iters: 670, time: 0.068, data: 0.002) G_GAN: 3.259 G_L1: 0.344 D_real: 0.003 D_fake: 0.032 \n",
            "(epoch: 155, iters: 770, time: 0.068, data: 0.002) G_GAN: 1.816 G_L1: 0.160 D_real: 2.097 D_fake: 0.056 \n",
            "(epoch: 155, iters: 870, time: 0.068, data: 0.002) G_GAN: 0.700 G_L1: 0.001 D_real: 0.703 D_fake: 0.683 \n",
            "saving the model at the end of epoch 155, iters 133444\n",
            "End of epoch 155 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000891 -> 0.0000871\n",
            "(epoch: 156, iters: 56, time: 0.068, data: 0.002) G_GAN: 6.768 G_L1: 2.636 D_real: 0.003 D_fake: 0.003 \n",
            "(epoch: 156, iters: 156, time: 0.068, data: 0.002) G_GAN: 0.687 G_L1: 0.001 D_real: 0.704 D_fake: 0.692 \n",
            "(epoch: 156, iters: 256, time: 0.069, data: 0.002) G_GAN: 0.728 G_L1: 0.001 D_real: 0.737 D_fake: 0.669 \n",
            "(epoch: 156, iters: 356, time: 0.069, data: 0.002) G_GAN: 4.581 G_L1: 1.203 D_real: 0.000 D_fake: 0.013 \n",
            "(epoch: 156, iters: 456, time: 0.068, data: 0.002) G_GAN: 0.689 G_L1: 0.001 D_real: 0.688 D_fake: 0.699 \n",
            "(epoch: 156, iters: 556, time: 0.066, data: 0.002) G_GAN: 3.585 G_L1: 0.477 D_real: 0.029 D_fake: 0.050 \n",
            "(epoch: 156, iters: 656, time: 0.069, data: 0.002) G_GAN: 7.269 G_L1: 0.163 D_real: 0.008 D_fake: 0.002 \n",
            "(epoch: 156, iters: 756, time: 0.062, data: 0.002) G_GAN: 5.463 G_L1: 0.613 D_real: 0.002 D_fake: 0.007 \n",
            "(epoch: 156, iters: 856, time: 0.069, data: 0.002) G_GAN: 5.906 G_L1: 2.993 D_real: 0.001 D_fake: 0.013 \n",
            "End of epoch 156 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000871 -> 0.0000851\n",
            "(epoch: 157, iters: 42, time: 0.068, data: 0.002) G_GAN: 0.687 G_L1: 0.001 D_real: 0.686 D_fake: 0.701 \n",
            "(epoch: 157, iters: 142, time: 0.068, data: 0.002) G_GAN: 2.422 G_L1: 0.023 D_real: 0.779 D_fake: 0.042 \n",
            "(epoch: 157, iters: 242, time: 0.069, data: 0.002) G_GAN: 9.034 G_L1: 0.647 D_real: 0.003 D_fake: 0.000 \n",
            "(epoch: 157, iters: 342, time: 0.068, data: 0.002) G_GAN: 7.264 G_L1: 0.842 D_real: 0.002 D_fake: 0.001 \n",
            "(epoch: 157, iters: 442, time: 0.067, data: 0.002) G_GAN: 5.271 G_L1: 0.702 D_real: 0.024 D_fake: 0.008 \n",
            "(epoch: 157, iters: 542, time: 0.067, data: 0.002) G_GAN: 4.709 G_L1: 0.060 D_real: 0.101 D_fake: 0.015 \n",
            "(epoch: 157, iters: 642, time: 0.062, data: 0.002) G_GAN: 7.118 G_L1: 0.477 D_real: 0.013 D_fake: 0.001 \n",
            "saving the latest model (epoch 157, total_iters 135000)\n",
            "(epoch: 157, iters: 742, time: 0.068, data: 0.002) G_GAN: 5.802 G_L1: 0.532 D_real: 0.039 D_fake: 0.004 \n",
            "(epoch: 157, iters: 842, time: 0.067, data: 0.002) G_GAN: 3.787 G_L1: 0.448 D_real: 0.010 D_fake: 0.218 \n",
            "End of epoch 157 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0000851 -> 0.0000832\n",
            "(epoch: 158, iters: 28, time: 0.062, data: 0.002) G_GAN: 0.665 G_L1: 0.001 D_real: 0.662 D_fake: 0.727 \n",
            "(epoch: 158, iters: 128, time: 0.068, data: 0.002) G_GAN: 3.181 G_L1: 0.118 D_real: 0.012 D_fake: 0.162 \n",
            "(epoch: 158, iters: 228, time: 0.068, data: 0.002) G_GAN: 5.532 G_L1: 1.030 D_real: 0.008 D_fake: 0.007 \n",
            "(epoch: 158, iters: 328, time: 0.068, data: 0.002) G_GAN: 2.027 G_L1: 0.180 D_real: 0.225 D_fake: 0.597 \n",
            "(epoch: 158, iters: 428, time: 0.066, data: 0.002) G_GAN: 0.682 G_L1: 0.007 D_real: 0.667 D_fake: 0.801 \n",
            "(epoch: 158, iters: 528, time: 0.068, data: 0.002) G_GAN: 0.679 G_L1: 0.001 D_real: 0.665 D_fake: 0.723 \n",
            "(epoch: 158, iters: 628, time: 0.067, data: 0.002) G_GAN: 0.659 G_L1: 0.001 D_real: 0.658 D_fake: 0.731 \n",
            "(epoch: 158, iters: 728, time: 0.065, data: 0.002) G_GAN: 4.723 G_L1: 0.336 D_real: 0.003 D_fake: 0.012 \n",
            "(epoch: 158, iters: 828, time: 0.068, data: 0.002) G_GAN: 0.644 G_L1: 0.001 D_real: 0.621 D_fake: 0.778 \n",
            "End of epoch 158 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000832 -> 0.0000812\n",
            "(epoch: 159, iters: 14, time: 0.068, data: 0.002) G_GAN: 9.302 G_L1: 1.155 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 159, iters: 114, time: 0.067, data: 0.002) G_GAN: 4.000 G_L1: 0.280 D_real: 0.135 D_fake: 0.012 \n",
            "(epoch: 159, iters: 214, time: 0.062, data: 0.002) G_GAN: 4.562 G_L1: 0.209 D_real: 0.012 D_fake: 0.015 \n",
            "(epoch: 159, iters: 314, time: 0.068, data: 0.002) G_GAN: 5.771 G_L1: 1.253 D_real: 0.012 D_fake: 0.006 \n",
            "(epoch: 159, iters: 414, time: 0.066, data: 0.002) G_GAN: 4.693 G_L1: 0.206 D_real: 0.006 D_fake: 0.017 \n",
            "(epoch: 159, iters: 514, time: 0.068, data: 0.002) G_GAN: 5.717 G_L1: 0.386 D_real: 0.006 D_fake: 0.005 \n",
            "(epoch: 159, iters: 614, time: 0.068, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
            "(epoch: 159, iters: 714, time: 0.069, data: 0.002) G_GAN: 3.216 G_L1: 0.134 D_real: 0.014 D_fake: 0.079 \n",
            "(epoch: 159, iters: 814, time: 0.069, data: 0.002) G_GAN: 5.112 G_L1: 0.538 D_real: 0.478 D_fake: 0.002 \n",
            "(epoch: 159, iters: 914, time: 0.063, data: 0.002) G_GAN: 3.427 G_L1: 0.524 D_real: 0.162 D_fake: 0.202 \n",
            "End of epoch 159 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000812 -> 0.0000792\n",
            "(epoch: 160, iters: 100, time: 0.068, data: 0.154) G_GAN: 0.817 G_L1: 0.000 D_real: 0.877 D_fake: 0.544 \n",
            "(epoch: 160, iters: 200, time: 0.067, data: 0.002) G_GAN: 7.693 G_L1: 0.852 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 160, iters: 300, time: 0.068, data: 0.002) G_GAN: 4.828 G_L1: 0.147 D_real: 0.001 D_fake: 0.017 \n",
            "(epoch: 160, iters: 400, time: 0.064, data: 0.002) G_GAN: 8.988 G_L1: 1.533 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 160, iters: 500, time: 0.068, data: 0.002) G_GAN: 5.573 G_L1: 0.877 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 160, iters: 600, time: 0.068, data: 0.002) G_GAN: 0.921 G_L1: 0.210 D_real: 1.806 D_fake: 0.187 \n",
            "(epoch: 160, iters: 700, time: 0.068, data: 0.002) G_GAN: 8.123 G_L1: 0.568 D_real: 0.003 D_fake: 0.001 \n",
            "(epoch: 160, iters: 800, time: 0.067, data: 0.002) G_GAN: 7.100 G_L1: 0.555 D_real: 0.012 D_fake: 0.001 \n",
            "(epoch: 160, iters: 900, time: 0.068, data: 0.002) G_GAN: 4.965 G_L1: 0.177 D_real: 0.004 D_fake: 0.124 \n",
            "saving the model at the end of epoch 160, iters 138014\n",
            "End of epoch 160 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000792 -> 0.0000772\n",
            "(epoch: 161, iters: 86, time: 0.068, data: 0.002) G_GAN: 0.661 G_L1: 0.000 D_real: 0.653 D_fake: 0.735 \n",
            "(epoch: 161, iters: 186, time: 0.068, data: 0.002) G_GAN: 0.692 G_L1: 0.001 D_real: 0.685 D_fake: 0.705 \n",
            "(epoch: 161, iters: 286, time: 0.067, data: 0.002) G_GAN: 0.701 G_L1: 0.000 D_real: 0.706 D_fake: 0.681 \n",
            "(epoch: 161, iters: 386, time: 0.068, data: 0.002) G_GAN: 0.719 G_L1: 0.001 D_real: 0.746 D_fake: 0.653 \n",
            "(epoch: 161, iters: 486, time: 0.068, data: 0.002) G_GAN: 8.224 G_L1: 0.622 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 161, iters: 586, time: 0.068, data: 0.002) G_GAN: 5.260 G_L1: 0.614 D_real: 0.024 D_fake: 0.009 \n",
            "(epoch: 161, iters: 686, time: 0.066, data: 0.002) G_GAN: 6.637 G_L1: 0.186 D_real: 0.026 D_fake: 0.002 \n",
            "(epoch: 161, iters: 786, time: 0.068, data: 0.002) G_GAN: 2.624 G_L1: 1.333 D_real: 0.000 D_fake: 0.411 \n",
            "(epoch: 161, iters: 886, time: 0.068, data: 0.001) G_GAN: 7.947 G_L1: 0.267 D_real: 0.000 D_fake: 0.001 \n",
            "End of epoch 161 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000772 -> 0.0000752\n",
            "(epoch: 162, iters: 72, time: 0.066, data: 0.002) G_GAN: 5.337 G_L1: 0.991 D_real: 0.000 D_fake: 0.011 \n",
            "(epoch: 162, iters: 172, time: 0.062, data: 0.002) G_GAN: 0.745 G_L1: 0.006 D_real: 0.741 D_fake: 0.646 \n",
            "(epoch: 162, iters: 272, time: 0.065, data: 0.002) G_GAN: 5.123 G_L1: 0.264 D_real: 0.001 D_fake: 0.012 \n",
            "(epoch: 162, iters: 372, time: 0.068, data: 0.002) G_GAN: 5.233 G_L1: 1.460 D_real: 0.007 D_fake: 0.013 \n",
            "(epoch: 162, iters: 472, time: 0.068, data: 0.001) G_GAN: 3.360 G_L1: 0.603 D_real: 0.007 D_fake: 0.061 \n",
            "(epoch: 162, iters: 572, time: 0.067, data: 0.002) G_GAN: 0.694 G_L1: 0.001 D_real: 0.695 D_fake: 0.691 \n",
            "(epoch: 162, iters: 672, time: 0.068, data: 0.002) G_GAN: 8.662 G_L1: 1.013 D_real: 0.002 D_fake: 0.001 \n",
            "(epoch: 162, iters: 772, time: 0.067, data: 0.002) G_GAN: 7.580 G_L1: 0.647 D_real: 0.010 D_fake: 0.001 \n",
            "(epoch: 162, iters: 872, time: 0.065, data: 0.002) G_GAN: 0.704 G_L1: 0.000 D_real: 0.708 D_fake: 0.679 \n",
            "End of epoch 162 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000752 -> 0.0000733\n",
            "(epoch: 163, iters: 58, time: 0.068, data: 0.002) G_GAN: 3.325 G_L1: 0.168 D_real: 0.000 D_fake: 1.040 \n",
            "(epoch: 163, iters: 158, time: 0.068, data: 0.002) G_GAN: 4.589 G_L1: 0.928 D_real: 0.010 D_fake: 0.016 \n",
            "saving the latest model (epoch 163, total_iters 140000)\n",
            "(epoch: 163, iters: 258, time: 0.068, data: 0.001) G_GAN: 0.629 G_L1: 0.000 D_real: 0.609 D_fake: 0.786 \n",
            "(epoch: 163, iters: 358, time: 0.068, data: 0.002) G_GAN: 3.461 G_L1: 0.143 D_real: 0.117 D_fake: 0.163 \n",
            "(epoch: 163, iters: 458, time: 0.067, data: 0.002) G_GAN: 8.549 G_L1: 0.433 D_real: 0.005 D_fake: 0.001 \n",
            "(epoch: 163, iters: 558, time: 0.068, data: 0.002) G_GAN: 6.685 G_L1: 0.326 D_real: 0.004 D_fake: 0.002 \n",
            "(epoch: 163, iters: 658, time: 0.068, data: 0.002) G_GAN: 3.007 G_L1: 0.143 D_real: 0.230 D_fake: 0.046 \n",
            "(epoch: 163, iters: 758, time: 0.069, data: 0.002) G_GAN: 4.284 G_L1: 0.165 D_real: 0.000 D_fake: 0.025 \n",
            "(epoch: 163, iters: 858, time: 0.064, data: 0.002) G_GAN: 6.842 G_L1: 0.317 D_real: 0.002 D_fake: 0.004 \n",
            "End of epoch 163 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0000733 -> 0.0000713\n",
            "(epoch: 164, iters: 44, time: 0.066, data: 0.002) G_GAN: 5.481 G_L1: 0.847 D_real: 0.000 D_fake: 0.007 \n",
            "(epoch: 164, iters: 144, time: 0.068, data: 0.002) G_GAN: 3.765 G_L1: 0.340 D_real: 0.006 D_fake: 0.038 \n",
            "(epoch: 164, iters: 244, time: 0.068, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
            "(epoch: 164, iters: 344, time: 0.064, data: 0.002) G_GAN: 6.230 G_L1: 0.666 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 164, iters: 444, time: 0.068, data: 0.002) G_GAN: 0.674 G_L1: 0.000 D_real: 0.680 D_fake: 0.714 \n",
            "(epoch: 164, iters: 544, time: 0.068, data: 0.002) G_GAN: 3.384 G_L1: 0.527 D_real: 0.003 D_fake: 0.079 \n",
            "(epoch: 164, iters: 644, time: 0.068, data: 0.002) G_GAN: 8.506 G_L1: 0.840 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 164, iters: 744, time: 0.068, data: 0.002) G_GAN: 9.461 G_L1: 0.381 D_real: 0.005 D_fake: 0.000 \n",
            "(epoch: 164, iters: 844, time: 0.068, data: 0.002) G_GAN: 0.701 G_L1: 0.000 D_real: 0.707 D_fake: 0.680 \n",
            "End of epoch 164 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000713 -> 0.0000693\n",
            "(epoch: 165, iters: 30, time: 0.068, data: 0.002) G_GAN: 0.683 G_L1: 0.000 D_real: 0.678 D_fake: 0.712 \n",
            "(epoch: 165, iters: 130, time: 0.068, data: 0.002) G_GAN: 8.493 G_L1: 0.432 D_real: 0.032 D_fake: 0.000 \n",
            "(epoch: 165, iters: 230, time: 0.067, data: 0.002) G_GAN: 1.237 G_L1: 0.009 D_real: 1.015 D_fake: 0.470 \n",
            "(epoch: 165, iters: 330, time: 0.069, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.704 D_fake: 0.683 \n",
            "(epoch: 165, iters: 430, time: 0.066, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.697 D_fake: 0.689 \n",
            "(epoch: 165, iters: 530, time: 0.065, data: 0.002) G_GAN: 7.384 G_L1: 1.596 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 165, iters: 630, time: 0.068, data: 0.002) G_GAN: 7.472 G_L1: 0.341 D_real: 0.032 D_fake: 0.001 \n",
            "(epoch: 165, iters: 730, time: 0.068, data: 0.002) G_GAN: 4.609 G_L1: 0.299 D_real: 0.001 D_fake: 0.019 \n",
            "(epoch: 165, iters: 830, time: 0.068, data: 0.002) G_GAN: 8.736 G_L1: 1.145 D_real: 0.000 D_fake: 0.000 \n",
            "saving the model at the end of epoch 165, iters 142584\n",
            "End of epoch 165 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0000693 -> 0.0000673\n",
            "(epoch: 166, iters: 16, time: 0.068, data: 0.002) G_GAN: 0.659 G_L1: 0.003 D_real: 0.611 D_fake: 0.800 \n",
            "(epoch: 166, iters: 116, time: 0.068, data: 0.002) G_GAN: 0.677 G_L1: 0.000 D_real: 0.670 D_fake: 0.717 \n",
            "(epoch: 166, iters: 216, time: 0.068, data: 0.002) G_GAN: 8.426 G_L1: 0.558 D_real: 0.012 D_fake: 0.000 \n",
            "(epoch: 166, iters: 316, time: 0.068, data: 0.002) G_GAN: 8.749 G_L1: 0.365 D_real: 0.006 D_fake: 0.000 \n",
            "(epoch: 166, iters: 416, time: 0.067, data: 0.002) G_GAN: 7.274 G_L1: 0.668 D_real: 0.064 D_fake: 0.001 \n",
            "(epoch: 166, iters: 516, time: 0.067, data: 0.002) G_GAN: 0.702 G_L1: 0.001 D_real: 0.702 D_fake: 0.684 \n",
            "(epoch: 166, iters: 616, time: 0.068, data: 0.002) G_GAN: 7.158 G_L1: 1.048 D_real: 0.031 D_fake: 0.002 \n",
            "(epoch: 166, iters: 716, time: 0.068, data: 0.002) G_GAN: 4.442 G_L1: 0.445 D_real: 0.002 D_fake: 0.021 \n",
            "(epoch: 166, iters: 816, time: 0.067, data: 0.002) G_GAN: 4.960 G_L1: 0.627 D_real: 0.000 D_fake: 0.018 \n",
            "End of epoch 166 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000673 -> 0.0000653\n",
            "(epoch: 167, iters: 2, time: 0.055, data: 0.002) G_GAN: 0.746 G_L1: 0.001 D_real: 0.780 D_fake: 0.618 \n",
            "(epoch: 167, iters: 102, time: 0.066, data: 0.001) G_GAN: 4.391 G_L1: 0.215 D_real: 0.008 D_fake: 0.032 \n",
            "(epoch: 167, iters: 202, time: 0.068, data: 0.002) G_GAN: 5.574 G_L1: 0.705 D_real: 0.028 D_fake: 0.005 \n",
            "(epoch: 167, iters: 302, time: 0.068, data: 0.002) G_GAN: 7.822 G_L1: 0.597 D_real: 0.002 D_fake: 0.001 \n",
            "(epoch: 167, iters: 402, time: 0.068, data: 0.002) G_GAN: 7.323 G_L1: 1.520 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 167, iters: 502, time: 0.068, data: 0.002) G_GAN: 8.329 G_L1: 1.062 D_real: 0.005 D_fake: 0.001 \n",
            "(epoch: 167, iters: 602, time: 0.064, data: 0.002) G_GAN: 7.056 G_L1: 0.298 D_real: 0.193 D_fake: 0.001 \n",
            "(epoch: 167, iters: 702, time: 0.067, data: 0.002) G_GAN: 6.613 G_L1: 0.724 D_real: 0.001 D_fake: 0.004 \n",
            "(epoch: 167, iters: 802, time: 0.068, data: 0.002) G_GAN: 4.757 G_L1: 0.078 D_real: 0.107 D_fake: 0.012 \n",
            "(epoch: 167, iters: 902, time: 0.069, data: 0.002) G_GAN: 6.850 G_L1: 0.149 D_real: 0.005 D_fake: 0.002 \n",
            "End of epoch 167 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000653 -> 0.0000634\n",
            "(epoch: 168, iters: 88, time: 0.064, data: 0.002) G_GAN: 7.495 G_L1: 0.645 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 168, iters: 188, time: 0.069, data: 0.002) G_GAN: 2.502 G_L1: 0.294 D_real: 0.142 D_fake: 0.160 \n",
            "(epoch: 168, iters: 288, time: 0.067, data: 0.002) G_GAN: 6.618 G_L1: 1.095 D_real: 0.003 D_fake: 0.002 \n",
            "(epoch: 168, iters: 388, time: 0.068, data: 0.002) G_GAN: 2.657 G_L1: 0.169 D_real: 0.194 D_fake: 0.094 \n",
            "(epoch: 168, iters: 488, time: 0.068, data: 0.002) G_GAN: 8.756 G_L1: 0.379 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 168, iters: 588, time: 0.067, data: 0.002) G_GAN: 4.640 G_L1: 0.700 D_real: 0.006 D_fake: 0.026 \n",
            "saving the latest model (epoch 168, total_iters 145000)\n",
            "(epoch: 168, iters: 688, time: 0.067, data: 0.002) G_GAN: 0.665 G_L1: 0.001 D_real: 0.671 D_fake: 0.717 \n",
            "(epoch: 168, iters: 788, time: 0.068, data: 0.002) G_GAN: 5.839 G_L1: 0.188 D_real: 0.036 D_fake: 0.005 \n",
            "(epoch: 168, iters: 888, time: 0.068, data: 0.002) G_GAN: 8.617 G_L1: 0.812 D_real: 0.000 D_fake: 0.000 \n",
            "End of epoch 168 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000634 -> 0.0000614\n",
            "(epoch: 169, iters: 74, time: 0.065, data: 0.002) G_GAN: 4.252 G_L1: 0.565 D_real: 0.001 D_fake: 0.027 \n",
            "(epoch: 169, iters: 174, time: 0.069, data: 0.001) G_GAN: 0.713 G_L1: 0.000 D_real: 0.714 D_fake: 0.674 \n",
            "(epoch: 169, iters: 274, time: 0.068, data: 0.002) G_GAN: 6.018 G_L1: 0.640 D_real: 0.007 D_fake: 0.006 \n",
            "(epoch: 169, iters: 374, time: 0.068, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.689 \n",
            "(epoch: 169, iters: 474, time: 0.068, data: 0.002) G_GAN: 8.456 G_L1: 0.556 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 169, iters: 574, time: 0.062, data: 0.002) G_GAN: 0.689 G_L1: 0.000 D_real: 0.680 D_fake: 0.714 \n",
            "(epoch: 169, iters: 674, time: 0.068, data: 0.002) G_GAN: 5.756 G_L1: 0.465 D_real: 0.009 D_fake: 0.007 \n",
            "(epoch: 169, iters: 774, time: 0.067, data: 0.002) G_GAN: 4.076 G_L1: 0.486 D_real: 0.003 D_fake: 0.026 \n",
            "(epoch: 169, iters: 874, time: 0.068, data: 0.002) G_GAN: 8.659 G_L1: 2.700 D_real: 0.015 D_fake: 0.001 \n",
            "End of epoch 169 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000614 -> 0.0000594\n",
            "(epoch: 170, iters: 60, time: 0.068, data: 0.002) G_GAN: 0.734 G_L1: 0.001 D_real: 0.739 D_fake: 0.663 \n",
            "(epoch: 170, iters: 160, time: 0.068, data: 0.002) G_GAN: 8.231 G_L1: 1.167 D_real: 0.013 D_fake: 0.001 \n",
            "(epoch: 170, iters: 260, time: 0.067, data: 0.002) G_GAN: 6.941 G_L1: 0.430 D_real: 0.005 D_fake: 0.002 \n",
            "(epoch: 170, iters: 360, time: 0.067, data: 0.002) G_GAN: 10.327 G_L1: 0.459 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 170, iters: 460, time: 0.068, data: 0.002) G_GAN: 4.694 G_L1: 0.962 D_real: 0.000 D_fake: 0.016 \n",
            "(epoch: 170, iters: 560, time: 0.068, data: 0.002) G_GAN: 9.962 G_L1: 0.517 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 170, iters: 660, time: 0.068, data: 0.002) G_GAN: 10.181 G_L1: 0.595 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 170, iters: 760, time: 0.068, data: 0.002) G_GAN: 6.681 G_L1: 1.042 D_real: 0.001 D_fake: 0.004 \n",
            "(epoch: 170, iters: 860, time: 0.067, data: 0.002) G_GAN: 6.553 G_L1: 1.045 D_real: 0.001 D_fake: 0.003 \n",
            "saving the model at the end of epoch 170, iters 147154\n",
            "End of epoch 170 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000594 -> 0.0000574\n",
            "(epoch: 171, iters: 46, time: 0.068, data: 0.002) G_GAN: 5.826 G_L1: 0.348 D_real: 0.012 D_fake: 0.005 \n",
            "(epoch: 171, iters: 146, time: 0.069, data: 0.002) G_GAN: 10.527 G_L1: 0.368 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 171, iters: 246, time: 0.067, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.739 D_fake: 0.652 \n",
            "(epoch: 171, iters: 346, time: 0.067, data: 0.001) G_GAN: 0.687 G_L1: 0.000 D_real: 0.688 D_fake: 0.699 \n",
            "(epoch: 171, iters: 446, time: 0.068, data: 0.002) G_GAN: 8.173 G_L1: 0.527 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 171, iters: 546, time: 0.068, data: 0.002) G_GAN: 0.682 G_L1: 0.001 D_real: 0.675 D_fake: 0.712 \n",
            "(epoch: 171, iters: 646, time: 0.067, data: 0.002) G_GAN: 6.084 G_L1: 0.426 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 171, iters: 746, time: 0.067, data: 0.002) G_GAN: 5.084 G_L1: 0.373 D_real: 0.001 D_fake: 0.017 \n",
            "(epoch: 171, iters: 846, time: 0.067, data: 0.002) G_GAN: 5.745 G_L1: 0.865 D_real: 0.046 D_fake: 0.014 \n",
            "End of epoch 171 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000574 -> 0.0000554\n",
            "(epoch: 172, iters: 32, time: 0.067, data: 0.002) G_GAN: 9.324 G_L1: 1.363 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 172, iters: 132, time: 0.068, data: 0.001) G_GAN: 6.459 G_L1: 0.643 D_real: 0.003 D_fake: 0.003 \n",
            "(epoch: 172, iters: 232, time: 0.067, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.719 D_fake: 0.669 \n",
            "(epoch: 172, iters: 332, time: 0.068, data: 0.002) G_GAN: 8.211 G_L1: 0.404 D_real: 0.003 D_fake: 0.001 \n",
            "(epoch: 172, iters: 432, time: 0.068, data: 0.002) G_GAN: 6.995 G_L1: 1.765 D_real: 0.001 D_fake: 0.004 \n",
            "(epoch: 172, iters: 532, time: 0.062, data: 0.002) G_GAN: 5.463 G_L1: 1.328 D_real: 0.001 D_fake: 0.007 \n",
            "(epoch: 172, iters: 632, time: 0.068, data: 0.002) G_GAN: 7.748 G_L1: 0.562 D_real: 0.002 D_fake: 0.001 \n",
            "(epoch: 172, iters: 732, time: 0.068, data: 0.002) G_GAN: 6.854 G_L1: 0.320 D_real: 0.002 D_fake: 0.002 \n",
            "(epoch: 172, iters: 832, time: 0.067, data: 0.002) G_GAN: 7.010 G_L1: 0.897 D_real: 0.000 D_fake: 0.002 \n",
            "End of epoch 172 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000554 -> 0.0000535\n",
            "(epoch: 173, iters: 18, time: 0.067, data: 0.002) G_GAN: 6.514 G_L1: 1.647 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 173, iters: 118, time: 0.068, data: 0.002) G_GAN: 6.789 G_L1: 0.903 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 173, iters: 218, time: 0.068, data: 0.002) G_GAN: 5.969 G_L1: 1.105 D_real: 0.021 D_fake: 0.009 \n",
            "(epoch: 173, iters: 318, time: 0.067, data: 0.001) G_GAN: 5.621 G_L1: 0.430 D_real: 0.041 D_fake: 0.006 \n",
            "(epoch: 173, iters: 418, time: 0.066, data: 0.002) G_GAN: 7.989 G_L1: 0.748 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 173, iters: 518, time: 0.067, data: 0.002) G_GAN: 0.701 G_L1: 0.000 D_real: 0.675 D_fake: 0.717 \n",
            "(epoch: 173, iters: 618, time: 0.066, data: 0.002) G_GAN: 0.560 G_L1: 0.000 D_real: 0.524 D_fake: 0.904 \n",
            "(epoch: 173, iters: 718, time: 0.067, data: 0.003) G_GAN: 4.853 G_L1: 0.232 D_real: 0.000 D_fake: 0.013 \n",
            "(epoch: 173, iters: 818, time: 0.067, data: 0.002) G_GAN: 3.146 G_L1: 0.553 D_real: 0.010 D_fake: 0.851 \n",
            "End of epoch 173 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000535 -> 0.0000515\n",
            "(epoch: 174, iters: 4, time: 0.066, data: 0.002) G_GAN: 3.380 G_L1: 0.061 D_real: 0.067 D_fake: 0.047 \n",
            "(epoch: 174, iters: 104, time: 0.067, data: 0.003) G_GAN: 9.044 G_L1: 0.219 D_real: 0.001 D_fake: 0.000 \n",
            "saving the latest model (epoch 174, total_iters 150000)\n",
            "(epoch: 174, iters: 204, time: 0.067, data: 0.002) G_GAN: 5.640 G_L1: 1.119 D_real: 0.000 D_fake: 0.010 \n",
            "(epoch: 174, iters: 304, time: 0.068, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.696 D_fake: 0.691 \n",
            "(epoch: 174, iters: 404, time: 0.066, data: 0.002) G_GAN: 1.762 G_L1: 0.984 D_real: 0.087 D_fake: 0.689 \n",
            "(epoch: 174, iters: 504, time: 0.068, data: 0.002) G_GAN: 9.566 G_L1: 0.940 D_real: 0.003 D_fake: 0.000 \n",
            "(epoch: 174, iters: 604, time: 0.063, data: 0.002) G_GAN: 6.090 G_L1: 0.173 D_real: 0.003 D_fake: 0.004 \n",
            "(epoch: 174, iters: 704, time: 0.068, data: 0.002) G_GAN: 6.178 G_L1: 0.918 D_real: 0.004 D_fake: 0.005 \n",
            "(epoch: 174, iters: 804, time: 0.068, data: 0.002) G_GAN: 7.455 G_L1: 0.386 D_real: 0.022 D_fake: 0.001 \n",
            "(epoch: 174, iters: 904, time: 0.068, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
            "End of epoch 174 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0000515 -> 0.0000495\n",
            "(epoch: 175, iters: 90, time: 0.072, data: 0.002) G_GAN: 6.752 G_L1: 1.366 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 175, iters: 190, time: 0.067, data: 0.002) G_GAN: 10.727 G_L1: 2.476 D_real: 0.011 D_fake: 0.000 \n",
            "(epoch: 175, iters: 290, time: 0.067, data: 0.002) G_GAN: 0.668 G_L1: 0.000 D_real: 0.662 D_fake: 0.726 \n",
            "(epoch: 175, iters: 390, time: 0.068, data: 0.002) G_GAN: 3.960 G_L1: 0.226 D_real: 0.002 D_fake: 0.035 \n",
            "(epoch: 175, iters: 490, time: 0.068, data: 0.002) G_GAN: 7.619 G_L1: 0.361 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 175, iters: 590, time: 0.067, data: 0.002) G_GAN: 6.714 G_L1: 0.213 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 175, iters: 690, time: 0.068, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
            "(epoch: 175, iters: 790, time: 0.068, data: 0.002) G_GAN: 10.018 G_L1: 0.215 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 175, iters: 890, time: 0.067, data: 0.002) G_GAN: 8.803 G_L1: 4.044 D_real: 0.000 D_fake: 0.002 \n",
            "saving the model at the end of epoch 175, iters 151724\n",
            "End of epoch 175 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000495 -> 0.0000475\n",
            "(epoch: 176, iters: 76, time: 0.067, data: 0.003) G_GAN: 7.150 G_L1: 0.825 D_real: 0.002 D_fake: 0.002 \n",
            "(epoch: 176, iters: 176, time: 0.070, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
            "(epoch: 176, iters: 276, time: 0.066, data: 0.002) G_GAN: 1.054 G_L1: 0.031 D_real: 0.362 D_fake: 1.513 \n",
            "(epoch: 176, iters: 376, time: 0.068, data: 0.002) G_GAN: 5.773 G_L1: 0.343 D_real: 0.006 D_fake: 0.006 \n",
            "(epoch: 176, iters: 476, time: 0.068, data: 0.002) G_GAN: 9.157 G_L1: 0.549 D_real: 0.111 D_fake: 0.000 \n",
            "(epoch: 176, iters: 576, time: 0.061, data: 0.002) G_GAN: 4.556 G_L1: 0.713 D_real: 0.002 D_fake: 0.017 \n",
            "(epoch: 176, iters: 676, time: 0.065, data: 0.002) G_GAN: 4.160 G_L1: 0.773 D_real: 0.017 D_fake: 0.048 \n",
            "(epoch: 176, iters: 776, time: 0.068, data: 0.002) G_GAN: 4.179 G_L1: 0.131 D_real: 0.002 D_fake: 0.025 \n",
            "(epoch: 176, iters: 876, time: 0.068, data: 0.002) G_GAN: 4.939 G_L1: 0.174 D_real: 0.005 D_fake: 0.012 \n",
            "End of epoch 176 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000475 -> 0.0000455\n",
            "(epoch: 177, iters: 62, time: 0.068, data: 0.002) G_GAN: 8.023 G_L1: 0.299 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 177, iters: 162, time: 0.062, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.759 D_fake: 0.640 \n",
            "(epoch: 177, iters: 262, time: 0.068, data: 0.002) G_GAN: 0.696 G_L1: 0.002 D_real: 0.682 D_fake: 0.721 \n",
            "(epoch: 177, iters: 362, time: 0.065, data: 0.002) G_GAN: 6.308 G_L1: 0.726 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 177, iters: 462, time: 0.065, data: 0.002) G_GAN: 5.500 G_L1: 0.825 D_real: 0.016 D_fake: 0.007 \n",
            "(epoch: 177, iters: 562, time: 0.063, data: 0.002) G_GAN: 3.908 G_L1: 0.096 D_real: 0.033 D_fake: 0.029 \n",
            "(epoch: 177, iters: 662, time: 0.067, data: 0.002) G_GAN: 6.758 G_L1: 0.445 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 177, iters: 762, time: 0.066, data: 0.002) G_GAN: 0.660 G_L1: 0.000 D_real: 0.655 D_fake: 0.735 \n",
            "(epoch: 177, iters: 862, time: 0.068, data: 0.002) G_GAN: 4.286 G_L1: 0.912 D_real: 0.004 D_fake: 0.030 \n",
            "End of epoch 177 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000455 -> 0.0000436\n",
            "(epoch: 178, iters: 48, time: 0.068, data: 0.002) G_GAN: 7.451 G_L1: 1.480 D_real: 0.011 D_fake: 0.001 \n",
            "(epoch: 178, iters: 148, time: 0.067, data: 0.002) G_GAN: 7.764 G_L1: 1.755 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 178, iters: 248, time: 0.068, data: 0.002) G_GAN: 6.049 G_L1: 0.391 D_real: 0.001 D_fake: 0.004 \n",
            "(epoch: 178, iters: 348, time: 0.067, data: 0.002) G_GAN: 8.877 G_L1: 0.572 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 178, iters: 448, time: 0.068, data: 0.002) G_GAN: 4.724 G_L1: 0.146 D_real: 0.028 D_fake: 0.028 \n",
            "(epoch: 178, iters: 548, time: 0.065, data: 0.002) G_GAN: 4.940 G_L1: 0.383 D_real: 0.004 D_fake: 0.011 \n",
            "(epoch: 178, iters: 648, time: 0.068, data: 0.002) G_GAN: 0.686 G_L1: 0.000 D_real: 0.684 D_fake: 0.702 \n",
            "(epoch: 178, iters: 748, time: 0.067, data: 0.002) G_GAN: 9.004 G_L1: 1.160 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 178, iters: 848, time: 0.067, data: 0.002) G_GAN: 6.810 G_L1: 0.345 D_real: 0.003 D_fake: 0.002 \n",
            "End of epoch 178 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000436 -> 0.0000416\n",
            "(epoch: 179, iters: 34, time: 0.066, data: 0.002) G_GAN: 7.896 G_L1: 0.436 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 179, iters: 134, time: 0.067, data: 0.002) G_GAN: 8.269 G_L1: 1.829 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 179, iters: 234, time: 0.064, data: 0.002) G_GAN: 0.621 G_L1: 0.000 D_real: 0.601 D_fake: 0.797 \n",
            "(epoch: 179, iters: 334, time: 0.067, data: 0.002) G_GAN: 5.142 G_L1: 0.851 D_real: 0.002 D_fake: 0.013 \n",
            "(epoch: 179, iters: 434, time: 0.068, data: 0.002) G_GAN: 9.011 G_L1: 1.557 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 179, iters: 534, time: 0.067, data: 0.002) G_GAN: 6.894 G_L1: 0.664 D_real: 0.001 D_fake: 0.002 \n",
            "saving the latest model (epoch 179, total_iters 155000)\n",
            "(epoch: 179, iters: 634, time: 0.064, data: 0.002) G_GAN: 4.085 G_L1: 0.770 D_real: 0.019 D_fake: 0.036 \n",
            "(epoch: 179, iters: 734, time: 0.069, data: 0.002) G_GAN: 3.828 G_L1: 0.129 D_real: 0.042 D_fake: 0.038 \n",
            "(epoch: 179, iters: 834, time: 0.065, data: 0.002) G_GAN: 4.752 G_L1: 0.732 D_real: 0.001 D_fake: 0.016 \n",
            "End of epoch 179 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000416 -> 0.0000396\n",
            "(epoch: 180, iters: 20, time: 0.067, data: 0.002) G_GAN: 3.504 G_L1: 0.156 D_real: 0.251 D_fake: 0.192 \n",
            "(epoch: 180, iters: 120, time: 0.067, data: 0.002) G_GAN: 10.173 G_L1: 0.493 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 180, iters: 220, time: 0.067, data: 0.002) G_GAN: 8.924 G_L1: 1.012 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 180, iters: 320, time: 0.066, data: 0.002) G_GAN: 8.325 G_L1: 0.180 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 180, iters: 420, time: 0.060, data: 0.002) G_GAN: 5.506 G_L1: 0.959 D_real: 0.000 D_fake: 0.013 \n",
            "(epoch: 180, iters: 520, time: 0.065, data: 0.002) G_GAN: 0.740 G_L1: 0.006 D_real: 0.534 D_fake: 0.949 \n",
            "(epoch: 180, iters: 620, time: 0.068, data: 0.002) G_GAN: 0.698 G_L1: 0.000 D_real: 0.703 D_fake: 0.686 \n",
            "(epoch: 180, iters: 720, time: 0.067, data: 0.002) G_GAN: 4.833 G_L1: 0.428 D_real: 0.253 D_fake: 0.005 \n",
            "(epoch: 180, iters: 820, time: 0.063, data: 0.002) G_GAN: 5.941 G_L1: 0.315 D_real: 0.006 D_fake: 0.005 \n",
            "saving the model at the end of epoch 180, iters 156294\n",
            "End of epoch 180 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000396 -> 0.0000376\n",
            "(epoch: 181, iters: 6, time: 0.059, data: 0.002) G_GAN: 7.620 G_L1: 0.968 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 181, iters: 106, time: 0.067, data: 0.001) G_GAN: 6.361 G_L1: 1.161 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 181, iters: 206, time: 0.068, data: 0.002) G_GAN: 1.103 G_L1: 0.006 D_real: 0.653 D_fake: 0.796 \n",
            "(epoch: 181, iters: 306, time: 0.066, data: 0.002) G_GAN: 6.321 G_L1: 0.126 D_real: 0.041 D_fake: 0.003 \n",
            "(epoch: 181, iters: 406, time: 0.063, data: 0.002) G_GAN: 7.334 G_L1: 0.478 D_real: 0.066 D_fake: 0.002 \n",
            "(epoch: 181, iters: 506, time: 0.067, data: 0.002) G_GAN: 7.574 G_L1: 2.574 D_real: 0.005 D_fake: 0.002 \n",
            "(epoch: 181, iters: 606, time: 0.063, data: 0.002) G_GAN: 4.047 G_L1: 0.163 D_real: 0.001 D_fake: 0.033 \n",
            "(epoch: 181, iters: 706, time: 0.067, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.706 D_fake: 0.684 \n",
            "(epoch: 181, iters: 806, time: 0.066, data: 0.002) G_GAN: 8.658 G_L1: 0.650 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 181, iters: 906, time: 0.067, data: 0.002) G_GAN: 0.671 G_L1: 0.002 D_real: 0.647 D_fake: 0.749 \n",
            "End of epoch 181 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000376 -> 0.0000356\n",
            "(epoch: 182, iters: 92, time: 0.067, data: 0.002) G_GAN: 5.251 G_L1: 0.558 D_real: 0.000 D_fake: 0.009 \n",
            "(epoch: 182, iters: 192, time: 0.068, data: 0.002) G_GAN: 0.684 G_L1: 0.000 D_real: 0.680 D_fake: 0.707 \n",
            "(epoch: 182, iters: 292, time: 0.067, data: 0.002) G_GAN: 0.907 G_L1: 0.023 D_real: 0.799 D_fake: 0.521 \n",
            "(epoch: 182, iters: 392, time: 0.067, data: 0.002) G_GAN: 5.721 G_L1: 0.171 D_real: 0.001 D_fake: 0.006 \n",
            "(epoch: 182, iters: 492, time: 0.066, data: 0.002) G_GAN: 8.570 G_L1: 0.245 D_real: 0.005 D_fake: 0.000 \n",
            "(epoch: 182, iters: 592, time: 0.067, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
            "(epoch: 182, iters: 692, time: 0.068, data: 0.002) G_GAN: 9.335 G_L1: 0.460 D_real: 0.026 D_fake: 0.000 \n",
            "(epoch: 182, iters: 792, time: 0.067, data: 0.002) G_GAN: 0.685 G_L1: 0.000 D_real: 0.684 D_fake: 0.703 \n",
            "(epoch: 182, iters: 892, time: 0.066, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.702 D_fake: 0.685 \n",
            "End of epoch 182 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000356 -> 0.0000337\n",
            "(epoch: 183, iters: 78, time: 0.063, data: 0.002) G_GAN: 6.415 G_L1: 0.495 D_real: 0.050 D_fake: 0.003 \n",
            "(epoch: 183, iters: 178, time: 0.066, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.691 D_fake: 0.696 \n",
            "(epoch: 183, iters: 278, time: 0.065, data: 0.002) G_GAN: 7.078 G_L1: 0.131 D_real: 0.003 D_fake: 0.002 \n",
            "(epoch: 183, iters: 378, time: 0.063, data: 0.002) G_GAN: 5.489 G_L1: 0.611 D_real: 0.006 D_fake: 0.007 \n",
            "(epoch: 183, iters: 478, time: 0.063, data: 0.002) G_GAN: 8.151 G_L1: 1.606 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 183, iters: 578, time: 0.062, data: 0.002) G_GAN: 2.930 G_L1: 0.213 D_real: 0.001 D_fake: 0.315 \n",
            "(epoch: 183, iters: 678, time: 0.066, data: 0.002) G_GAN: 8.295 G_L1: 2.468 D_real: 0.026 D_fake: 0.001 \n",
            "(epoch: 183, iters: 778, time: 0.066, data: 0.002) G_GAN: 0.689 G_L1: 0.000 D_real: 0.685 D_fake: 0.701 \n",
            "(epoch: 183, iters: 878, time: 0.068, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
            "End of epoch 183 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000337 -> 0.0000317\n",
            "(epoch: 184, iters: 64, time: 0.066, data: 0.002) G_GAN: 3.355 G_L1: 0.464 D_real: 0.002 D_fake: 0.074 \n",
            "(epoch: 184, iters: 164, time: 0.067, data: 0.002) G_GAN: 5.691 G_L1: 0.137 D_real: 0.003 D_fake: 0.008 \n",
            "(epoch: 184, iters: 264, time: 0.058, data: 0.002) G_GAN: 10.266 G_L1: 0.789 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 184, iters: 364, time: 0.068, data: 0.002) G_GAN: 0.648 G_L1: 0.000 D_real: 0.659 D_fake: 0.729 \n",
            "(epoch: 184, iters: 464, time: 0.066, data: 0.002) G_GAN: 0.704 G_L1: 0.000 D_real: 0.682 D_fake: 0.705 \n",
            "(epoch: 184, iters: 564, time: 0.066, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
            "(epoch: 184, iters: 664, time: 0.066, data: 0.002) G_GAN: 4.399 G_L1: 0.155 D_real: 0.018 D_fake: 0.022 \n",
            "(epoch: 184, iters: 764, time: 0.067, data: 0.002) G_GAN: 10.568 G_L1: 1.649 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 184, iters: 864, time: 0.066, data: 0.002) G_GAN: 3.576 G_L1: 0.162 D_real: 0.119 D_fake: 0.035 \n",
            "End of epoch 184 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000317 -> 0.0000297\n",
            "(epoch: 185, iters: 50, time: 0.065, data: 0.002) G_GAN: 7.388 G_L1: 0.131 D_real: 0.008 D_fake: 0.001 \n",
            "saving the latest model (epoch 185, total_iters 160000)\n",
            "(epoch: 185, iters: 150, time: 0.064, data: 0.002) G_GAN: 9.309 G_L1: 0.956 D_real: 0.004 D_fake: 0.000 \n",
            "(epoch: 185, iters: 250, time: 0.063, data: 0.002) G_GAN: 2.952 G_L1: 0.032 D_real: 0.049 D_fake: 0.378 \n",
            "(epoch: 185, iters: 350, time: 0.062, data: 0.002) G_GAN: 7.713 G_L1: 0.763 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 185, iters: 450, time: 0.065, data: 0.002) G_GAN: 1.497 G_L1: 0.094 D_real: 0.267 D_fake: 0.227 \n",
            "(epoch: 185, iters: 550, time: 0.065, data: 0.002) G_GAN: 6.982 G_L1: 0.273 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 185, iters: 650, time: 0.066, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.726 D_fake: 0.665 \n",
            "(epoch: 185, iters: 750, time: 0.060, data: 0.002) G_GAN: 7.467 G_L1: 0.655 D_real: 0.002 D_fake: 0.001 \n",
            "(epoch: 185, iters: 850, time: 0.066, data: 0.002) G_GAN: 7.506 G_L1: 0.932 D_real: 0.000 D_fake: 0.002 \n",
            "saving the model at the end of epoch 185, iters 160864\n",
            "End of epoch 185 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0000297 -> 0.0000277\n",
            "(epoch: 186, iters: 36, time: 0.065, data: 0.002) G_GAN: 1.886 G_L1: 0.029 D_real: 0.206 D_fake: 0.189 \n",
            "(epoch: 186, iters: 136, time: 0.064, data: 0.002) G_GAN: 6.789 G_L1: 1.845 D_real: 0.016 D_fake: 0.003 \n",
            "(epoch: 186, iters: 236, time: 0.067, data: 0.002) G_GAN: 8.016 G_L1: 0.833 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 186, iters: 336, time: 0.065, data: 0.002) G_GAN: 10.152 G_L1: 0.757 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 186, iters: 436, time: 0.066, data: 0.006) G_GAN: 6.227 G_L1: 0.630 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 186, iters: 536, time: 0.067, data: 0.002) G_GAN: 6.531 G_L1: 0.175 D_real: 0.084 D_fake: 0.002 \n",
            "(epoch: 186, iters: 636, time: 0.067, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.724 D_fake: 0.665 \n",
            "(epoch: 186, iters: 736, time: 0.063, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
            "(epoch: 186, iters: 836, time: 0.067, data: 0.002) G_GAN: 4.925 G_L1: 1.541 D_real: 0.000 D_fake: 0.022 \n",
            "End of epoch 186 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000277 -> 0.0000257\n",
            "(epoch: 187, iters: 22, time: 0.066, data: 0.002) G_GAN: 7.549 G_L1: 0.238 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 187, iters: 122, time: 0.067, data: 0.002) G_GAN: 0.686 G_L1: 0.000 D_real: 0.677 D_fake: 0.710 \n",
            "(epoch: 187, iters: 222, time: 0.067, data: 0.002) G_GAN: 8.344 G_L1: 0.493 D_real: 0.033 D_fake: 0.001 \n",
            "(epoch: 187, iters: 322, time: 0.064, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
            "(epoch: 187, iters: 422, time: 0.066, data: 0.002) G_GAN: 5.193 G_L1: 0.058 D_real: 0.023 D_fake: 0.009 \n",
            "(epoch: 187, iters: 522, time: 0.067, data: 0.002) G_GAN: 0.688 G_L1: 0.000 D_real: 0.684 D_fake: 0.703 \n",
            "(epoch: 187, iters: 622, time: 0.065, data: 0.002) G_GAN: 5.058 G_L1: 1.758 D_real: 0.000 D_fake: 0.019 \n",
            "(epoch: 187, iters: 722, time: 0.065, data: 0.002) G_GAN: 3.945 G_L1: 0.068 D_real: 0.011 D_fake: 0.053 \n",
            "(epoch: 187, iters: 822, time: 0.066, data: 0.002) G_GAN: 12.164 G_L1: 0.314 D_real: 0.001 D_fake: 0.000 \n",
            "End of epoch 187 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000257 -> 0.0000238\n",
            "(epoch: 188, iters: 8, time: 0.061, data: 0.002) G_GAN: 3.567 G_L1: 0.191 D_real: 0.001 D_fake: 0.080 \n",
            "(epoch: 188, iters: 108, time: 0.068, data: 0.002) G_GAN: 8.862 G_L1: 0.632 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 188, iters: 208, time: 0.066, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.701 D_fake: 0.685 \n",
            "(epoch: 188, iters: 308, time: 0.066, data: 0.002) G_GAN: 5.405 G_L1: 0.223 D_real: 0.023 D_fake: 0.009 \n",
            "(epoch: 188, iters: 408, time: 0.065, data: 0.002) G_GAN: 5.526 G_L1: 0.072 D_real: 0.008 D_fake: 0.007 \n",
            "(epoch: 188, iters: 508, time: 0.067, data: 0.002) G_GAN: 6.343 G_L1: 0.474 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 188, iters: 608, time: 0.063, data: 0.002) G_GAN: 4.389 G_L1: 1.874 D_real: 0.000 D_fake: 0.028 \n",
            "(epoch: 188, iters: 708, time: 0.066, data: 0.002) G_GAN: 9.375 G_L1: 0.852 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 188, iters: 808, time: 0.066, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
            "(epoch: 188, iters: 908, time: 0.064, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.736 D_fake: 0.652 \n",
            "End of epoch 188 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000238 -> 0.0000218\n",
            "(epoch: 189, iters: 94, time: 0.066, data: 0.002) G_GAN: 10.189 G_L1: 1.106 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 189, iters: 194, time: 0.064, data: 0.002) G_GAN: 8.752 G_L1: 0.653 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 189, iters: 294, time: 0.064, data: 0.002) G_GAN: 10.235 G_L1: 1.195 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 189, iters: 394, time: 0.064, data: 0.002) G_GAN: 0.702 G_L1: 0.000 D_real: 0.707 D_fake: 0.680 \n",
            "(epoch: 189, iters: 494, time: 0.065, data: 0.002) G_GAN: 7.556 G_L1: 0.870 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 189, iters: 594, time: 0.061, data: 0.002) G_GAN: 9.682 G_L1: 0.117 D_real: 0.018 D_fake: 0.000 \n",
            "(epoch: 189, iters: 694, time: 0.065, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.711 D_fake: 0.677 \n",
            "(epoch: 189, iters: 794, time: 0.063, data: 0.002) G_GAN: 7.443 G_L1: 0.197 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 189, iters: 894, time: 0.066, data: 0.002) G_GAN: 3.160 G_L1: 0.138 D_real: 0.002 D_fake: 0.158 \n",
            "End of epoch 189 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0000218 -> 0.0000198\n",
            "(epoch: 190, iters: 80, time: 0.069, data: 0.002) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.697 \n",
            "(epoch: 190, iters: 180, time: 0.064, data: 0.002) G_GAN: 1.096 G_L1: 0.194 D_real: 1.115 D_fake: 0.151 \n",
            "(epoch: 190, iters: 280, time: 0.066, data: 0.002) G_GAN: 6.721 G_L1: 0.911 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 190, iters: 380, time: 0.067, data: 0.002) G_GAN: 6.094 G_L1: 0.484 D_real: 0.001 D_fake: 0.006 \n",
            "(epoch: 190, iters: 480, time: 0.063, data: 0.002) G_GAN: 5.145 G_L1: 0.446 D_real: 0.001 D_fake: 0.010 \n",
            "saving the latest model (epoch 190, total_iters 165000)\n",
            "(epoch: 190, iters: 580, time: 0.061, data: 0.002) G_GAN: 9.824 G_L1: 0.809 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 190, iters: 680, time: 0.063, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
            "(epoch: 190, iters: 780, time: 0.064, data: 0.002) G_GAN: 6.444 G_L1: 0.537 D_real: 0.028 D_fake: 0.002 \n",
            "(epoch: 190, iters: 880, time: 0.066, data: 0.002) G_GAN: 10.129 G_L1: 0.476 D_real: 0.000 D_fake: 0.000 \n",
            "saving the model at the end of epoch 190, iters 165434\n",
            "End of epoch 190 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0000198 -> 0.0000178\n",
            "(epoch: 191, iters: 66, time: 0.067, data: 0.002) G_GAN: 11.379 G_L1: 2.394 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 191, iters: 166, time: 0.067, data: 0.002) G_GAN: 11.118 G_L1: 0.423 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 191, iters: 266, time: 0.066, data: 0.002) G_GAN: 6.494 G_L1: 1.069 D_real: 0.002 D_fake: 0.003 \n",
            "(epoch: 191, iters: 366, time: 0.067, data: 0.002) G_GAN: 0.686 G_L1: 0.000 D_real: 0.685 D_fake: 0.702 \n",
            "(epoch: 191, iters: 466, time: 0.067, data: 0.002) G_GAN: 5.641 G_L1: 0.395 D_real: 0.000 D_fake: 0.009 \n",
            "(epoch: 191, iters: 566, time: 0.067, data: 0.002) G_GAN: 0.682 G_L1: 0.000 D_real: 0.678 D_fake: 0.708 \n",
            "(epoch: 191, iters: 666, time: 0.066, data: 0.002) G_GAN: 9.397 G_L1: 0.839 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 191, iters: 766, time: 0.068, data: 0.002) G_GAN: 9.804 G_L1: 1.403 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 191, iters: 866, time: 0.069, data: 0.002) G_GAN: 0.974 G_L1: 0.208 D_real: 0.529 D_fake: 0.742 \n",
            "End of epoch 191 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000178 -> 0.0000158\n",
            "(epoch: 192, iters: 52, time: 0.067, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
            "(epoch: 192, iters: 152, time: 0.067, data: 0.002) G_GAN: 10.710 G_L1: 0.798 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 192, iters: 252, time: 0.068, data: 0.002) G_GAN: 7.393 G_L1: 1.060 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 192, iters: 352, time: 0.068, data: 0.002) G_GAN: 6.932 G_L1: 0.268 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 192, iters: 452, time: 0.063, data: 0.002) G_GAN: 10.454 G_L1: 0.686 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 192, iters: 552, time: 0.068, data: 0.002) G_GAN: 9.211 G_L1: 0.605 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 192, iters: 652, time: 0.068, data: 0.002) G_GAN: 6.321 G_L1: 0.149 D_real: 0.001 D_fake: 0.004 \n",
            "(epoch: 192, iters: 752, time: 0.063, data: 0.002) G_GAN: 6.218 G_L1: 0.570 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 192, iters: 852, time: 0.068, data: 0.002) G_GAN: 7.194 G_L1: 0.644 D_real: 0.001 D_fake: 0.002 \n",
            "End of epoch 192 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000158 -> 0.0000139\n",
            "(epoch: 193, iters: 38, time: 0.061, data: 0.002) G_GAN: 7.932 G_L1: 0.646 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 193, iters: 138, time: 0.067, data: 0.001) G_GAN: 9.701 G_L1: 0.570 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 193, iters: 238, time: 0.068, data: 0.002) G_GAN: 6.332 G_L1: 0.188 D_real: 0.012 D_fake: 0.003 \n",
            "(epoch: 193, iters: 338, time: 0.067, data: 0.002) G_GAN: 6.951 G_L1: 0.733 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 193, iters: 438, time: 0.063, data: 0.002) G_GAN: 8.618 G_L1: 0.962 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 193, iters: 538, time: 0.068, data: 0.002) G_GAN: 7.990 G_L1: 0.552 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 193, iters: 638, time: 0.068, data: 0.002) G_GAN: 8.744 G_L1: 0.540 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 193, iters: 738, time: 0.067, data: 0.002) G_GAN: 5.909 G_L1: 0.199 D_real: 0.002 D_fake: 0.005 \n",
            "(epoch: 193, iters: 838, time: 0.068, data: 0.002) G_GAN: 10.002 G_L1: 0.254 D_real: 0.000 D_fake: 0.000 \n",
            "End of epoch 193 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000139 -> 0.0000119\n",
            "(epoch: 194, iters: 24, time: 0.067, data: 0.002) G_GAN: 8.799 G_L1: 1.328 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 194, iters: 124, time: 0.064, data: 0.002) G_GAN: 0.739 G_L1: 0.041 D_real: 0.679 D_fake: 0.827 \n",
            "(epoch: 194, iters: 224, time: 0.068, data: 0.003) G_GAN: 8.608 G_L1: 1.615 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 194, iters: 324, time: 0.067, data: 0.002) G_GAN: 2.679 G_L1: 1.545 D_real: 0.051 D_fake: 0.131 \n",
            "(epoch: 194, iters: 424, time: 0.068, data: 0.002) G_GAN: 6.042 G_L1: 0.203 D_real: 0.022 D_fake: 0.003 \n",
            "(epoch: 194, iters: 524, time: 0.067, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
            "(epoch: 194, iters: 624, time: 0.064, data: 0.002) G_GAN: 11.828 G_L1: 0.675 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 194, iters: 724, time: 0.068, data: 0.002) G_GAN: 0.723 G_L1: 0.004 D_real: 0.737 D_fake: 0.701 \n",
            "(epoch: 194, iters: 824, time: 0.067, data: 0.002) G_GAN: 9.558 G_L1: 0.453 D_real: 0.000 D_fake: 0.000 \n",
            "End of epoch 194 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000119 -> 0.0000099\n",
            "(epoch: 195, iters: 10, time: 0.068, data: 0.003) G_GAN: 5.412 G_L1: 0.465 D_real: 0.000 D_fake: 0.011 \n",
            "(epoch: 195, iters: 110, time: 0.066, data: 0.002) G_GAN: 6.091 G_L1: 0.666 D_real: 0.003 D_fake: 0.004 \n",
            "(epoch: 195, iters: 210, time: 0.068, data: 0.002) G_GAN: 9.074 G_L1: 0.402 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 195, iters: 310, time: 0.068, data: 0.002) G_GAN: 6.877 G_L1: 0.567 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 195, iters: 410, time: 0.067, data: 0.002) G_GAN: 5.146 G_L1: 0.479 D_real: 0.000 D_fake: 0.010 \n",
            "(epoch: 195, iters: 510, time: 0.069, data: 0.002) G_GAN: 10.238 G_L1: 0.703 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 195, iters: 610, time: 0.069, data: 0.002) G_GAN: 6.481 G_L1: 0.206 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 195, iters: 710, time: 0.067, data: 0.002) G_GAN: 7.722 G_L1: 0.386 D_real: 0.005 D_fake: 0.001 \n",
            "(epoch: 195, iters: 810, time: 0.069, data: 0.002) G_GAN: 6.896 G_L1: 0.364 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 195, iters: 910, time: 0.068, data: 0.002) G_GAN: 8.029 G_L1: 1.367 D_real: 0.001 D_fake: 0.001 \n",
            "saving the latest model (epoch 195, total_iters 170000)\n",
            "saving the model at the end of epoch 195, iters 170004\n",
            "End of epoch 195 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0000099 -> 0.0000079\n",
            "(epoch: 196, iters: 96, time: 0.068, data: 0.001) G_GAN: 8.206 G_L1: 0.560 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 196, iters: 196, time: 0.068, data: 0.002) G_GAN: 6.591 G_L1: 1.642 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 196, iters: 296, time: 0.068, data: 0.002) G_GAN: 6.150 G_L1: 1.707 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 196, iters: 396, time: 0.068, data: 0.002) G_GAN: 0.683 G_L1: 0.000 D_real: 0.682 D_fake: 0.704 \n",
            "(epoch: 196, iters: 496, time: 0.068, data: 0.002) G_GAN: 7.947 G_L1: 0.406 D_real: 0.067 D_fake: 0.001 \n",
            "(epoch: 196, iters: 596, time: 0.068, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.701 D_fake: 0.686 \n",
            "(epoch: 196, iters: 696, time: 0.068, data: 0.002) G_GAN: 5.145 G_L1: 0.014 D_real: 0.009 D_fake: 0.008 \n",
            "(epoch: 196, iters: 796, time: 0.068, data: 0.002) G_GAN: 8.885 G_L1: 1.937 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 196, iters: 896, time: 0.065, data: 0.002) G_GAN: 8.405 G_L1: 2.813 D_real: 0.002 D_fake: 0.003 \n",
            "End of epoch 196 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000079 -> 0.0000059\n",
            "(epoch: 197, iters: 82, time: 0.069, data: 0.002) G_GAN: 0.958 G_L1: 0.011 D_real: 0.915 D_fake: 0.501 \n",
            "(epoch: 197, iters: 182, time: 0.069, data: 0.002) G_GAN: 0.686 G_L1: 0.000 D_real: 0.685 D_fake: 0.702 \n",
            "(epoch: 197, iters: 282, time: 0.068, data: 0.002) G_GAN: 5.757 G_L1: 0.345 D_real: 0.004 D_fake: 0.005 \n",
            "(epoch: 197, iters: 382, time: 0.067, data: 0.002) G_GAN: 11.706 G_L1: 0.649 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 197, iters: 482, time: 0.068, data: 0.002) G_GAN: 7.474 G_L1: 0.198 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 197, iters: 582, time: 0.068, data: 0.002) G_GAN: 6.083 G_L1: 0.415 D_real: 0.006 D_fake: 0.004 \n",
            "(epoch: 197, iters: 682, time: 0.068, data: 0.002) G_GAN: 6.642 G_L1: 0.649 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 197, iters: 782, time: 0.079, data: 0.002) G_GAN: 7.671 G_L1: 0.766 D_real: 0.005 D_fake: 0.001 \n",
            "(epoch: 197, iters: 882, time: 0.067, data: 0.002) G_GAN: 8.883 G_L1: 0.998 D_real: 0.000 D_fake: 0.001 \n",
            "End of epoch 197 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000059 -> 0.0000040\n",
            "(epoch: 198, iters: 68, time: 0.068, data: 0.002) G_GAN: 1.405 G_L1: 0.219 D_real: 0.519 D_fake: 0.335 \n",
            "(epoch: 198, iters: 168, time: 0.068, data: 0.002) G_GAN: 9.294 G_L1: 0.251 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 198, iters: 268, time: 0.069, data: 0.002) G_GAN: 5.683 G_L1: 0.133 D_real: 0.004 D_fake: 0.007 \n",
            "(epoch: 198, iters: 368, time: 0.068, data: 0.002) G_GAN: 8.989 G_L1: 0.214 D_real: 0.006 D_fake: 0.000 \n",
            "(epoch: 198, iters: 468, time: 0.065, data: 0.002) G_GAN: 1.630 G_L1: 0.036 D_real: 0.598 D_fake: 0.232 \n",
            "(epoch: 198, iters: 568, time: 0.068, data: 0.002) G_GAN: 0.701 G_L1: 0.000 D_real: 0.700 D_fake: 0.686 \n",
            "(epoch: 198, iters: 668, time: 0.064, data: 0.002) G_GAN: 8.190 G_L1: 0.649 D_real: 0.004 D_fake: 0.001 \n",
            "(epoch: 198, iters: 768, time: 0.068, data: 0.002) G_GAN: 7.896 G_L1: 0.807 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 198, iters: 868, time: 0.068, data: 0.002) G_GAN: 9.713 G_L1: 2.820 D_real: 0.000 D_fake: 0.001 \n",
            "End of epoch 198 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000040 -> 0.0000020\n",
            "(epoch: 199, iters: 54, time: 0.067, data: 0.002) G_GAN: 9.113 G_L1: 0.928 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 199, iters: 154, time: 0.067, data: 0.002) G_GAN: 6.527 G_L1: 0.549 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 199, iters: 254, time: 0.068, data: 0.002) G_GAN: 0.674 G_L1: 0.000 D_real: 0.673 D_fake: 0.713 \n",
            "(epoch: 199, iters: 354, time: 0.068, data: 0.002) G_GAN: 12.200 G_L1: 1.968 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 199, iters: 454, time: 0.064, data: 0.002) G_GAN: 7.758 G_L1: 1.173 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 199, iters: 554, time: 0.072, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.701 D_fake: 0.685 \n",
            "(epoch: 199, iters: 654, time: 0.068, data: 0.002) G_GAN: 3.187 G_L1: 0.067 D_real: 0.003 D_fake: 0.064 \n",
            "(epoch: 199, iters: 754, time: 0.068, data: 0.002) G_GAN: 10.259 G_L1: 1.040 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 199, iters: 854, time: 0.063, data: 0.002) G_GAN: 8.376 G_L1: 0.141 D_real: 0.000 D_fake: 0.001 \n",
            "End of epoch 199 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000020 -> 0.0000000\n",
            "(epoch: 200, iters: 40, time: 0.068, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.699 D_fake: 0.688 \n",
            "(epoch: 200, iters: 140, time: 0.063, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.699 D_fake: 0.688 \n",
            "(epoch: 200, iters: 240, time: 0.067, data: 0.002) G_GAN: 9.489 G_L1: 0.329 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 200, iters: 340, time: 0.068, data: 0.002) G_GAN: 0.723 G_L1: 0.014 D_real: 0.698 D_fake: 0.679 \n",
            "(epoch: 200, iters: 440, time: 0.066, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.699 D_fake: 0.688 \n",
            "(epoch: 200, iters: 540, time: 0.067, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.699 D_fake: 0.688 \n",
            "(epoch: 200, iters: 640, time: 0.058, data: 0.002) G_GAN: 5.278 G_L1: 1.445 D_real: 0.001 D_fake: 0.009 \n",
            "(epoch: 200, iters: 740, time: 0.069, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.699 D_fake: 0.688 \n",
            "(epoch: 200, iters: 840, time: 0.068, data: 0.002) G_GAN: 4.668 G_L1: 0.957 D_real: 0.025 D_fake: 0.015 \n",
            "saving the model at the end of epoch 200, iters 174574\n",
            "End of epoch 200 / 200 \t Time Taken: 44 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UkcaFZiyASl"
      },
      "source": [
        "# Testing\n",
        "\n",
        "-   `python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_pix2pix`\n",
        "\n",
        "Change the `--dataroot`, `--name`, and `--direction` to be consistent with your trained model's configuration and how you want to transform images.\n",
        "\n",
        "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n",
        "> Note that we specified --direction BtoA as Facades dataset's A to B direction is photos to labels.\n",
        "\n",
        "> If you would like to apply a pre-trained model to a collection of input images (rather than image pairs), please use --model test option. See ./scripts/test_single.sh for how to apply a model to Facade label maps (stored in the directory facades/testB).\n",
        "\n",
        "> See a list of currently available models at ./scripts/download_pix2pix_model.sh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mey7o6j-0368",
        "outputId": "f74f65c1-a174-46e7-9390-0c3656effb97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls checkpoints/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "maps_pix2pix  pix2pix\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCsKkEq0yGh0",
        "outputId": "dffb6401-6cdb-4a63-9d71-23df93d3dabc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python test.py --dataroot ./mydataset --model pix2pix --name maps_pix2pix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./mydataset                   \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: maps_pix2pix                  \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: unet_256                      \n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 1                             \n",
            "                    phase: test                          \n",
            "               preprocess: resize_and_crop               \n",
            "              results_dir: ./results/                    \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/maps_pix2pix/latest_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 54.410 M\n",
            "-----------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"test.py\", line 58, in <module>\n",
            "    save_images(visuals, img_path, img_dir)\n",
            "  File \"/gdrive/My Drive/Colab Notebooks/pytorch-CycleGAN-and-pix2pix/util/util.py\", line 121, in save_images\n",
            "    save_image(im, save_path, aspect_ratio=1)\n",
            "  File \"/gdrive/My Drive/Colab Notebooks/pytorch-CycleGAN-and-pix2pix/util/util.py\", line 64, in save_image\n",
            "    image_pil.save(image_path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 2099, in save\n",
            "    fp = builtins.open(filename, \"w+b\")\n",
            "FileNotFoundError: [Errno 2] No such file or directory: './results/maps_pix2pix/test_latest/0_real_A.png'\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}